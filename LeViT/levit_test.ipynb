{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import levit \n",
    "import levit_c \n",
    "import torch \n",
    "import tensorrt as trt \n",
    "from cuda import cudart\n",
    "import numpy as np\n",
    "# import pycuda.driver\n",
    "# import pycuda.autoinit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_128 = levit.LeViT_128(pretrained=True,distillation=True)\n",
    "my_model_192 = levit.LeViT_192(pretrained=True,distillation=True)\n",
    "my_model_128S = levit.LeViT_128S(pretrained=True,distillation=True)\n",
    "my_model_256 = levit.LeViT_256(pretrained=True,distillation=True)\n",
    "my_model_384 = levit.LeViT_384(pretrained=True,distillation=True)\n",
    "\n",
    "input_tensor = torch.randn(16,3,224,224)\n",
    "torch.onnx.export(my_model_128,               # model being run\n",
    "                  input_tensor,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"levit_128_onnx.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True, \n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})  # whether to execute constant folding for optimization)\n",
    "torch.onnx.export(my_model_192,               # model being run\n",
    "                  input_tensor,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"levit_192_onnx.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True, \n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})  # whether to execute constant folding for optimization)\n",
    "torch.onnx.export(my_model_128S,               # model being run\n",
    "                  input_tensor,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"levit_128S_onnx.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True, \n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})  # whether to execute constant folding for optimization)\n",
    "torch.onnx.export(my_model_256,               # model being run\n",
    "                  input_tensor,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"levit_256_onnx.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True, \n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})  # whether to execute constant folding for optimization)\n",
    "torch.onnx.export(my_model_384,               # model being run\n",
    "                  input_tensor,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"levit_384_onnx.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True, \n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})  # whether to execute constant folding for optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_engine(max_batch_size = 512,\n",
    "                 max_workspace_size_n = 4,\n",
    "                 onnx_path = \"levit_128_onnx.onnx\",\n",
    "                 trtfile = \"my_model.plan\",\n",
    "                 min_shape = (2,3,224,224),\n",
    "                 common_shape = (4,3,224,224),\n",
    "                 max_shape = (16,3,224,224)\n",
    "                 ):\n",
    "    logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "    builder = trt.Builder(logger)\n",
    "    builder.max_batch_size = max_batch_size\n",
    "\n",
    "    profile = builder.create_optimization_profile()\n",
    "\n",
    "    config = builder.create_builder_config()\n",
    "    config.max_workspace_size = max_workspace_size_n<<30\n",
    "    config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "    parser = trt.OnnxParser(network,logger)\n",
    "    with open(onnx_path, \"rb\") as model:\n",
    "        parser.parse(model.read())\n",
    "\n",
    "    input_tensor = network.get_input(0)\n",
    "    profile.set_shape(input_tensor.name,min_shape,common_shape,max_shape)\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    engineString = builder.build_serialized_network(network,config)\n",
    "    if(engineString == None):\n",
    "        print(\"Fail building\")\n",
    "        return \n",
    "    print(\"Success !\") \n",
    "    with open(trtfile,'wb') as f:\n",
    "        f.write(engineString)\n",
    "    return engineString, logger\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24356/2388561028.py:16: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = max_workspace_size_n<<30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/24/2022-15:21:28] [TRT] [I] [MemUsageChange] Init CUDA: CPU +192, GPU +0, now: CPU 3388, GPU 913 (MiB)\n",
      "[05/24/2022-15:21:29] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 3407 MiB, GPU 913 MiB\n",
      "[05/24/2022-15:21:29] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 3415 MiB, GPU 913 MiB\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::NMS_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::Reorg_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::Region_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::Clip_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::LReLU_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::PriorBox_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::Normalize_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::ScatterND version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::RPROI_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::CropAndResize version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::Proposal version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::Split version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registered plugin creator - ::InstanceNormalization_TRT version 2\n",
      "[05/24/2022-15:21:29] [TRT] [V] Adding network input: input with dtype: float32, dimensions: (-1, 3, 224, 224)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input for ONNX tensor: input\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.0.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.1.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.2.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.3.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.4.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.5.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.6.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.7.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.kv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.kv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.kv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.kv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.q.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.q.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.q.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.q.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.8.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.9.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.10.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.11.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.12.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.13.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.14.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.15.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.16.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.17.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.kv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.kv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.kv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.kv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.q.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.q.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.q.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.q.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.18.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.19.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.20.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.21.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.22.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.23.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.24.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.25.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.26.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: blocks.27.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head.l.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head.l.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head_dist.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head_dist.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head_dist.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head_dist.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head_dist.l.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: head_dist.l.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1431\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1432\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1434\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1435\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1437\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1438\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1440\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Conv_1441\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1442\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1443\n",
      "[05/24/2022-15:21:29] [TRT] [W] onnx2trt_utils.cpp:365: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1444\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1445\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1446\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1447\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1448\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1449\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1450\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1451\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1452\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1453\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1454\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1455\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1456\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1457\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1458\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1459\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1460\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1461\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1462\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1463\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1464\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1465\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1466\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1467\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1468\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1469\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1470\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1471\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1472\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1473\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1474\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1475\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1476\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1477\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1478\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1479\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1480\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1481\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1482\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1483\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1484\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1485\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1486\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1487\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1488\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1489\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1490\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1491\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1492\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1493\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1494\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1495\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1496\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1497\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1498\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1499\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1500\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1501\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1502\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1503\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1504\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1505\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1506\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1507\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1508\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1509\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1510\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1511\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1512\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1513\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1514\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1515\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1516\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1517\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1518\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1519\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1520\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1521\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1522\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1523\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1524\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1525\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1526\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1527\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1528\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1529\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1530\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1531\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1532\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1533\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1534\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1535\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1536\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1537\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1538\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1539\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1540\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1541\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1542\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1543\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1544\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1545\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1546\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1547\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1548\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1549\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1550\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1551\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::Concat_1552\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1553\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1554\n",
      "[05/24/2022-15:21:29] [TRT] [V] Importing initializer: onnx::MatMul_1555\n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Conv_0 [Conv]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1431\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1432\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_0 [Conv] inputs: [input -> (-1, 3, 224, 224)[FLOAT]], [onnx::Conv_1431 -> (16, 3, 3, 3)[FLOAT]], [onnx::Conv_1432 -> (16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution input dimensions: (-1, 3, 224, 224)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Conv_0 for ONNX node: Conv_0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 16\n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution output dimensions: (-1, 16, 112, 112)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.4 for ONNX tensor: input.4\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_0 [Conv] outputs: [input.4 -> (-1, 16, 112, 112)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_1 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.4\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_1 [HardSigmoid] inputs: [input.4 -> (-1, 16, 112, 112)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_1 for ONNX node: HardSigmoid_1\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_417 for ONNX tensor: onnx::Mul_417\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_1 [HardSigmoid] outputs: [onnx::Mul_417 -> (-1, 16, 112, 112)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_2 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.4\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_417\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_2 [Mul] inputs: [input.4 -> (-1, 16, 112, 112)[FLOAT]], [onnx::Mul_417 -> (-1, 16, 112, 112)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_2 for ONNX node: Mul_2\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.8 for ONNX tensor: input.8\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_2 [Mul] outputs: [input.8 -> (-1, 16, 112, 112)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Conv_3 [Conv]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.8\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1434\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1435\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_3 [Conv] inputs: [input.8 -> (-1, 16, 112, 112)[FLOAT]], [onnx::Conv_1434 -> (32, 16, 3, 3)[FLOAT]], [onnx::Conv_1435 -> (32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution input dimensions: (-1, 16, 112, 112)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Conv_3 for ONNX node: Conv_3\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 32\n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution output dimensions: (-1, 32, 56, 56)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.16 for ONNX tensor: input.16\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_3 [Conv] outputs: [input.16 -> (-1, 32, 56, 56)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_4 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.16\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_4 [HardSigmoid] inputs: [input.16 -> (-1, 32, 56, 56)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_4 for ONNX node: HardSigmoid_4\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_421 for ONNX tensor: onnx::Mul_421\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_4 [HardSigmoid] outputs: [onnx::Mul_421 -> (-1, 32, 56, 56)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_5 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.16\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_421\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_5 [Mul] inputs: [input.16 -> (-1, 32, 56, 56)[FLOAT]], [onnx::Mul_421 -> (-1, 32, 56, 56)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_5 for ONNX node: Mul_5\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.20 for ONNX tensor: input.20\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_5 [Mul] outputs: [input.20 -> (-1, 32, 56, 56)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Conv_6 [Conv]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.20\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1437\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1438\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_6 [Conv] inputs: [input.20 -> (-1, 32, 56, 56)[FLOAT]], [onnx::Conv_1437 -> (64, 32, 3, 3)[FLOAT]], [onnx::Conv_1438 -> (64)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution input dimensions: (-1, 32, 56, 56)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Conv_6 for ONNX node: Conv_6\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64\n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution output dimensions: (-1, 64, 28, 28)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.28 for ONNX tensor: input.28\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_6 [Conv] outputs: [input.28 -> (-1, 64, 28, 28)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_7 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.28\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_7 [HardSigmoid] inputs: [input.28 -> (-1, 64, 28, 28)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_7 for ONNX node: HardSigmoid_7\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_425 for ONNX tensor: onnx::Mul_425\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_7 [HardSigmoid] outputs: [onnx::Mul_425 -> (-1, 64, 28, 28)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_8 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.28\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_425\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_8 [Mul] inputs: [input.28 -> (-1, 64, 28, 28)[FLOAT]], [onnx::Mul_425 -> (-1, 64, 28, 28)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_8 for ONNX node: Mul_8\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.32 for ONNX tensor: input.32\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_8 [Mul] outputs: [input.32 -> (-1, 64, 28, 28)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Conv_9 [Conv]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.32\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1440\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Conv_1441\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_9 [Conv] inputs: [input.32 -> (-1, 64, 28, 28)[FLOAT]], [onnx::Conv_1440 -> (128, 64, 3, 3)[FLOAT]], [onnx::Conv_1441 -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution input dimensions: (-1, 64, 28, 28)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Conv_9 for ONNX node: Conv_9\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128\n",
      "[05/24/2022-15:21:29] [TRT] [V] Convolution output dimensions: (-1, 128, 14, 14)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Shape_1439 for ONNX tensor: onnx::Shape_1439\n",
      "[05/24/2022-15:21:29] [TRT] [V] Conv_9 [Conv] outputs: [onnx::Shape_1439 -> (-1, 128, 14, 14)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_10 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_1439\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_10 [Shape] inputs: [onnx::Shape_1439 -> (-1, 128, 14, 14)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_10 for ONNX node: Shape_10\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Slice_429 for ONNX tensor: onnx::Slice_429\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_10 [Shape] outputs: [onnx::Slice_429 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_11 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_11 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_11 [Constant] outputs: [onnx::Slice_430 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_12 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_12 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_12 [Constant] outputs: [onnx::Slice_431 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_13 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_13 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_13 [Constant] outputs: [onnx::Slice_432 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Slice_14 [Slice]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_429\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_431\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_432\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_430\n",
      "[05/24/2022-15:21:29] [TRT] [V] Slice_14 [Slice] inputs: [onnx::Slice_429 -> (4)[INT32]], [onnx::Slice_431 -> (1)[INT32]], [onnx::Slice_432 -> (1)[INT32]], [onnx::Slice_430 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Slice_14 for ONNX node: Slice_14\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_433 for ONNX tensor: onnx::Concat_433\n",
      "[05/24/2022-15:21:29] [TRT] [V] Slice_14 [Slice] outputs: [onnx::Concat_433 -> (2)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_15 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_15 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_15 [Constant] outputs: [onnx::Concat_434 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_16 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_433\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_434\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_16 [Concat] inputs: [onnx::Concat_433 -> (2)[INT32]], [onnx::Concat_434 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_434 for ONNX node: onnx::Concat_434\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_16 for ONNX node: Concat_16\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_435 for ONNX tensor: onnx::Reshape_435\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_16 [Concat] outputs: [onnx::Reshape_435 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_17 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_1439\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_435\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_17 [Reshape] inputs: [onnx::Shape_1439 -> (-1, 128, 14, 14)[FLOAT]], [onnx::Reshape_435 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_17 for ONNX node: Reshape_17\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_436 for ONNX tensor: onnx::Transpose_436\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_17 [Reshape] outputs: [onnx::Transpose_436 -> (-1, 128, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_18 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_436\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_18 [Transpose] inputs: [onnx::Transpose_436 -> (-1, 128, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_18 for ONNX node: Transpose_18\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Shape_437 for ONNX tensor: onnx::Shape_437\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_18 [Transpose] outputs: [onnx::Shape_437 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_19 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_437\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_19 [Shape] inputs: [onnx::Shape_437 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_19 for ONNX node: Shape_19\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_438 for ONNX tensor: onnx::Gather_438\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_19 [Shape] outputs: [onnx::Gather_438 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_20 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_20 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_20 [Constant] outputs: [onnx::Gather_439 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_21 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_438\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_439\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_21 [Gather] inputs: [onnx::Gather_438 -> (3)[INT32]], [onnx::Gather_439 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_439 for ONNX node: onnx::Gather_439\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_21 for ONNX node: Gather_21\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_440 for ONNX tensor: onnx::Unsqueeze_440\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_21 [Gather] outputs: [onnx::Unsqueeze_440 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_22 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_437\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_22 [Shape] inputs: [onnx::Shape_437 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_22 for ONNX node: Shape_22\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_441 for ONNX tensor: onnx::Gather_441\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_22 [Shape] outputs: [onnx::Gather_441 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_23 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_23 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_23 [Constant] outputs: [onnx::Gather_442 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_24 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_441\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_442\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_24 [Gather] inputs: [onnx::Gather_441 -> (3)[INT32]], [onnx::Gather_442 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_442 for ONNX node: onnx::Gather_442\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_24 for ONNX node: Gather_24\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_443 for ONNX tensor: onnx::Unsqueeze_443\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_24 [Gather] outputs: [onnx::Unsqueeze_443 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_25 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_437\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1442\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_25 [MatMul] inputs: [onnx::Shape_437 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1442 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1442 for ONNX node: onnx::MatMul_1442\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_25 for ONNX node: MatMul_25\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_445 for ONNX tensor: onnx::Flatten_445\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_25 [MatMul] outputs: [onnx::Flatten_445 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_26 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_445\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_26 [Flatten] inputs: [onnx::Flatten_445 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_26 for ONNX node: Flatten_26\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.40 for ONNX tensor: input.40\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_26 [Flatten] outputs: [input.40 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_27 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.40\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_27 [BatchNormalization] inputs: [input.40 -> (-1, 256)[FLOAT]], [blocks.0.m.qkv.bn.weight -> (256)[FLOAT]], [blocks.0.m.qkv.bn.bias -> (256)[FLOAT]], [blocks.0.m.qkv.bn.running_mean -> (256)[FLOAT]], [blocks.0.m.qkv.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_27 for ONNX node: BatchNormalization_27\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_447 for ONNX tensor: onnx::Reshape_447\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_27 [BatchNormalization] outputs: [onnx::Reshape_447 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_28 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_445\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_28 [Shape] inputs: [onnx::Flatten_445 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_28 for ONNX node: Shape_28\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_448 for ONNX tensor: onnx::Reshape_448\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_28 [Shape] outputs: [onnx::Reshape_448 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_29 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_447\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_448\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_29 [Reshape] inputs: [onnx::Reshape_447 -> (-1, 256)[FLOAT]], [onnx::Reshape_448 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_29 for ONNX node: Reshape_29\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_449 for ONNX tensor: onnx::Reshape_449\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_29 [Reshape] outputs: [onnx::Reshape_449 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_30 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_440\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_30 [Unsqueeze] inputs: [onnx::Unsqueeze_440 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_30 for ONNX node: Unsqueeze_30\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_452 for ONNX tensor: onnx::Concat_452\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_30 [Unsqueeze] outputs: [onnx::Concat_452 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_31 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_443\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_31 [Unsqueeze] inputs: [onnx::Unsqueeze_443 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_31 for ONNX node: Unsqueeze_31\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_453 for ONNX tensor: onnx::Concat_453\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_31 [Unsqueeze] outputs: [onnx::Concat_453 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_32 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_452\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_453\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1443\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1444\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_32 [Concat] inputs: [onnx::Concat_452 -> (1)[INT32]], [onnx::Concat_453 -> (1)[INT32]], [onnx::Concat_1443 -> (1)[INT32]], [onnx::Concat_1444 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1443 for ONNX node: onnx::Concat_1443\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1444 for ONNX node: onnx::Concat_1444\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_32 for ONNX node: Concat_32\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_456 for ONNX tensor: onnx::Reshape_456\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_32 [Concat] outputs: [onnx::Reshape_456 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_33 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_449\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_456\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_33 [Reshape] inputs: [onnx::Reshape_449 -> (-1, 196, 256)[FLOAT]], [onnx::Reshape_456 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_33 for ONNX node: Reshape_33\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Split_457 for ONNX tensor: onnx::Split_457\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_33 [Reshape] outputs: [onnx::Split_457 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Split_34 [Split]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Split_457\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_34 [Split] inputs: [onnx::Split_457 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_34 for ONNX node: Split_34\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_34_71 for ONNX node: Split_34\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_34_73 for ONNX node: Split_34\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_458 for ONNX tensor: onnx::Transpose_458\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_459 for ONNX tensor: onnx::Transpose_459\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_460 for ONNX tensor: onnx::Transpose_460\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_34 [Split] outputs: [onnx::Transpose_458 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_459 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_460 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_35 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_458\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_35 [Transpose] inputs: [onnx::Transpose_458 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_35 for ONNX node: Transpose_35\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_461 for ONNX tensor: onnx::MatMul_461\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_35 [Transpose] outputs: [onnx::MatMul_461 -> (-1, 4, 196, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_36 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_460\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_36 [Transpose] inputs: [onnx::Transpose_460 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_36 for ONNX node: Transpose_36\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_462 for ONNX tensor: onnx::MatMul_462\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_36 [Transpose] outputs: [onnx::MatMul_462 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_37 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_459\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_37 [Transpose] inputs: [onnx::Transpose_459 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_37 for ONNX node: Transpose_37\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_463 for ONNX tensor: onnx::MatMul_463\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_37 [Transpose] outputs: [onnx::MatMul_463 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_38 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_461\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_463\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_38 [MatMul] inputs: [onnx::MatMul_461 -> (-1, 4, 196, 16)[FLOAT]], [onnx::MatMul_463 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_38 for ONNX node: MatMul_38\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_464 for ONNX tensor: onnx::Mul_464\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_38 [MatMul] outputs: [onnx::Mul_464 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_39 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_39 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_39 [Constant] outputs: [onnx::Mul_465 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_40 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_464\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_465\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_40 [Mul] inputs: [onnx::Mul_464 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Mul_465 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Mul_465 for ONNX node: onnx::Mul_465\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_40 for ONNX node: Mul_40\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_466 for ONNX tensor: onnx::Add_466\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_40 [Mul] outputs: [onnx::Add_466 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_41 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_41 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_41 [Constant] outputs: [onnx::Add_467 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_42 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_466\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_467\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_42 [Add] inputs: [onnx::Add_466 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Add_467 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Add_467 for ONNX node: onnx::Add_467\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_42 for ONNX node: Add_42\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Softmax_468 for ONNX tensor: onnx::Softmax_468\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_42 [Add] outputs: [onnx::Softmax_468 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Softmax_43 [Softmax]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Softmax_468\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_43 [Softmax] inputs: [onnx::Softmax_468 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Softmax_43 for ONNX node: Softmax_43\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_469 for ONNX tensor: onnx::MatMul_469\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_43 [Softmax] outputs: [onnx::MatMul_469 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_44 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_469\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_462\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_44 [MatMul] inputs: [onnx::MatMul_469 -> (-1, 4, 196, 196)[FLOAT]], [onnx::MatMul_462 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_44 for ONNX node: MatMul_44\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_470 for ONNX tensor: onnx::Transpose_470\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_44 [MatMul] outputs: [onnx::Transpose_470 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_45 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_470\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_45 [Transpose] inputs: [onnx::Transpose_470 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_45 for ONNX node: Transpose_45\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_471 for ONNX tensor: onnx::Reshape_471\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_45 [Transpose] outputs: [onnx::Reshape_471 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_46 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_440\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_46 [Unsqueeze] inputs: [onnx::Unsqueeze_440 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_46 for ONNX node: Unsqueeze_46\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_473 for ONNX tensor: onnx::Concat_473\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_46 [Unsqueeze] outputs: [onnx::Concat_473 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_47 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_443\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_47 [Unsqueeze] inputs: [onnx::Unsqueeze_443 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_47 for ONNX node: Unsqueeze_47\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_474 for ONNX tensor: onnx::Concat_474\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_47 [Unsqueeze] outputs: [onnx::Concat_474 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_48 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_473\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_474\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1445\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_48 [Concat] inputs: [onnx::Concat_473 -> (1)[INT32]], [onnx::Concat_474 -> (1)[INT32]], [onnx::Concat_1445 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1445 for ONNX node: onnx::Concat_1445\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_48 for ONNX node: Concat_48\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_476 for ONNX tensor: onnx::Reshape_476\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_48 [Concat] outputs: [onnx::Reshape_476 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_49 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_471\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_476\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_49 [Reshape] inputs: [onnx::Reshape_471 -> (-1, 196, 4, 32)[FLOAT]], [onnx::Reshape_476 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_49 for ONNX node: Reshape_49\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.44 for ONNX tensor: input.44\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_49 [Reshape] outputs: [input.44 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_50 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.44\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_50 [HardSigmoid] inputs: [input.44 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_50 for ONNX node: HardSigmoid_50\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_478 for ONNX tensor: onnx::Mul_478\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_50 [HardSigmoid] outputs: [onnx::Mul_478 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_51 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.44\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_478\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_51 [Mul] inputs: [input.44 -> (-1, 196, 128)[FLOAT]], [onnx::Mul_478 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_51 for ONNX node: Mul_51\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_479 for ONNX tensor: onnx::MatMul_479\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_51 [Mul] outputs: [onnx::MatMul_479 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_52 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_479\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1446\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_52 [MatMul] inputs: [onnx::MatMul_479 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1446 -> (128, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1446 for ONNX node: onnx::MatMul_1446\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_52 for ONNX node: MatMul_52\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_481 for ONNX tensor: onnx::Flatten_481\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_52 [MatMul] outputs: [onnx::Flatten_481 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_53 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_481\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_53 [Flatten] inputs: [onnx::Flatten_481 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_53 for ONNX node: Flatten_53\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.48 for ONNX tensor: input.48\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_53 [Flatten] outputs: [input.48 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_54 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.48\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.0.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_54 [BatchNormalization] inputs: [input.48 -> (-1, 128)[FLOAT]], [blocks.0.m.proj.1.bn.weight -> (128)[FLOAT]], [blocks.0.m.proj.1.bn.bias -> (128)[FLOAT]], [blocks.0.m.proj.1.bn.running_mean -> (128)[FLOAT]], [blocks.0.m.proj.1.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_54 for ONNX node: BatchNormalization_54\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_483 for ONNX tensor: onnx::Reshape_483\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_54 [BatchNormalization] outputs: [onnx::Reshape_483 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_55 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_481\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_55 [Shape] inputs: [onnx::Flatten_481 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_55 for ONNX node: Shape_55\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_484 for ONNX tensor: onnx::Reshape_484\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_55 [Shape] outputs: [onnx::Reshape_484 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_56 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_483\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_484\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_56 [Reshape] inputs: [onnx::Reshape_483 -> (-1, 128)[FLOAT]], [onnx::Reshape_484 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_56 for ONNX node: Reshape_56\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_485 for ONNX tensor: onnx::Add_485\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_56 [Reshape] outputs: [onnx::Add_485 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_57 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_437\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_485\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_57 [Add] inputs: [onnx::Shape_437 -> (-1, 196, 128)[FLOAT]], [onnx::Add_485 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_57 for ONNX node: Add_57\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_486 for ONNX tensor: onnx::MatMul_486\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_57 [Add] outputs: [onnx::MatMul_486 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_58 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_486\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1447\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_58 [MatMul] inputs: [onnx::MatMul_486 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1447 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1447 for ONNX node: onnx::MatMul_1447\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_58 for ONNX node: MatMul_58\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_488 for ONNX tensor: onnx::Flatten_488\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_58 [MatMul] outputs: [onnx::Flatten_488 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_59 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_488\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_59 [Flatten] inputs: [onnx::Flatten_488 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_59 for ONNX node: Flatten_59\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.52 for ONNX tensor: input.52\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_59 [Flatten] outputs: [input.52 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_60 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.52\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_60 [BatchNormalization] inputs: [input.52 -> (-1, 256)[FLOAT]], [blocks.1.m.0.bn.weight -> (256)[FLOAT]], [blocks.1.m.0.bn.bias -> (256)[FLOAT]], [blocks.1.m.0.bn.running_mean -> (256)[FLOAT]], [blocks.1.m.0.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_60 for ONNX node: BatchNormalization_60\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_490 for ONNX tensor: onnx::Reshape_490\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_60 [BatchNormalization] outputs: [onnx::Reshape_490 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_61 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_488\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_61 [Shape] inputs: [onnx::Flatten_488 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_61 for ONNX node: Shape_61\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_491 for ONNX tensor: onnx::Reshape_491\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_61 [Shape] outputs: [onnx::Reshape_491 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_62 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_490\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_491\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_62 [Reshape] inputs: [onnx::Reshape_490 -> (-1, 256)[FLOAT]], [onnx::Reshape_491 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_62 for ONNX node: Reshape_62\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.56 for ONNX tensor: input.56\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_62 [Reshape] outputs: [input.56 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_63 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.56\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_63 [HardSigmoid] inputs: [input.56 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_63 for ONNX node: HardSigmoid_63\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_493 for ONNX tensor: onnx::Mul_493\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_63 [HardSigmoid] outputs: [onnx::Mul_493 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_64 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.56\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_493\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_64 [Mul] inputs: [input.56 -> (-1, 196, 256)[FLOAT]], [onnx::Mul_493 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_64 for ONNX node: Mul_64\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_494 for ONNX tensor: onnx::MatMul_494\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_64 [Mul] outputs: [onnx::MatMul_494 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_65 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_494\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1448\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_65 [MatMul] inputs: [onnx::MatMul_494 -> (-1, 196, 256)[FLOAT]], [onnx::MatMul_1448 -> (256, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1448 for ONNX node: onnx::MatMul_1448\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_65 for ONNX node: MatMul_65\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_496 for ONNX tensor: onnx::Flatten_496\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_65 [MatMul] outputs: [onnx::Flatten_496 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_66 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_496\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_66 [Flatten] inputs: [onnx::Flatten_496 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_66 for ONNX node: Flatten_66\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.60 for ONNX tensor: input.60\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_66 [Flatten] outputs: [input.60 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_67 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.60\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.1.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_67 [BatchNormalization] inputs: [input.60 -> (-1, 128)[FLOAT]], [blocks.1.m.2.bn.weight -> (128)[FLOAT]], [blocks.1.m.2.bn.bias -> (128)[FLOAT]], [blocks.1.m.2.bn.running_mean -> (128)[FLOAT]], [blocks.1.m.2.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_67 for ONNX node: BatchNormalization_67\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_498 for ONNX tensor: onnx::Reshape_498\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_67 [BatchNormalization] outputs: [onnx::Reshape_498 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_68 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_496\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_68 [Shape] inputs: [onnx::Flatten_496 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_68 for ONNX node: Shape_68\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_499 for ONNX tensor: onnx::Reshape_499\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_68 [Shape] outputs: [onnx::Reshape_499 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_69 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_498\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_499\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_69 [Reshape] inputs: [onnx::Reshape_498 -> (-1, 128)[FLOAT]], [onnx::Reshape_499 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_69 for ONNX node: Reshape_69\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_500 for ONNX tensor: onnx::Add_500\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_69 [Reshape] outputs: [onnx::Add_500 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_70 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_486\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_500\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_70 [Add] inputs: [onnx::MatMul_486 -> (-1, 196, 128)[FLOAT]], [onnx::Add_500 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_70 for ONNX node: Add_70\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Shape_501 for ONNX tensor: onnx::Shape_501\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_70 [Add] outputs: [onnx::Shape_501 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_71 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_501\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_71 [Shape] inputs: [onnx::Shape_501 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_71 for ONNX node: Shape_71\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_502 for ONNX tensor: onnx::Gather_502\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_71 [Shape] outputs: [onnx::Gather_502 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_72 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_72 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_72 [Constant] outputs: [onnx::Gather_503 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_73 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_502\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_503\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_73 [Gather] inputs: [onnx::Gather_502 -> (3)[INT32]], [onnx::Gather_503 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_503 for ONNX node: onnx::Gather_503\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_73 for ONNX node: Gather_73\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_504 for ONNX tensor: onnx::Unsqueeze_504\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_73 [Gather] outputs: [onnx::Unsqueeze_504 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_74 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_501\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_74 [Shape] inputs: [onnx::Shape_501 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_74 for ONNX node: Shape_74\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_505 for ONNX tensor: onnx::Gather_505\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_74 [Shape] outputs: [onnx::Gather_505 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_75 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_75 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_75 [Constant] outputs: [onnx::Gather_506 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_76 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_505\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_506\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_76 [Gather] inputs: [onnx::Gather_505 -> (3)[INT32]], [onnx::Gather_506 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_506 for ONNX node: onnx::Gather_506\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_76 for ONNX node: Gather_76\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_507 for ONNX tensor: onnx::Unsqueeze_507\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_76 [Gather] outputs: [onnx::Unsqueeze_507 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_77 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_501\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1449\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_77 [MatMul] inputs: [onnx::Shape_501 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1449 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1449 for ONNX node: onnx::MatMul_1449\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_77 for ONNX node: MatMul_77\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_509 for ONNX tensor: onnx::Flatten_509\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_77 [MatMul] outputs: [onnx::Flatten_509 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_78 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_509\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_78 [Flatten] inputs: [onnx::Flatten_509 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_78 for ONNX node: Flatten_78\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.64 for ONNX tensor: input.64\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_78 [Flatten] outputs: [input.64 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_79 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.64\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_79 [BatchNormalization] inputs: [input.64 -> (-1, 256)[FLOAT]], [blocks.2.m.qkv.bn.weight -> (256)[FLOAT]], [blocks.2.m.qkv.bn.bias -> (256)[FLOAT]], [blocks.2.m.qkv.bn.running_mean -> (256)[FLOAT]], [blocks.2.m.qkv.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_79 for ONNX node: BatchNormalization_79\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_511 for ONNX tensor: onnx::Reshape_511\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_79 [BatchNormalization] outputs: [onnx::Reshape_511 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_80 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_509\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_80 [Shape] inputs: [onnx::Flatten_509 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_80 for ONNX node: Shape_80\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_512 for ONNX tensor: onnx::Reshape_512\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_80 [Shape] outputs: [onnx::Reshape_512 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_81 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_511\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_512\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_81 [Reshape] inputs: [onnx::Reshape_511 -> (-1, 256)[FLOAT]], [onnx::Reshape_512 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_81 for ONNX node: Reshape_81\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_513 for ONNX tensor: onnx::Reshape_513\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_81 [Reshape] outputs: [onnx::Reshape_513 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_82 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_504\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_82 [Unsqueeze] inputs: [onnx::Unsqueeze_504 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_82 for ONNX node: Unsqueeze_82\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_516 for ONNX tensor: onnx::Concat_516\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_82 [Unsqueeze] outputs: [onnx::Concat_516 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_83 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_507\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_83 [Unsqueeze] inputs: [onnx::Unsqueeze_507 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_83 for ONNX node: Unsqueeze_83\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_517 for ONNX tensor: onnx::Concat_517\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_83 [Unsqueeze] outputs: [onnx::Concat_517 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_84 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_516\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_517\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1450\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1451\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_84 [Concat] inputs: [onnx::Concat_516 -> (1)[INT32]], [onnx::Concat_517 -> (1)[INT32]], [onnx::Concat_1450 -> (1)[INT32]], [onnx::Concat_1451 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1450 for ONNX node: onnx::Concat_1450\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1451 for ONNX node: onnx::Concat_1451\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_84 for ONNX node: Concat_84\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_520 for ONNX tensor: onnx::Reshape_520\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_84 [Concat] outputs: [onnx::Reshape_520 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_85 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_513\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_520\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_85 [Reshape] inputs: [onnx::Reshape_513 -> (-1, 196, 256)[FLOAT]], [onnx::Reshape_520 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_85 for ONNX node: Reshape_85\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Split_521 for ONNX tensor: onnx::Split_521\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_85 [Reshape] outputs: [onnx::Split_521 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Split_86 [Split]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Split_521\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_86 [Split] inputs: [onnx::Split_521 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_86 for ONNX node: Split_86\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_86_111 for ONNX node: Split_86\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_86_113 for ONNX node: Split_86\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_522 for ONNX tensor: onnx::Transpose_522\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_523 for ONNX tensor: onnx::Transpose_523\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_524 for ONNX tensor: onnx::Transpose_524\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_86 [Split] outputs: [onnx::Transpose_522 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_523 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_524 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_87 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_522\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_87 [Transpose] inputs: [onnx::Transpose_522 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_87 for ONNX node: Transpose_87\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_525 for ONNX tensor: onnx::MatMul_525\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_87 [Transpose] outputs: [onnx::MatMul_525 -> (-1, 4, 196, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_88 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_524\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_88 [Transpose] inputs: [onnx::Transpose_524 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_88 for ONNX node: Transpose_88\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_526 for ONNX tensor: onnx::MatMul_526\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_88 [Transpose] outputs: [onnx::MatMul_526 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_89 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_523\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_89 [Transpose] inputs: [onnx::Transpose_523 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_89 for ONNX node: Transpose_89\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_527 for ONNX tensor: onnx::MatMul_527\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_89 [Transpose] outputs: [onnx::MatMul_527 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_90 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_525\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_527\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_90 [MatMul] inputs: [onnx::MatMul_525 -> (-1, 4, 196, 16)[FLOAT]], [onnx::MatMul_527 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_90 for ONNX node: MatMul_90\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_528 for ONNX tensor: onnx::Mul_528\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_90 [MatMul] outputs: [onnx::Mul_528 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_91 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_91 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_91 [Constant] outputs: [onnx::Mul_529 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_92 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_528\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_529\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_92 [Mul] inputs: [onnx::Mul_528 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Mul_529 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Mul_529 for ONNX node: onnx::Mul_529\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_92 for ONNX node: Mul_92\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_530 for ONNX tensor: onnx::Add_530\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_92 [Mul] outputs: [onnx::Add_530 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_93 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_93 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_93 [Constant] outputs: [onnx::Add_531 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_94 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_530\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_531\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_94 [Add] inputs: [onnx::Add_530 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Add_531 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Add_531 for ONNX node: onnx::Add_531\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_94 for ONNX node: Add_94\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Softmax_532 for ONNX tensor: onnx::Softmax_532\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_94 [Add] outputs: [onnx::Softmax_532 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Softmax_95 [Softmax]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Softmax_532\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_95 [Softmax] inputs: [onnx::Softmax_532 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Softmax_95 for ONNX node: Softmax_95\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_533 for ONNX tensor: onnx::MatMul_533\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_95 [Softmax] outputs: [onnx::MatMul_533 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_96 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_533\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_526\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_96 [MatMul] inputs: [onnx::MatMul_533 -> (-1, 4, 196, 196)[FLOAT]], [onnx::MatMul_526 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_96 for ONNX node: MatMul_96\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_534 for ONNX tensor: onnx::Transpose_534\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_96 [MatMul] outputs: [onnx::Transpose_534 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_97 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_534\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_97 [Transpose] inputs: [onnx::Transpose_534 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_97 for ONNX node: Transpose_97\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_535 for ONNX tensor: onnx::Reshape_535\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_97 [Transpose] outputs: [onnx::Reshape_535 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_98 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_504\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_98 [Unsqueeze] inputs: [onnx::Unsqueeze_504 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_98 for ONNX node: Unsqueeze_98\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_537 for ONNX tensor: onnx::Concat_537\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_98 [Unsqueeze] outputs: [onnx::Concat_537 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_99 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_507\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_99 [Unsqueeze] inputs: [onnx::Unsqueeze_507 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_99 for ONNX node: Unsqueeze_99\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_538 for ONNX tensor: onnx::Concat_538\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_99 [Unsqueeze] outputs: [onnx::Concat_538 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_100 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_537\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_538\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1452\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_100 [Concat] inputs: [onnx::Concat_537 -> (1)[INT32]], [onnx::Concat_538 -> (1)[INT32]], [onnx::Concat_1452 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1452 for ONNX node: onnx::Concat_1452\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_100 for ONNX node: Concat_100\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_540 for ONNX tensor: onnx::Reshape_540\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_100 [Concat] outputs: [onnx::Reshape_540 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_101 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_535\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_540\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_101 [Reshape] inputs: [onnx::Reshape_535 -> (-1, 196, 4, 32)[FLOAT]], [onnx::Reshape_540 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_101 for ONNX node: Reshape_101\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.68 for ONNX tensor: input.68\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_101 [Reshape] outputs: [input.68 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_102 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.68\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_102 [HardSigmoid] inputs: [input.68 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_102 for ONNX node: HardSigmoid_102\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_542 for ONNX tensor: onnx::Mul_542\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_102 [HardSigmoid] outputs: [onnx::Mul_542 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_103 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.68\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_542\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_103 [Mul] inputs: [input.68 -> (-1, 196, 128)[FLOAT]], [onnx::Mul_542 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_103 for ONNX node: Mul_103\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_543 for ONNX tensor: onnx::MatMul_543\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_103 [Mul] outputs: [onnx::MatMul_543 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_104 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_543\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1453\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_104 [MatMul] inputs: [onnx::MatMul_543 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1453 -> (128, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1453 for ONNX node: onnx::MatMul_1453\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_104 for ONNX node: MatMul_104\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_545 for ONNX tensor: onnx::Flatten_545\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_104 [MatMul] outputs: [onnx::Flatten_545 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_105 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_545\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_105 [Flatten] inputs: [onnx::Flatten_545 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_105 for ONNX node: Flatten_105\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.72 for ONNX tensor: input.72\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_105 [Flatten] outputs: [input.72 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_106 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.72\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.2.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_106 [BatchNormalization] inputs: [input.72 -> (-1, 128)[FLOAT]], [blocks.2.m.proj.1.bn.weight -> (128)[FLOAT]], [blocks.2.m.proj.1.bn.bias -> (128)[FLOAT]], [blocks.2.m.proj.1.bn.running_mean -> (128)[FLOAT]], [blocks.2.m.proj.1.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_106 for ONNX node: BatchNormalization_106\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_547 for ONNX tensor: onnx::Reshape_547\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_106 [BatchNormalization] outputs: [onnx::Reshape_547 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_107 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_545\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_107 [Shape] inputs: [onnx::Flatten_545 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_107 for ONNX node: Shape_107\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_548 for ONNX tensor: onnx::Reshape_548\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_107 [Shape] outputs: [onnx::Reshape_548 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_108 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_547\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_548\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_108 [Reshape] inputs: [onnx::Reshape_547 -> (-1, 128)[FLOAT]], [onnx::Reshape_548 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_108 for ONNX node: Reshape_108\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_549 for ONNX tensor: onnx::Add_549\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_108 [Reshape] outputs: [onnx::Add_549 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_109 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_501\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_549\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_109 [Add] inputs: [onnx::Shape_501 -> (-1, 196, 128)[FLOAT]], [onnx::Add_549 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_109 for ONNX node: Add_109\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_550 for ONNX tensor: onnx::MatMul_550\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_109 [Add] outputs: [onnx::MatMul_550 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_110 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_550\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1454\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_110 [MatMul] inputs: [onnx::MatMul_550 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1454 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1454 for ONNX node: onnx::MatMul_1454\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_110 for ONNX node: MatMul_110\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_552 for ONNX tensor: onnx::Flatten_552\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_110 [MatMul] outputs: [onnx::Flatten_552 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_111 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_552\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_111 [Flatten] inputs: [onnx::Flatten_552 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_111 for ONNX node: Flatten_111\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.76 for ONNX tensor: input.76\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_111 [Flatten] outputs: [input.76 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_112 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.76\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_112 [BatchNormalization] inputs: [input.76 -> (-1, 256)[FLOAT]], [blocks.3.m.0.bn.weight -> (256)[FLOAT]], [blocks.3.m.0.bn.bias -> (256)[FLOAT]], [blocks.3.m.0.bn.running_mean -> (256)[FLOAT]], [blocks.3.m.0.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_112 for ONNX node: BatchNormalization_112\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_554 for ONNX tensor: onnx::Reshape_554\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_112 [BatchNormalization] outputs: [onnx::Reshape_554 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_113 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_552\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_113 [Shape] inputs: [onnx::Flatten_552 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_113 for ONNX node: Shape_113\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_555 for ONNX tensor: onnx::Reshape_555\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_113 [Shape] outputs: [onnx::Reshape_555 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_114 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_554\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_555\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_114 [Reshape] inputs: [onnx::Reshape_554 -> (-1, 256)[FLOAT]], [onnx::Reshape_555 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_114 for ONNX node: Reshape_114\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.80 for ONNX tensor: input.80\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_114 [Reshape] outputs: [input.80 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_115 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.80\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_115 [HardSigmoid] inputs: [input.80 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_115 for ONNX node: HardSigmoid_115\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_557 for ONNX tensor: onnx::Mul_557\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_115 [HardSigmoid] outputs: [onnx::Mul_557 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_116 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.80\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_557\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_116 [Mul] inputs: [input.80 -> (-1, 196, 256)[FLOAT]], [onnx::Mul_557 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_116 for ONNX node: Mul_116\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_558 for ONNX tensor: onnx::MatMul_558\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_116 [Mul] outputs: [onnx::MatMul_558 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_117 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_558\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1455\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_117 [MatMul] inputs: [onnx::MatMul_558 -> (-1, 196, 256)[FLOAT]], [onnx::MatMul_1455 -> (256, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1455 for ONNX node: onnx::MatMul_1455\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_117 for ONNX node: MatMul_117\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_560 for ONNX tensor: onnx::Flatten_560\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_117 [MatMul] outputs: [onnx::Flatten_560 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_118 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_560\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_118 [Flatten] inputs: [onnx::Flatten_560 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_118 for ONNX node: Flatten_118\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.84 for ONNX tensor: input.84\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_118 [Flatten] outputs: [input.84 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_119 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.84\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.3.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_119 [BatchNormalization] inputs: [input.84 -> (-1, 128)[FLOAT]], [blocks.3.m.2.bn.weight -> (128)[FLOAT]], [blocks.3.m.2.bn.bias -> (128)[FLOAT]], [blocks.3.m.2.bn.running_mean -> (128)[FLOAT]], [blocks.3.m.2.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_119 for ONNX node: BatchNormalization_119\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_562 for ONNX tensor: onnx::Reshape_562\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_119 [BatchNormalization] outputs: [onnx::Reshape_562 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_120 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_560\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_120 [Shape] inputs: [onnx::Flatten_560 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_120 for ONNX node: Shape_120\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_563 for ONNX tensor: onnx::Reshape_563\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_120 [Shape] outputs: [onnx::Reshape_563 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_121 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_562\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_563\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_121 [Reshape] inputs: [onnx::Reshape_562 -> (-1, 128)[FLOAT]], [onnx::Reshape_563 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_121 for ONNX node: Reshape_121\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_564 for ONNX tensor: onnx::Add_564\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_121 [Reshape] outputs: [onnx::Add_564 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_122 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_550\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_564\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_122 [Add] inputs: [onnx::MatMul_550 -> (-1, 196, 128)[FLOAT]], [onnx::Add_564 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_122 for ONNX node: Add_122\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Shape_565 for ONNX tensor: onnx::Shape_565\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_122 [Add] outputs: [onnx::Shape_565 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_123 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_565\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_123 [Shape] inputs: [onnx::Shape_565 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_123 for ONNX node: Shape_123\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_566 for ONNX tensor: onnx::Gather_566\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_123 [Shape] outputs: [onnx::Gather_566 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_124 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_124 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_124 [Constant] outputs: [onnx::Gather_567 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_125 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_566\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_567\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_125 [Gather] inputs: [onnx::Gather_566 -> (3)[INT32]], [onnx::Gather_567 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_567 for ONNX node: onnx::Gather_567\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_125 for ONNX node: Gather_125\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_568 for ONNX tensor: onnx::Unsqueeze_568\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_125 [Gather] outputs: [onnx::Unsqueeze_568 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_126 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_565\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_126 [Shape] inputs: [onnx::Shape_565 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_126 for ONNX node: Shape_126\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_569 for ONNX tensor: onnx::Gather_569\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_126 [Shape] outputs: [onnx::Gather_569 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_127 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_127 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_127 [Constant] outputs: [onnx::Gather_570 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_128 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_569\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_570\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_128 [Gather] inputs: [onnx::Gather_569 -> (3)[INT32]], [onnx::Gather_570 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_570 for ONNX node: onnx::Gather_570\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_128 for ONNX node: Gather_128\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_571 for ONNX tensor: onnx::Unsqueeze_571\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_128 [Gather] outputs: [onnx::Unsqueeze_571 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_129 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_565\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1456\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_129 [MatMul] inputs: [onnx::Shape_565 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1456 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1456 for ONNX node: onnx::MatMul_1456\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_129 for ONNX node: MatMul_129\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_573 for ONNX tensor: onnx::Flatten_573\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_129 [MatMul] outputs: [onnx::Flatten_573 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_130 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_573\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_130 [Flatten] inputs: [onnx::Flatten_573 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_130 for ONNX node: Flatten_130\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.88 for ONNX tensor: input.88\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_130 [Flatten] outputs: [input.88 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_131 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.88\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_131 [BatchNormalization] inputs: [input.88 -> (-1, 256)[FLOAT]], [blocks.4.m.qkv.bn.weight -> (256)[FLOAT]], [blocks.4.m.qkv.bn.bias -> (256)[FLOAT]], [blocks.4.m.qkv.bn.running_mean -> (256)[FLOAT]], [blocks.4.m.qkv.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_131 for ONNX node: BatchNormalization_131\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_575 for ONNX tensor: onnx::Reshape_575\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_131 [BatchNormalization] outputs: [onnx::Reshape_575 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_132 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_573\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_132 [Shape] inputs: [onnx::Flatten_573 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_132 for ONNX node: Shape_132\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_576 for ONNX tensor: onnx::Reshape_576\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_132 [Shape] outputs: [onnx::Reshape_576 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_133 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_575\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_576\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_133 [Reshape] inputs: [onnx::Reshape_575 -> (-1, 256)[FLOAT]], [onnx::Reshape_576 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_133 for ONNX node: Reshape_133\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_577 for ONNX tensor: onnx::Reshape_577\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_133 [Reshape] outputs: [onnx::Reshape_577 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_134 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_568\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_134 [Unsqueeze] inputs: [onnx::Unsqueeze_568 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_134 for ONNX node: Unsqueeze_134\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_580 for ONNX tensor: onnx::Concat_580\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_134 [Unsqueeze] outputs: [onnx::Concat_580 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_135 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_571\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_135 [Unsqueeze] inputs: [onnx::Unsqueeze_571 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_135 for ONNX node: Unsqueeze_135\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_581 for ONNX tensor: onnx::Concat_581\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_135 [Unsqueeze] outputs: [onnx::Concat_581 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_136 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_580\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_581\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1457\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1458\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_136 [Concat] inputs: [onnx::Concat_580 -> (1)[INT32]], [onnx::Concat_581 -> (1)[INT32]], [onnx::Concat_1457 -> (1)[INT32]], [onnx::Concat_1458 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1457 for ONNX node: onnx::Concat_1457\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1458 for ONNX node: onnx::Concat_1458\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_136 for ONNX node: Concat_136\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_584 for ONNX tensor: onnx::Reshape_584\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_136 [Concat] outputs: [onnx::Reshape_584 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_137 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_577\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_584\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_137 [Reshape] inputs: [onnx::Reshape_577 -> (-1, 196, 256)[FLOAT]], [onnx::Reshape_584 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_137 for ONNX node: Reshape_137\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Split_585 for ONNX tensor: onnx::Split_585\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_137 [Reshape] outputs: [onnx::Split_585 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Split_138 [Split]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Split_585\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_138 [Split] inputs: [onnx::Split_585 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_138 for ONNX node: Split_138\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_138_151 for ONNX node: Split_138\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_138_153 for ONNX node: Split_138\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_586 for ONNX tensor: onnx::Transpose_586\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_587 for ONNX tensor: onnx::Transpose_587\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_588 for ONNX tensor: onnx::Transpose_588\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_138 [Split] outputs: [onnx::Transpose_586 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_587 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_588 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_139 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_586\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_139 [Transpose] inputs: [onnx::Transpose_586 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_139 for ONNX node: Transpose_139\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_589 for ONNX tensor: onnx::MatMul_589\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_139 [Transpose] outputs: [onnx::MatMul_589 -> (-1, 4, 196, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_140 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_588\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_140 [Transpose] inputs: [onnx::Transpose_588 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_140 for ONNX node: Transpose_140\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_590 for ONNX tensor: onnx::MatMul_590\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_140 [Transpose] outputs: [onnx::MatMul_590 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_141 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_587\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_141 [Transpose] inputs: [onnx::Transpose_587 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_141 for ONNX node: Transpose_141\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_591 for ONNX tensor: onnx::MatMul_591\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_141 [Transpose] outputs: [onnx::MatMul_591 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_142 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_589\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_591\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_142 [MatMul] inputs: [onnx::MatMul_589 -> (-1, 4, 196, 16)[FLOAT]], [onnx::MatMul_591 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_142 for ONNX node: MatMul_142\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_592 for ONNX tensor: onnx::Mul_592\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_142 [MatMul] outputs: [onnx::Mul_592 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_143 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_143 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_143 [Constant] outputs: [onnx::Mul_593 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_144 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_592\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_593\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_144 [Mul] inputs: [onnx::Mul_592 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Mul_593 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Mul_593 for ONNX node: onnx::Mul_593\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_144 for ONNX node: Mul_144\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_594 for ONNX tensor: onnx::Add_594\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_144 [Mul] outputs: [onnx::Add_594 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_145 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_145 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_145 [Constant] outputs: [onnx::Add_595 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_146 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_594\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_595\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_146 [Add] inputs: [onnx::Add_594 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Add_595 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Add_595 for ONNX node: onnx::Add_595\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_146 for ONNX node: Add_146\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Softmax_596 for ONNX tensor: onnx::Softmax_596\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_146 [Add] outputs: [onnx::Softmax_596 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Softmax_147 [Softmax]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Softmax_596\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_147 [Softmax] inputs: [onnx::Softmax_596 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Softmax_147 for ONNX node: Softmax_147\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_597 for ONNX tensor: onnx::MatMul_597\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_147 [Softmax] outputs: [onnx::MatMul_597 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_148 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_597\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_590\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_148 [MatMul] inputs: [onnx::MatMul_597 -> (-1, 4, 196, 196)[FLOAT]], [onnx::MatMul_590 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_148 for ONNX node: MatMul_148\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_598 for ONNX tensor: onnx::Transpose_598\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_148 [MatMul] outputs: [onnx::Transpose_598 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_149 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_598\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_149 [Transpose] inputs: [onnx::Transpose_598 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_149 for ONNX node: Transpose_149\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_599 for ONNX tensor: onnx::Reshape_599\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_149 [Transpose] outputs: [onnx::Reshape_599 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_150 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_568\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_150 [Unsqueeze] inputs: [onnx::Unsqueeze_568 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_150 for ONNX node: Unsqueeze_150\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_601 for ONNX tensor: onnx::Concat_601\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_150 [Unsqueeze] outputs: [onnx::Concat_601 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_151 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_571\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_151 [Unsqueeze] inputs: [onnx::Unsqueeze_571 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_151 for ONNX node: Unsqueeze_151\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_602 for ONNX tensor: onnx::Concat_602\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_151 [Unsqueeze] outputs: [onnx::Concat_602 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_152 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_601\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_602\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1459\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_152 [Concat] inputs: [onnx::Concat_601 -> (1)[INT32]], [onnx::Concat_602 -> (1)[INT32]], [onnx::Concat_1459 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1459 for ONNX node: onnx::Concat_1459\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_152 for ONNX node: Concat_152\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_604 for ONNX tensor: onnx::Reshape_604\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_152 [Concat] outputs: [onnx::Reshape_604 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_153 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_599\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_604\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_153 [Reshape] inputs: [onnx::Reshape_599 -> (-1, 196, 4, 32)[FLOAT]], [onnx::Reshape_604 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_153 for ONNX node: Reshape_153\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.92 for ONNX tensor: input.92\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_153 [Reshape] outputs: [input.92 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_154 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.92\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_154 [HardSigmoid] inputs: [input.92 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_154 for ONNX node: HardSigmoid_154\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_606 for ONNX tensor: onnx::Mul_606\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_154 [HardSigmoid] outputs: [onnx::Mul_606 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_155 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.92\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_606\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_155 [Mul] inputs: [input.92 -> (-1, 196, 128)[FLOAT]], [onnx::Mul_606 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_155 for ONNX node: Mul_155\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_607 for ONNX tensor: onnx::MatMul_607\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_155 [Mul] outputs: [onnx::MatMul_607 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_156 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_607\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1460\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_156 [MatMul] inputs: [onnx::MatMul_607 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1460 -> (128, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1460 for ONNX node: onnx::MatMul_1460\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_156 for ONNX node: MatMul_156\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_609 for ONNX tensor: onnx::Flatten_609\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_156 [MatMul] outputs: [onnx::Flatten_609 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_157 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_609\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_157 [Flatten] inputs: [onnx::Flatten_609 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_157 for ONNX node: Flatten_157\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.96 for ONNX tensor: input.96\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_157 [Flatten] outputs: [input.96 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_158 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.96\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.4.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_158 [BatchNormalization] inputs: [input.96 -> (-1, 128)[FLOAT]], [blocks.4.m.proj.1.bn.weight -> (128)[FLOAT]], [blocks.4.m.proj.1.bn.bias -> (128)[FLOAT]], [blocks.4.m.proj.1.bn.running_mean -> (128)[FLOAT]], [blocks.4.m.proj.1.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_158 for ONNX node: BatchNormalization_158\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_611 for ONNX tensor: onnx::Reshape_611\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_158 [BatchNormalization] outputs: [onnx::Reshape_611 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_159 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_609\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_159 [Shape] inputs: [onnx::Flatten_609 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_159 for ONNX node: Shape_159\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_612 for ONNX tensor: onnx::Reshape_612\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_159 [Shape] outputs: [onnx::Reshape_612 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_160 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_611\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_612\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_160 [Reshape] inputs: [onnx::Reshape_611 -> (-1, 128)[FLOAT]], [onnx::Reshape_612 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_160 for ONNX node: Reshape_160\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_613 for ONNX tensor: onnx::Add_613\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_160 [Reshape] outputs: [onnx::Add_613 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_161 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_565\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_613\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_161 [Add] inputs: [onnx::Shape_565 -> (-1, 196, 128)[FLOAT]], [onnx::Add_613 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_161 for ONNX node: Add_161\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_614 for ONNX tensor: onnx::MatMul_614\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_161 [Add] outputs: [onnx::MatMul_614 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_162 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_614\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1461\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_162 [MatMul] inputs: [onnx::MatMul_614 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1461 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1461 for ONNX node: onnx::MatMul_1461\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_162 for ONNX node: MatMul_162\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_616 for ONNX tensor: onnx::Flatten_616\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_162 [MatMul] outputs: [onnx::Flatten_616 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_163 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_616\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_163 [Flatten] inputs: [onnx::Flatten_616 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_163 for ONNX node: Flatten_163\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.100 for ONNX tensor: input.100\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_163 [Flatten] outputs: [input.100 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_164 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.100\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_164 [BatchNormalization] inputs: [input.100 -> (-1, 256)[FLOAT]], [blocks.5.m.0.bn.weight -> (256)[FLOAT]], [blocks.5.m.0.bn.bias -> (256)[FLOAT]], [blocks.5.m.0.bn.running_mean -> (256)[FLOAT]], [blocks.5.m.0.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_164 for ONNX node: BatchNormalization_164\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_618 for ONNX tensor: onnx::Reshape_618\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_164 [BatchNormalization] outputs: [onnx::Reshape_618 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_165 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_616\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_165 [Shape] inputs: [onnx::Flatten_616 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_165 for ONNX node: Shape_165\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_619 for ONNX tensor: onnx::Reshape_619\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_165 [Shape] outputs: [onnx::Reshape_619 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_166 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_618\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_619\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_166 [Reshape] inputs: [onnx::Reshape_618 -> (-1, 256)[FLOAT]], [onnx::Reshape_619 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_166 for ONNX node: Reshape_166\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.104 for ONNX tensor: input.104\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_166 [Reshape] outputs: [input.104 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_167 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.104\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_167 [HardSigmoid] inputs: [input.104 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_167 for ONNX node: HardSigmoid_167\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_621 for ONNX tensor: onnx::Mul_621\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_167 [HardSigmoid] outputs: [onnx::Mul_621 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_168 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.104\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_621\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_168 [Mul] inputs: [input.104 -> (-1, 196, 256)[FLOAT]], [onnx::Mul_621 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_168 for ONNX node: Mul_168\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_622 for ONNX tensor: onnx::MatMul_622\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_168 [Mul] outputs: [onnx::MatMul_622 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_169 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_622\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1462\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_169 [MatMul] inputs: [onnx::MatMul_622 -> (-1, 196, 256)[FLOAT]], [onnx::MatMul_1462 -> (256, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1462 for ONNX node: onnx::MatMul_1462\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_169 for ONNX node: MatMul_169\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_624 for ONNX tensor: onnx::Flatten_624\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_169 [MatMul] outputs: [onnx::Flatten_624 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_170 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_624\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_170 [Flatten] inputs: [onnx::Flatten_624 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_170 for ONNX node: Flatten_170\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.108 for ONNX tensor: input.108\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_170 [Flatten] outputs: [input.108 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_171 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.108\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.5.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_171 [BatchNormalization] inputs: [input.108 -> (-1, 128)[FLOAT]], [blocks.5.m.2.bn.weight -> (128)[FLOAT]], [blocks.5.m.2.bn.bias -> (128)[FLOAT]], [blocks.5.m.2.bn.running_mean -> (128)[FLOAT]], [blocks.5.m.2.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_171 for ONNX node: BatchNormalization_171\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_626 for ONNX tensor: onnx::Reshape_626\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_171 [BatchNormalization] outputs: [onnx::Reshape_626 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_172 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_624\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_172 [Shape] inputs: [onnx::Flatten_624 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_172 for ONNX node: Shape_172\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_627 for ONNX tensor: onnx::Reshape_627\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_172 [Shape] outputs: [onnx::Reshape_627 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_173 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_626\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_627\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_173 [Reshape] inputs: [onnx::Reshape_626 -> (-1, 128)[FLOAT]], [onnx::Reshape_627 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_173 for ONNX node: Reshape_173\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_628 for ONNX tensor: onnx::Add_628\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_173 [Reshape] outputs: [onnx::Add_628 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_174 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_614\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_628\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_174 [Add] inputs: [onnx::MatMul_614 -> (-1, 196, 128)[FLOAT]], [onnx::Add_628 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_174 for ONNX node: Add_174\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Shape_629 for ONNX tensor: onnx::Shape_629\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_174 [Add] outputs: [onnx::Shape_629 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_175 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_629\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_175 [Shape] inputs: [onnx::Shape_629 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_175 for ONNX node: Shape_175\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_630 for ONNX tensor: onnx::Gather_630\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_175 [Shape] outputs: [onnx::Gather_630 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_176 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_176 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_176 [Constant] outputs: [onnx::Gather_631 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_177 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_630\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_631\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_177 [Gather] inputs: [onnx::Gather_630 -> (3)[INT32]], [onnx::Gather_631 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_631 for ONNX node: onnx::Gather_631\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_177 for ONNX node: Gather_177\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_632 for ONNX tensor: onnx::Unsqueeze_632\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_177 [Gather] outputs: [onnx::Unsqueeze_632 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_178 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_629\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_178 [Shape] inputs: [onnx::Shape_629 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_178 for ONNX node: Shape_178\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_633 for ONNX tensor: onnx::Gather_633\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_178 [Shape] outputs: [onnx::Gather_633 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_179 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_179 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_179 [Constant] outputs: [onnx::Gather_634 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_180 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_633\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_634\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_180 [Gather] inputs: [onnx::Gather_633 -> (3)[INT32]], [onnx::Gather_634 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_634 for ONNX node: onnx::Gather_634\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_180 for ONNX node: Gather_180\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_635 for ONNX tensor: onnx::Unsqueeze_635\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_180 [Gather] outputs: [onnx::Unsqueeze_635 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_181 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_629\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1463\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_181 [MatMul] inputs: [onnx::Shape_629 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1463 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1463 for ONNX node: onnx::MatMul_1463\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_181 for ONNX node: MatMul_181\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_637 for ONNX tensor: onnx::Flatten_637\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_181 [MatMul] outputs: [onnx::Flatten_637 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_182 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_637\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_182 [Flatten] inputs: [onnx::Flatten_637 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_182 for ONNX node: Flatten_182\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.112 for ONNX tensor: input.112\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_182 [Flatten] outputs: [input.112 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_183 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.112\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_183 [BatchNormalization] inputs: [input.112 -> (-1, 256)[FLOAT]], [blocks.6.m.qkv.bn.weight -> (256)[FLOAT]], [blocks.6.m.qkv.bn.bias -> (256)[FLOAT]], [blocks.6.m.qkv.bn.running_mean -> (256)[FLOAT]], [blocks.6.m.qkv.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_183 for ONNX node: BatchNormalization_183\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_639 for ONNX tensor: onnx::Reshape_639\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_183 [BatchNormalization] outputs: [onnx::Reshape_639 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_184 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_637\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_184 [Shape] inputs: [onnx::Flatten_637 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_184 for ONNX node: Shape_184\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_640 for ONNX tensor: onnx::Reshape_640\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_184 [Shape] outputs: [onnx::Reshape_640 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_185 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_639\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_640\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_185 [Reshape] inputs: [onnx::Reshape_639 -> (-1, 256)[FLOAT]], [onnx::Reshape_640 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_185 for ONNX node: Reshape_185\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_641 for ONNX tensor: onnx::Reshape_641\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_185 [Reshape] outputs: [onnx::Reshape_641 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_186 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_632\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_186 [Unsqueeze] inputs: [onnx::Unsqueeze_632 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_186 for ONNX node: Unsqueeze_186\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_644 for ONNX tensor: onnx::Concat_644\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_186 [Unsqueeze] outputs: [onnx::Concat_644 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_187 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_635\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_187 [Unsqueeze] inputs: [onnx::Unsqueeze_635 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_187 for ONNX node: Unsqueeze_187\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_645 for ONNX tensor: onnx::Concat_645\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_187 [Unsqueeze] outputs: [onnx::Concat_645 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_188 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_644\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_645\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1464\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1465\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_188 [Concat] inputs: [onnx::Concat_644 -> (1)[INT32]], [onnx::Concat_645 -> (1)[INT32]], [onnx::Concat_1464 -> (1)[INT32]], [onnx::Concat_1465 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1464 for ONNX node: onnx::Concat_1464\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1465 for ONNX node: onnx::Concat_1465\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_188 for ONNX node: Concat_188\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_648 for ONNX tensor: onnx::Reshape_648\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_188 [Concat] outputs: [onnx::Reshape_648 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_189 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_641\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_648\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_189 [Reshape] inputs: [onnx::Reshape_641 -> (-1, 196, 256)[FLOAT]], [onnx::Reshape_648 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_189 for ONNX node: Reshape_189\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Split_649 for ONNX tensor: onnx::Split_649\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_189 [Reshape] outputs: [onnx::Split_649 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Split_190 [Split]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Split_649\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_190 [Split] inputs: [onnx::Split_649 -> (-1, 196, 4, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_190 for ONNX node: Split_190\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_190_191 for ONNX node: Split_190\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_190_193 for ONNX node: Split_190\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_650 for ONNX tensor: onnx::Transpose_650\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_651 for ONNX tensor: onnx::Transpose_651\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_652 for ONNX tensor: onnx::Transpose_652\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_190 [Split] outputs: [onnx::Transpose_650 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_651 -> (-1, 196, 4, 16)[FLOAT]], [onnx::Transpose_652 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_191 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_650\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_191 [Transpose] inputs: [onnx::Transpose_650 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_191 for ONNX node: Transpose_191\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_653 for ONNX tensor: onnx::MatMul_653\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_191 [Transpose] outputs: [onnx::MatMul_653 -> (-1, 4, 196, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_192 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_652\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_192 [Transpose] inputs: [onnx::Transpose_652 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_192 for ONNX node: Transpose_192\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_654 for ONNX tensor: onnx::MatMul_654\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_192 [Transpose] outputs: [onnx::MatMul_654 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_193 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_651\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_193 [Transpose] inputs: [onnx::Transpose_651 -> (-1, 196, 4, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_193 for ONNX node: Transpose_193\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_655 for ONNX tensor: onnx::MatMul_655\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_193 [Transpose] outputs: [onnx::MatMul_655 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_194 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_653\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_655\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_194 [MatMul] inputs: [onnx::MatMul_653 -> (-1, 4, 196, 16)[FLOAT]], [onnx::MatMul_655 -> (-1, 4, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_194 for ONNX node: MatMul_194\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_656 for ONNX tensor: onnx::Mul_656\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_194 [MatMul] outputs: [onnx::Mul_656 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_195 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_195 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_195 [Constant] outputs: [onnx::Mul_657 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_196 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_656\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_657\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_196 [Mul] inputs: [onnx::Mul_656 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Mul_657 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Mul_657 for ONNX node: onnx::Mul_657\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_196 for ONNX node: Mul_196\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_658 for ONNX tensor: onnx::Add_658\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_196 [Mul] outputs: [onnx::Add_658 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_197 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_197 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_197 [Constant] outputs: [onnx::Add_659 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_198 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_658\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_659\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_198 [Add] inputs: [onnx::Add_658 -> (-1, 4, 196, 196)[FLOAT]], [onnx::Add_659 -> (4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Add_659 for ONNX node: onnx::Add_659\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_198 for ONNX node: Add_198\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Softmax_660 for ONNX tensor: onnx::Softmax_660\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_198 [Add] outputs: [onnx::Softmax_660 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Softmax_199 [Softmax]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Softmax_660\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_199 [Softmax] inputs: [onnx::Softmax_660 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Softmax_199 for ONNX node: Softmax_199\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_661 for ONNX tensor: onnx::MatMul_661\n",
      "[05/24/2022-15:21:29] [TRT] [V] Softmax_199 [Softmax] outputs: [onnx::MatMul_661 -> (-1, 4, 196, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_200 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_661\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_654\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_200 [MatMul] inputs: [onnx::MatMul_661 -> (-1, 4, 196, 196)[FLOAT]], [onnx::MatMul_654 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_200 for ONNX node: MatMul_200\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_662 for ONNX tensor: onnx::Transpose_662\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_200 [MatMul] outputs: [onnx::Transpose_662 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_201 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_662\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_201 [Transpose] inputs: [onnx::Transpose_662 -> (-1, 4, 196, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_201 for ONNX node: Transpose_201\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_663 for ONNX tensor: onnx::Reshape_663\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_201 [Transpose] outputs: [onnx::Reshape_663 -> (-1, 196, 4, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_202 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_632\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_202 [Unsqueeze] inputs: [onnx::Unsqueeze_632 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_202 for ONNX node: Unsqueeze_202\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_665 for ONNX tensor: onnx::Concat_665\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_202 [Unsqueeze] outputs: [onnx::Concat_665 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_203 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_635\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_203 [Unsqueeze] inputs: [onnx::Unsqueeze_635 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_203 for ONNX node: Unsqueeze_203\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_666 for ONNX tensor: onnx::Concat_666\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_203 [Unsqueeze] outputs: [onnx::Concat_666 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_204 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_665\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_666\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1466\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_204 [Concat] inputs: [onnx::Concat_665 -> (1)[INT32]], [onnx::Concat_666 -> (1)[INT32]], [onnx::Concat_1466 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1466 for ONNX node: onnx::Concat_1466\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_204 for ONNX node: Concat_204\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_668 for ONNX tensor: onnx::Reshape_668\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_204 [Concat] outputs: [onnx::Reshape_668 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_205 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_663\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_668\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_205 [Reshape] inputs: [onnx::Reshape_663 -> (-1, 196, 4, 32)[FLOAT]], [onnx::Reshape_668 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_205 for ONNX node: Reshape_205\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.116 for ONNX tensor: input.116\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_205 [Reshape] outputs: [input.116 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_206 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.116\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_206 [HardSigmoid] inputs: [input.116 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_206 for ONNX node: HardSigmoid_206\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_670 for ONNX tensor: onnx::Mul_670\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_206 [HardSigmoid] outputs: [onnx::Mul_670 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_207 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.116\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_670\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_207 [Mul] inputs: [input.116 -> (-1, 196, 128)[FLOAT]], [onnx::Mul_670 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_207 for ONNX node: Mul_207\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_671 for ONNX tensor: onnx::MatMul_671\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_207 [Mul] outputs: [onnx::MatMul_671 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_208 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_671\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1467\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_208 [MatMul] inputs: [onnx::MatMul_671 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1467 -> (128, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1467 for ONNX node: onnx::MatMul_1467\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_208 for ONNX node: MatMul_208\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_673 for ONNX tensor: onnx::Flatten_673\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_208 [MatMul] outputs: [onnx::Flatten_673 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_209 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_673\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_209 [Flatten] inputs: [onnx::Flatten_673 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_209 for ONNX node: Flatten_209\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.120 for ONNX tensor: input.120\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_209 [Flatten] outputs: [input.120 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_210 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.120\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.6.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_210 [BatchNormalization] inputs: [input.120 -> (-1, 128)[FLOAT]], [blocks.6.m.proj.1.bn.weight -> (128)[FLOAT]], [blocks.6.m.proj.1.bn.bias -> (128)[FLOAT]], [blocks.6.m.proj.1.bn.running_mean -> (128)[FLOAT]], [blocks.6.m.proj.1.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_210 for ONNX node: BatchNormalization_210\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_675 for ONNX tensor: onnx::Reshape_675\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_210 [BatchNormalization] outputs: [onnx::Reshape_675 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_211 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_673\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_211 [Shape] inputs: [onnx::Flatten_673 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_211 for ONNX node: Shape_211\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_676 for ONNX tensor: onnx::Reshape_676\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_211 [Shape] outputs: [onnx::Reshape_676 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_212 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_675\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_676\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_212 [Reshape] inputs: [onnx::Reshape_675 -> (-1, 128)[FLOAT]], [onnx::Reshape_676 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_212 for ONNX node: Reshape_212\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_677 for ONNX tensor: onnx::Add_677\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_212 [Reshape] outputs: [onnx::Add_677 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_213 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_629\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_677\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_213 [Add] inputs: [onnx::Shape_629 -> (-1, 196, 128)[FLOAT]], [onnx::Add_677 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_213 for ONNX node: Add_213\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_678 for ONNX tensor: onnx::MatMul_678\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_213 [Add] outputs: [onnx::MatMul_678 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_214 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_678\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1468\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_214 [MatMul] inputs: [onnx::MatMul_678 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1468 -> (128, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1468 for ONNX node: onnx::MatMul_1468\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_214 for ONNX node: MatMul_214\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_680 for ONNX tensor: onnx::Flatten_680\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_214 [MatMul] outputs: [onnx::Flatten_680 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_215 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_680\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_215 [Flatten] inputs: [onnx::Flatten_680 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_215 for ONNX node: Flatten_215\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.124 for ONNX tensor: input.124\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_215 [Flatten] outputs: [input.124 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_216 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.124\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.0.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.0.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.0.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_216 [BatchNormalization] inputs: [input.124 -> (-1, 256)[FLOAT]], [blocks.7.m.0.bn.weight -> (256)[FLOAT]], [blocks.7.m.0.bn.bias -> (256)[FLOAT]], [blocks.7.m.0.bn.running_mean -> (256)[FLOAT]], [blocks.7.m.0.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_216 for ONNX node: BatchNormalization_216\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_682 for ONNX tensor: onnx::Reshape_682\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_216 [BatchNormalization] outputs: [onnx::Reshape_682 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_217 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_680\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_217 [Shape] inputs: [onnx::Flatten_680 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_217 for ONNX node: Shape_217\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_683 for ONNX tensor: onnx::Reshape_683\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_217 [Shape] outputs: [onnx::Reshape_683 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_218 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_682\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_683\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_218 [Reshape] inputs: [onnx::Reshape_682 -> (-1, 256)[FLOAT]], [onnx::Reshape_683 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_218 for ONNX node: Reshape_218\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.128 for ONNX tensor: input.128\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_218 [Reshape] outputs: [input.128 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: HardSigmoid_219 [HardSigmoid]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.128\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_219 [HardSigmoid] inputs: [input.128 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: HardSigmoid_219 for ONNX node: HardSigmoid_219\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Mul_685 for ONNX tensor: onnx::Mul_685\n",
      "[05/24/2022-15:21:29] [TRT] [V] HardSigmoid_219 [HardSigmoid] outputs: [onnx::Mul_685 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Mul_220 [Mul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.128\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Mul_685\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_220 [Mul] inputs: [input.128 -> (-1, 196, 256)[FLOAT]], [onnx::Mul_685 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Mul_220 for ONNX node: Mul_220\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_686 for ONNX tensor: onnx::MatMul_686\n",
      "[05/24/2022-15:21:29] [TRT] [V] Mul_220 [Mul] outputs: [onnx::MatMul_686 -> (-1, 196, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_221 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_686\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1469\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_221 [MatMul] inputs: [onnx::MatMul_686 -> (-1, 196, 256)[FLOAT]], [onnx::MatMul_1469 -> (256, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1469 for ONNX node: onnx::MatMul_1469\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_221 for ONNX node: MatMul_221\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_688 for ONNX tensor: onnx::Flatten_688\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_221 [MatMul] outputs: [onnx::Flatten_688 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_222 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_688\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_222 [Flatten] inputs: [onnx::Flatten_688 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_222 for ONNX node: Flatten_222\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.132 for ONNX tensor: input.132\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_222 [Flatten] outputs: [input.132 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_223 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.132\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.2.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.2.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.7.m.2.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_223 [BatchNormalization] inputs: [input.132 -> (-1, 128)[FLOAT]], [blocks.7.m.2.bn.weight -> (128)[FLOAT]], [blocks.7.m.2.bn.bias -> (128)[FLOAT]], [blocks.7.m.2.bn.running_mean -> (128)[FLOAT]], [blocks.7.m.2.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_223 for ONNX node: BatchNormalization_223\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_690 for ONNX tensor: onnx::Reshape_690\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_223 [BatchNormalization] outputs: [onnx::Reshape_690 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_224 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_688\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_224 [Shape] inputs: [onnx::Flatten_688 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_224 for ONNX node: Shape_224\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_691 for ONNX tensor: onnx::Reshape_691\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_224 [Shape] outputs: [onnx::Reshape_691 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_225 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_690\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_691\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_225 [Reshape] inputs: [onnx::Reshape_690 -> (-1, 128)[FLOAT]], [onnx::Reshape_691 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_225 for ONNX node: Reshape_225\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Add_692 for ONNX tensor: onnx::Add_692\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_225 [Reshape] outputs: [onnx::Add_692 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Add_226 [Add]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_678\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Add_692\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_226 [Add] inputs: [onnx::MatMul_678 -> (-1, 196, 128)[FLOAT]], [onnx::Add_692 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Add_226 for ONNX node: Add_226\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Shape_693 for ONNX tensor: onnx::Shape_693\n",
      "[05/24/2022-15:21:29] [TRT] [V] Add_226 [Add] outputs: [onnx::Shape_693 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_227 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_693\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_227 [Shape] inputs: [onnx::Shape_693 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_227 for ONNX node: Shape_227\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_694 for ONNX tensor: onnx::Gather_694\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_227 [Shape] outputs: [onnx::Gather_694 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_228 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_228 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_228 [Constant] outputs: [onnx::Gather_695 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_229 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_694\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_695\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_229 [Gather] inputs: [onnx::Gather_694 -> (3)[INT32]], [onnx::Gather_695 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_695 for ONNX node: onnx::Gather_695\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_229 for ONNX node: Gather_229\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_696 for ONNX tensor: onnx::Unsqueeze_696\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_229 [Gather] outputs: [onnx::Unsqueeze_696 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_230 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_693\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_230 [Shape] inputs: [onnx::Shape_693 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_230 for ONNX node: Shape_230\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_697 for ONNX tensor: onnx::Gather_697\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_230 [Shape] outputs: [onnx::Gather_697 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_231 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_231 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_231 [Constant] outputs: [onnx::Gather_698 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_232 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_697\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_698\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_232 [Gather] inputs: [onnx::Gather_697 -> (3)[INT32]], [onnx::Gather_698 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_698 for ONNX node: onnx::Gather_698\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_232 for ONNX node: Gather_232\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_699 for ONNX tensor: onnx::Unsqueeze_699\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_232 [Gather] outputs: [onnx::Unsqueeze_699 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: MatMul_233 [MatMul]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_693\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::MatMul_1470\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_233 [MatMul] inputs: [onnx::Shape_693 -> (-1, 196, 128)[FLOAT]], [onnx::MatMul_1470 -> (128, 640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::MatMul_1470 for ONNX node: onnx::MatMul_1470\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: MatMul_233 for ONNX node: MatMul_233\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Flatten_701 for ONNX tensor: onnx::Flatten_701\n",
      "[05/24/2022-15:21:29] [TRT] [V] MatMul_233 [MatMul] outputs: [onnx::Flatten_701 -> (-1, 196, 640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Flatten_234 [Flatten]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_701\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_234 [Flatten] inputs: [onnx::Flatten_701 -> (-1, 196, 640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Flatten_234 for ONNX node: Flatten_234\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: input.136 for ONNX tensor: input.136\n",
      "[05/24/2022-15:21:29] [TRT] [V] Flatten_234 [Flatten] outputs: [input.136 -> (-1, 640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: BatchNormalization_235 [BatchNormalization]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: input.136\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.8.kv.bn.weight\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.8.kv.bn.bias\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.8.kv.bn.running_mean\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: blocks.8.kv.bn.running_var\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_235 [BatchNormalization] inputs: [input.136 -> (-1, 640)[FLOAT]], [blocks.8.kv.bn.weight -> (640)[FLOAT]], [blocks.8.kv.bn.bias -> (640)[FLOAT]], [blocks.8.kv.bn.running_mean -> (640)[FLOAT]], [blocks.8.kv.bn.running_var -> (640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (_, 640), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: BatchNormalization_235 for ONNX node: BatchNormalization_235\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_703 for ONNX tensor: onnx::Reshape_703\n",
      "[05/24/2022-15:21:29] [TRT] [V] BatchNormalization_235 [BatchNormalization] outputs: [onnx::Reshape_703 -> (-1, 640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_236 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Flatten_701\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_236 [Shape] inputs: [onnx::Flatten_701 -> (-1, 196, 640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_236 for ONNX node: Shape_236\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_704 for ONNX tensor: onnx::Reshape_704\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_236 [Shape] outputs: [onnx::Reshape_704 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_237 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_703\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_704\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_237 [Reshape] inputs: [onnx::Reshape_703 -> (-1, 640)[FLOAT]], [onnx::Reshape_704 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_237 for ONNX node: Reshape_237\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_705 for ONNX tensor: onnx::Reshape_705\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_237 [Reshape] outputs: [onnx::Reshape_705 -> (-1, 196, 640)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_238 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_696\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_238 [Unsqueeze] inputs: [onnx::Unsqueeze_696 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_238 for ONNX node: Unsqueeze_238\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_708 for ONNX tensor: onnx::Concat_708\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_238 [Unsqueeze] outputs: [onnx::Concat_708 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_239 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_699\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_239 [Unsqueeze] inputs: [onnx::Unsqueeze_699 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_239 for ONNX node: Unsqueeze_239\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_709 for ONNX tensor: onnx::Concat_709\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_239 [Unsqueeze] outputs: [onnx::Concat_709 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_240 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_708\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_709\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1471\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1472\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_240 [Concat] inputs: [onnx::Concat_708 -> (1)[INT32]], [onnx::Concat_709 -> (1)[INT32]], [onnx::Concat_1471 -> (1)[INT32]], [onnx::Concat_1472 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1471 for ONNX node: onnx::Concat_1471\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1472 for ONNX node: onnx::Concat_1472\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_240 for ONNX node: Concat_240\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_712 for ONNX tensor: onnx::Reshape_712\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_240 [Concat] outputs: [onnx::Reshape_712 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_241 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_705\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_712\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_241 [Reshape] inputs: [onnx::Reshape_705 -> (-1, 196, 640)[FLOAT]], [onnx::Reshape_712 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_241 for ONNX node: Reshape_241\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Split_713 for ONNX tensor: onnx::Split_713\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_241 [Reshape] outputs: [onnx::Split_713 -> (-1, 196, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Split_242 [Split]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Split_713\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_242 [Split] inputs: [onnx::Split_713 -> (-1, 196, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_242 for ONNX node: Split_242\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Split_242_231 for ONNX node: Split_242\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_714 for ONNX tensor: onnx::Transpose_714\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Transpose_715 for ONNX tensor: onnx::Transpose_715\n",
      "[05/24/2022-15:21:29] [TRT] [V] Split_242 [Split] outputs: [onnx::Transpose_714 -> (-1, 196, 8, 16)[FLOAT]], [onnx::Transpose_715 -> (-1, 196, 8, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Transpose_243 [Transpose]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Transpose_715\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_243 [Transpose] inputs: [onnx::Transpose_715 -> (-1, 196, 8, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Transpose_243 for ONNX node: Transpose_243\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::MatMul_716 for ONNX tensor: onnx::MatMul_716\n",
      "[05/24/2022-15:21:29] [TRT] [V] Transpose_243 [Transpose] outputs: [onnx::MatMul_716 -> (-1, 8, 196, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_244 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_693\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_244 [Shape] inputs: [onnx::Shape_693 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_244 for ONNX node: Shape_244\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_717 for ONNX tensor: onnx::Gather_717\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_244 [Shape] outputs: [onnx::Gather_717 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_245 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_245 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_245 [Constant] outputs: [onnx::Gather_718 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_246 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_717\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_718\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_246 [Gather] inputs: [onnx::Gather_717 -> (3)[INT32]], [onnx::Gather_718 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_718 for ONNX node: onnx::Gather_718\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_246 for ONNX node: Gather_246\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_719 for ONNX tensor: onnx::Unsqueeze_719\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_246 [Gather] outputs: [onnx::Unsqueeze_719 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Shape_247 [Shape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_693\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_247 [Shape] inputs: [onnx::Shape_693 -> (-1, 196, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Shape_247 for ONNX node: Shape_247\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Gather_720 for ONNX tensor: onnx::Gather_720\n",
      "[05/24/2022-15:21:29] [TRT] [V] Shape_247 [Shape] outputs: [onnx::Gather_720 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_248 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_248 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_248 [Constant] outputs: [onnx::Gather_721 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Gather_249 [Gather]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_720\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Gather_721\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_249 [Gather] inputs: [onnx::Gather_720 -> (3)[INT32]], [onnx::Gather_721 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Gather_721 for ONNX node: onnx::Gather_721\n",
      "[05/24/2022-15:21:29] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Gather_249 for ONNX node: Gather_249\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Unsqueeze_722 for ONNX tensor: onnx::Unsqueeze_722\n",
      "[05/24/2022-15:21:29] [TRT] [V] Gather_249 [Gather] outputs: [onnx::Unsqueeze_722 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_250 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_719\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_250 [Unsqueeze] inputs: [onnx::Unsqueeze_719 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_250 for ONNX node: Unsqueeze_250\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_725 for ONNX tensor: onnx::Concat_725\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_250 [Unsqueeze] outputs: [onnx::Concat_725 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Unsqueeze_251 [Unsqueeze]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Unsqueeze_722\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_251 [Unsqueeze] inputs: [onnx::Unsqueeze_722 -> ()[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Unsqueeze_251 for ONNX node: Unsqueeze_251\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Concat_728 for ONNX tensor: onnx::Concat_728\n",
      "[05/24/2022-15:21:29] [TRT] [V] Unsqueeze_251 [Unsqueeze] outputs: [onnx::Concat_728 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Concat_252 [Concat]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_725\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1473\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_1474\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Concat_728\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_252 [Concat] inputs: [onnx::Concat_725 -> (1)[INT32]], [onnx::Concat_1473 -> (1)[INT32]], [onnx::Concat_1474 -> (1)[INT32]], [onnx::Concat_728 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1473 for ONNX node: onnx::Concat_1473\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: onnx::Concat_1474 for ONNX node: onnx::Concat_1474\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Concat_252 for ONNX node: Concat_252\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Reshape_729 for ONNX tensor: onnx::Reshape_729\n",
      "[05/24/2022-15:21:29] [TRT] [V] Concat_252 [Concat] outputs: [onnx::Reshape_729 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Reshape_253 [Reshape]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Shape_693\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Reshape_729\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_253 [Reshape] inputs: [onnx::Shape_693 -> (-1, 196, 128)[FLOAT]], [onnx::Reshape_729 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Reshape_253 for ONNX node: Reshape_253\n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering tensor: onnx::Slice_730 for ONNX tensor: onnx::Slice_730\n",
      "[05/24/2022-15:21:29] [TRT] [V] Reshape_253 [Reshape] outputs: [onnx::Slice_730 -> (-1, 14, 14, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_254 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_254 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_254 [Constant] outputs: [onnx::Slice_731 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_255 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_255 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_255 [Constant] outputs: [onnx::Slice_732 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_256 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_256 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Weight at index 0: 9223372036854775807 is out of range. Clamping to: 2147483647\n",
      "[05/24/2022-15:21:29] [TRT] [W] onnx2trt_utils.cpp:391: One or more weights outside the range of INT32 was clamped\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_256 [Constant] outputs: [onnx::Slice_733 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Constant_257 [Constant]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_257 [Constant] inputs: \n",
      "[05/24/2022-15:21:29] [TRT] [V] Constant_257 [Constant] outputs: [onnx::Slice_734 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Parsing node: Slice_258 [Slice]\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_730\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_732\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_733\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_731\n",
      "[05/24/2022-15:21:29] [TRT] [V] Searching for input: onnx::Slice_734\n",
      "[05/24/2022-15:21:29] [TRT] [V] Slice_258 [Slice] inputs: [onnx::Slice_730 -> (-1, 14, 14, 128)[FLOAT]], [onnx::Slice_732 -> (1)[INT32]], [onnx::Slice_733 -> (1)[INT32]], [onnx::Slice_731 -> (1)[INT32]], [onnx::Slice_734 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:29] [TRT] [V] Registering layer: Slice_258 for ONNX node: Slice_258\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Slice_735 for ONNX tensor: onnx::Slice_735\n",
      "[05/24/2022-15:21:30] [TRT] [V] Slice_258 [Slice] outputs: [onnx::Slice_735 -> (-1, 7, 14, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_259 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_259 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_259 [Constant] outputs: [onnx::Slice_736 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_260 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_260 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_260 [Constant] outputs: [onnx::Slice_737 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_261 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_261 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Weight at index 0: 9223372036854775807 is out of range. Clamping to: 2147483647\n",
      "[05/24/2022-15:21:30] [TRT] [W] onnx2trt_utils.cpp:391: One or more weights outside the range of INT32 was clamped\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_261 [Constant] outputs: [onnx::Slice_738 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_262 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_262 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_262 [Constant] outputs: [onnx::Slice_739 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Slice_263 [Slice]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Slice_735\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Slice_737\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Slice_738\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Slice_736\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Slice_739\n",
      "[05/24/2022-15:21:30] [TRT] [V] Slice_263 [Slice] inputs: [onnx::Slice_735 -> (-1, 7, 14, 128)[FLOAT]], [onnx::Slice_737 -> (1)[INT32]], [onnx::Slice_738 -> (1)[INT32]], [onnx::Slice_736 -> (1)[INT32]], [onnx::Slice_739 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Slice_263 for ONNX node: Slice_263\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_740 for ONNX tensor: onnx::Reshape_740\n",
      "[05/24/2022-15:21:30] [TRT] [V] Slice_263 [Slice] outputs: [onnx::Reshape_740 -> (-1, 7, 7, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_264 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_719\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_264 [Unsqueeze] inputs: [onnx::Unsqueeze_719 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_264 for ONNX node: Unsqueeze_264\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_742 for ONNX tensor: onnx::Concat_742\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_264 [Unsqueeze] outputs: [onnx::Concat_742 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_265 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_722\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_265 [Unsqueeze] inputs: [onnx::Unsqueeze_722 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_265 for ONNX node: Unsqueeze_265\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_744 for ONNX tensor: onnx::Concat_744\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_265 [Unsqueeze] outputs: [onnx::Concat_744 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_266 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_742\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1475\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_744\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_266 [Concat] inputs: [onnx::Concat_742 -> (1)[INT32]], [onnx::Concat_1475 -> (1)[INT32]], [onnx::Concat_744 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1475 for ONNX node: onnx::Concat_1475\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_266 for ONNX node: Concat_266\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_745 for ONNX tensor: onnx::Reshape_745\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_266 [Concat] outputs: [onnx::Reshape_745 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_267 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_740\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_745\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_267 [Reshape] inputs: [onnx::Reshape_740 -> (-1, 7, 7, 128)[FLOAT]], [onnx::Reshape_745 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_267 for ONNX node: Reshape_267\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_746 for ONNX tensor: onnx::MatMul_746\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_267 [Reshape] outputs: [onnx::MatMul_746 -> (-1, 49, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_268 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_746\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1476\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_268 [MatMul] inputs: [onnx::MatMul_746 -> (-1, 49, 128)[FLOAT]], [onnx::MatMul_1476 -> (128, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1476 for ONNX node: onnx::MatMul_1476\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_268 for ONNX node: MatMul_268\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_748 for ONNX tensor: onnx::Flatten_748\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_268 [MatMul] outputs: [onnx::Flatten_748 -> (-1, 49, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_269 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_748\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_269 [Flatten] inputs: [onnx::Flatten_748 -> (-1, 49, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_269 for ONNX node: Flatten_269\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.140 for ONNX tensor: input.140\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_269 [Flatten] outputs: [input.140 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_270 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.140\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.q.1.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.q.1.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.q.1.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.q.1.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_270 [BatchNormalization] inputs: [input.140 -> (-1, 128)[FLOAT]], [blocks.8.q.1.bn.weight -> (128)[FLOAT]], [blocks.8.q.1.bn.bias -> (128)[FLOAT]], [blocks.8.q.1.bn.running_mean -> (128)[FLOAT]], [blocks.8.q.1.bn.running_var -> (128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 128), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_270 for ONNX node: BatchNormalization_270\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_750 for ONNX tensor: onnx::Reshape_750\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_270 [BatchNormalization] outputs: [onnx::Reshape_750 -> (-1, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_271 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_748\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_271 [Shape] inputs: [onnx::Flatten_748 -> (-1, 49, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_271 for ONNX node: Shape_271\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_751 for ONNX tensor: onnx::Reshape_751\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_271 [Shape] outputs: [onnx::Reshape_751 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_272 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_750\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_751\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_272 [Reshape] inputs: [onnx::Reshape_750 -> (-1, 128)[FLOAT]], [onnx::Reshape_751 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_272 for ONNX node: Reshape_272\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_752 for ONNX tensor: onnx::Reshape_752\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_272 [Reshape] outputs: [onnx::Reshape_752 -> (-1, 49, 128)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_273 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_696\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_273 [Unsqueeze] inputs: [onnx::Unsqueeze_696 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_273 for ONNX node: Unsqueeze_273\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_756 for ONNX tensor: onnx::Concat_756\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_273 [Unsqueeze] outputs: [onnx::Concat_756 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_274 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_756\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1477\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1478\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1479\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_274 [Concat] inputs: [onnx::Concat_756 -> (1)[INT32]], [onnx::Concat_1477 -> (1)[INT32]], [onnx::Concat_1478 -> (1)[INT32]], [onnx::Concat_1479 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1477 for ONNX node: onnx::Concat_1477\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1478 for ONNX node: onnx::Concat_1478\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1479 for ONNX node: onnx::Concat_1479\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_274 for ONNX node: Concat_274\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_760 for ONNX tensor: onnx::Reshape_760\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_274 [Concat] outputs: [onnx::Reshape_760 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_275 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_752\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_760\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_275 [Reshape] inputs: [onnx::Reshape_752 -> (-1, 49, 128)[FLOAT]], [onnx::Reshape_760 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_275 for ONNX node: Reshape_275\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_761 for ONNX tensor: onnx::Transpose_761\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_275 [Reshape] outputs: [onnx::Transpose_761 -> (-1, 49, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_276 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_761\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_276 [Transpose] inputs: [onnx::Transpose_761 -> (-1, 49, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_276 for ONNX node: Transpose_276\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_762 for ONNX tensor: onnx::MatMul_762\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_276 [Transpose] outputs: [onnx::MatMul_762 -> (-1, 8, 49, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_277 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_714\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_277 [Transpose] inputs: [onnx::Transpose_714 -> (-1, 196, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_277 for ONNX node: Transpose_277\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_763 for ONNX tensor: onnx::MatMul_763\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_277 [Transpose] outputs: [onnx::MatMul_763 -> (-1, 8, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_278 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_762\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_763\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_278 [MatMul] inputs: [onnx::MatMul_762 -> (-1, 8, 49, 16)[FLOAT]], [onnx::MatMul_763 -> (-1, 8, 16, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_278 for ONNX node: MatMul_278\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_764 for ONNX tensor: onnx::Mul_764\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_278 [MatMul] outputs: [onnx::Mul_764 -> (-1, 8, 49, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_279 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_279 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_279 [Constant] outputs: [onnx::Mul_765 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_280 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_764\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_765\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_280 [Mul] inputs: [onnx::Mul_764 -> (-1, 8, 49, 196)[FLOAT]], [onnx::Mul_765 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Mul_765 for ONNX node: onnx::Mul_765\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_280 for ONNX node: Mul_280\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_766 for ONNX tensor: onnx::Add_766\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_280 [Mul] outputs: [onnx::Add_766 -> (-1, 8, 49, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_281 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_281 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_281 [Constant] outputs: [onnx::Add_767 -> (8, 49, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_282 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_766\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_767\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_282 [Add] inputs: [onnx::Add_766 -> (-1, 8, 49, 196)[FLOAT]], [onnx::Add_767 -> (8, 49, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Add_767 for ONNX node: onnx::Add_767\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_282 for ONNX node: Add_282\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Softmax_768 for ONNX tensor: onnx::Softmax_768\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_282 [Add] outputs: [onnx::Softmax_768 -> (-1, 8, 49, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Softmax_283 [Softmax]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Softmax_768\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_283 [Softmax] inputs: [onnx::Softmax_768 -> (-1, 8, 49, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Softmax_283 for ONNX node: Softmax_283\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_769 for ONNX tensor: onnx::MatMul_769\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_283 [Softmax] outputs: [onnx::MatMul_769 -> (-1, 8, 49, 196)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_284 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_769\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_716\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_284 [MatMul] inputs: [onnx::MatMul_769 -> (-1, 8, 49, 196)[FLOAT]], [onnx::MatMul_716 -> (-1, 8, 196, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_284 for ONNX node: MatMul_284\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_770 for ONNX tensor: onnx::Transpose_770\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_284 [MatMul] outputs: [onnx::Transpose_770 -> (-1, 8, 49, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_285 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_770\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_285 [Transpose] inputs: [onnx::Transpose_770 -> (-1, 8, 49, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_285 for ONNX node: Transpose_285\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_771 for ONNX tensor: onnx::Reshape_771\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_285 [Transpose] outputs: [onnx::Reshape_771 -> (-1, 49, 8, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_286 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_696\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_286 [Unsqueeze] inputs: [onnx::Unsqueeze_696 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_286 for ONNX node: Unsqueeze_286\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_774 for ONNX tensor: onnx::Concat_774\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_286 [Unsqueeze] outputs: [onnx::Concat_774 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_287 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_774\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1480\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1481\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_287 [Concat] inputs: [onnx::Concat_774 -> (1)[INT32]], [onnx::Concat_1480 -> (1)[INT32]], [onnx::Concat_1481 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1480 for ONNX node: onnx::Concat_1480\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1481 for ONNX node: onnx::Concat_1481\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_287 for ONNX node: Concat_287\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_777 for ONNX tensor: onnx::Reshape_777\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_287 [Concat] outputs: [onnx::Reshape_777 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_288 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_771\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_777\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_288 [Reshape] inputs: [onnx::Reshape_771 -> (-1, 49, 8, 64)[FLOAT]], [onnx::Reshape_777 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_288 for ONNX node: Reshape_288\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.144 for ONNX tensor: input.144\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_288 [Reshape] outputs: [input.144 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_289 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.144\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_289 [HardSigmoid] inputs: [input.144 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_289 for ONNX node: HardSigmoid_289\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_779 for ONNX tensor: onnx::Mul_779\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_289 [HardSigmoid] outputs: [onnx::Mul_779 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_290 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.144\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_779\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_290 [Mul] inputs: [input.144 -> (-1, -1, 512)[FLOAT]], [onnx::Mul_779 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_290 for ONNX node: Mul_290\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_780 for ONNX tensor: onnx::MatMul_780\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_290 [Mul] outputs: [onnx::MatMul_780 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_291 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_780\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1482\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_291 [MatMul] inputs: [onnx::MatMul_780 -> (-1, -1, 512)[FLOAT]], [onnx::MatMul_1482 -> (512, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1482 for ONNX node: onnx::MatMul_1482\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_291 for ONNX node: MatMul_291\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_782 for ONNX tensor: onnx::Flatten_782\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_291 [MatMul] outputs: [onnx::Flatten_782 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_292 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_782\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_292 [Flatten] inputs: [onnx::Flatten_782 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_292 for ONNX node: Flatten_292\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.148 for ONNX tensor: input.148\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_292 [Flatten] outputs: [input.148 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_293 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.148\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.proj.1.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.proj.1.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.8.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_293 [BatchNormalization] inputs: [input.148 -> (-1, 256)[FLOAT]], [blocks.8.proj.1.bn.weight -> (256)[FLOAT]], [blocks.8.proj.1.bn.bias -> (256)[FLOAT]], [blocks.8.proj.1.bn.running_mean -> (256)[FLOAT]], [blocks.8.proj.1.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_293 for ONNX node: BatchNormalization_293\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_784 for ONNX tensor: onnx::Reshape_784\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_293 [BatchNormalization] outputs: [onnx::Reshape_784 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_294 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_782\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_294 [Shape] inputs: [onnx::Flatten_782 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_294 for ONNX node: Shape_294\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_785 for ONNX tensor: onnx::Reshape_785\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_294 [Shape] outputs: [onnx::Reshape_785 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_295 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_784\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_785\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_295 [Reshape] inputs: [onnx::Reshape_784 -> (-1, 256)[FLOAT]], [onnx::Reshape_785 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_295 for ONNX node: Reshape_295\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_786 for ONNX tensor: onnx::MatMul_786\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_295 [Reshape] outputs: [onnx::MatMul_786 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_296 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_786\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1483\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_296 [MatMul] inputs: [onnx::MatMul_786 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1483 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1483 for ONNX node: onnx::MatMul_1483\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_296 for ONNX node: MatMul_296\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_788 for ONNX tensor: onnx::Flatten_788\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_296 [MatMul] outputs: [onnx::Flatten_788 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_297 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_788\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_297 [Flatten] inputs: [onnx::Flatten_788 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_297 for ONNX node: Flatten_297\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.152 for ONNX tensor: input.152\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_297 [Flatten] outputs: [input.152 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_298 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.152\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.0.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.0.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.0.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_298 [BatchNormalization] inputs: [input.152 -> (-1, 512)[FLOAT]], [blocks.9.m.0.bn.weight -> (512)[FLOAT]], [blocks.9.m.0.bn.bias -> (512)[FLOAT]], [blocks.9.m.0.bn.running_mean -> (512)[FLOAT]], [blocks.9.m.0.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_298 for ONNX node: BatchNormalization_298\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_790 for ONNX tensor: onnx::Reshape_790\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_298 [BatchNormalization] outputs: [onnx::Reshape_790 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_299 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_788\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_299 [Shape] inputs: [onnx::Flatten_788 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_299 for ONNX node: Shape_299\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_791 for ONNX tensor: onnx::Reshape_791\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_299 [Shape] outputs: [onnx::Reshape_791 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_300 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_790\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_791\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_300 [Reshape] inputs: [onnx::Reshape_790 -> (-1, 512)[FLOAT]], [onnx::Reshape_791 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_300 for ONNX node: Reshape_300\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.156 for ONNX tensor: input.156\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_300 [Reshape] outputs: [input.156 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_301 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.156\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_301 [HardSigmoid] inputs: [input.156 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_301 for ONNX node: HardSigmoid_301\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_793 for ONNX tensor: onnx::Mul_793\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_301 [HardSigmoid] outputs: [onnx::Mul_793 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_302 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.156\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_793\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_302 [Mul] inputs: [input.156 -> (-1, -1, 512)[FLOAT]], [onnx::Mul_793 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_302 for ONNX node: Mul_302\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_794 for ONNX tensor: onnx::MatMul_794\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_302 [Mul] outputs: [onnx::MatMul_794 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_303 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_794\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1484\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_303 [MatMul] inputs: [onnx::MatMul_794 -> (-1, -1, 512)[FLOAT]], [onnx::MatMul_1484 -> (512, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1484 for ONNX node: onnx::MatMul_1484\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_303 for ONNX node: MatMul_303\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_796 for ONNX tensor: onnx::Flatten_796\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_303 [MatMul] outputs: [onnx::Flatten_796 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_304 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_796\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_304 [Flatten] inputs: [onnx::Flatten_796 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_304 for ONNX node: Flatten_304\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.160 for ONNX tensor: input.160\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_304 [Flatten] outputs: [input.160 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_305 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.160\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.2.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.2.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.9.m.2.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_305 [BatchNormalization] inputs: [input.160 -> (-1, 256)[FLOAT]], [blocks.9.m.2.bn.weight -> (256)[FLOAT]], [blocks.9.m.2.bn.bias -> (256)[FLOAT]], [blocks.9.m.2.bn.running_mean -> (256)[FLOAT]], [blocks.9.m.2.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_305 for ONNX node: BatchNormalization_305\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_798 for ONNX tensor: onnx::Reshape_798\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_305 [BatchNormalization] outputs: [onnx::Reshape_798 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_306 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_796\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_306 [Shape] inputs: [onnx::Flatten_796 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_306 for ONNX node: Shape_306\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_799 for ONNX tensor: onnx::Reshape_799\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_306 [Shape] outputs: [onnx::Reshape_799 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_307 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_798\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_799\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_307 [Reshape] inputs: [onnx::Reshape_798 -> (-1, 256)[FLOAT]], [onnx::Reshape_799 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_307 for ONNX node: Reshape_307\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_800 for ONNX tensor: onnx::Add_800\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_307 [Reshape] outputs: [onnx::Add_800 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_308 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_786\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_800\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_308 [Add] inputs: [onnx::MatMul_786 -> (-1, -1, 256)[FLOAT]], [onnx::Add_800 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_308 for ONNX node: Add_308\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Shape_801 for ONNX tensor: onnx::Shape_801\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_308 [Add] outputs: [onnx::Shape_801 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_309 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_801\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_309 [Shape] inputs: [onnx::Shape_801 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_309 for ONNX node: Shape_309\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_802 for ONNX tensor: onnx::Gather_802\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_309 [Shape] outputs: [onnx::Gather_802 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_310 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_310 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_310 [Constant] outputs: [onnx::Gather_803 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_311 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_802\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_803\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_311 [Gather] inputs: [onnx::Gather_802 -> (3)[INT32]], [onnx::Gather_803 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_803 for ONNX node: onnx::Gather_803\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_311 for ONNX node: Gather_311\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_804 for ONNX tensor: onnx::Unsqueeze_804\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_311 [Gather] outputs: [onnx::Unsqueeze_804 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_312 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_801\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_312 [Shape] inputs: [onnx::Shape_801 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_312 for ONNX node: Shape_312\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_805 for ONNX tensor: onnx::Gather_805\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_312 [Shape] outputs: [onnx::Gather_805 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_313 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_313 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_313 [Constant] outputs: [onnx::Gather_806 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_314 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_805\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_806\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_314 [Gather] inputs: [onnx::Gather_805 -> (3)[INT32]], [onnx::Gather_806 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_806 for ONNX node: onnx::Gather_806\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_314 for ONNX node: Gather_314\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_807 for ONNX tensor: onnx::Unsqueeze_807\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_314 [Gather] outputs: [onnx::Unsqueeze_807 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_315 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_801\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1485\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_315 [MatMul] inputs: [onnx::Shape_801 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1485 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1485 for ONNX node: onnx::MatMul_1485\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_315 for ONNX node: MatMul_315\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_809 for ONNX tensor: onnx::Flatten_809\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_315 [MatMul] outputs: [onnx::Flatten_809 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_316 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_809\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_316 [Flatten] inputs: [onnx::Flatten_809 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_316 for ONNX node: Flatten_316\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.164 for ONNX tensor: input.164\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_316 [Flatten] outputs: [input.164 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_317 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.164\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_317 [BatchNormalization] inputs: [input.164 -> (-1, 512)[FLOAT]], [blocks.10.m.qkv.bn.weight -> (512)[FLOAT]], [blocks.10.m.qkv.bn.bias -> (512)[FLOAT]], [blocks.10.m.qkv.bn.running_mean -> (512)[FLOAT]], [blocks.10.m.qkv.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_317 for ONNX node: BatchNormalization_317\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_811 for ONNX tensor: onnx::Reshape_811\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_317 [BatchNormalization] outputs: [onnx::Reshape_811 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_318 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_809\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_318 [Shape] inputs: [onnx::Flatten_809 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_318 for ONNX node: Shape_318\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_812 for ONNX tensor: onnx::Reshape_812\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_318 [Shape] outputs: [onnx::Reshape_812 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_319 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_811\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_812\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_319 [Reshape] inputs: [onnx::Reshape_811 -> (-1, 512)[FLOAT]], [onnx::Reshape_812 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_319 for ONNX node: Reshape_319\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_813 for ONNX tensor: onnx::Reshape_813\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_319 [Reshape] outputs: [onnx::Reshape_813 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_320 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_804\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_320 [Unsqueeze] inputs: [onnx::Unsqueeze_804 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_320 for ONNX node: Unsqueeze_320\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_816 for ONNX tensor: onnx::Concat_816\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_320 [Unsqueeze] outputs: [onnx::Concat_816 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_321 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_807\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_321 [Unsqueeze] inputs: [onnx::Unsqueeze_807 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_321 for ONNX node: Unsqueeze_321\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_817 for ONNX tensor: onnx::Concat_817\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_321 [Unsqueeze] outputs: [onnx::Concat_817 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_322 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_816\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_817\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1486\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1487\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_322 [Concat] inputs: [onnx::Concat_816 -> (1)[INT32]], [onnx::Concat_817 -> (1)[INT32]], [onnx::Concat_1486 -> (1)[INT32]], [onnx::Concat_1487 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1486 for ONNX node: onnx::Concat_1486\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1487 for ONNX node: onnx::Concat_1487\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_322 for ONNX node: Concat_322\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_820 for ONNX tensor: onnx::Reshape_820\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_322 [Concat] outputs: [onnx::Reshape_820 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_323 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_813\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_820\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_323 [Reshape] inputs: [onnx::Reshape_813 -> (-1, -1, 512)[FLOAT]], [onnx::Reshape_820 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_323 for ONNX node: Reshape_323\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Split_821 for ONNX tensor: onnx::Split_821\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_323 [Reshape] outputs: [onnx::Split_821 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Split_324 [Split]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Split_821\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_324 [Split] inputs: [onnx::Split_821 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_324 for ONNX node: Split_324\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_324_306 for ONNX node: Split_324\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_324_308 for ONNX node: Split_324\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_822 for ONNX tensor: onnx::Transpose_822\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_823 for ONNX tensor: onnx::Transpose_823\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_824 for ONNX tensor: onnx::Transpose_824\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_324 [Split] outputs: [onnx::Transpose_822 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_823 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_824 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_325 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_822\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_325 [Transpose] inputs: [onnx::Transpose_822 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_325 for ONNX node: Transpose_325\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_825 for ONNX tensor: onnx::MatMul_825\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_325 [Transpose] outputs: [onnx::MatMul_825 -> (-1, 8, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_326 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_824\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_326 [Transpose] inputs: [onnx::Transpose_824 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_326 for ONNX node: Transpose_326\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_826 for ONNX tensor: onnx::MatMul_826\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_326 [Transpose] outputs: [onnx::MatMul_826 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_327 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_823\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_327 [Transpose] inputs: [onnx::Transpose_823 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_327 for ONNX node: Transpose_327\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_827 for ONNX tensor: onnx::MatMul_827\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_327 [Transpose] outputs: [onnx::MatMul_827 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_328 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_825\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_827\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_328 [MatMul] inputs: [onnx::MatMul_825 -> (-1, 8, -1, 16)[FLOAT]], [onnx::MatMul_827 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_328 for ONNX node: MatMul_328\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_828 for ONNX tensor: onnx::Mul_828\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_328 [MatMul] outputs: [onnx::Mul_828 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_329 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_329 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_329 [Constant] outputs: [onnx::Mul_829 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_330 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_828\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_829\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_330 [Mul] inputs: [onnx::Mul_828 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Mul_829 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Mul_829 for ONNX node: onnx::Mul_829\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_330 for ONNX node: Mul_330\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_830 for ONNX tensor: onnx::Add_830\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_330 [Mul] outputs: [onnx::Add_830 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_331 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_331 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_331 [Constant] outputs: [onnx::Add_831 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_332 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_830\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_831\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_332 [Add] inputs: [onnx::Add_830 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Add_831 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Add_831 for ONNX node: onnx::Add_831\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_332 for ONNX node: Add_332\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Softmax_832 for ONNX tensor: onnx::Softmax_832\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_332 [Add] outputs: [onnx::Softmax_832 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Softmax_333 [Softmax]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Softmax_832\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_333 [Softmax] inputs: [onnx::Softmax_832 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Softmax_333 for ONNX node: Softmax_333\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_833 for ONNX tensor: onnx::MatMul_833\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_333 [Softmax] outputs: [onnx::MatMul_833 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_334 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_833\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_826\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_334 [MatMul] inputs: [onnx::MatMul_833 -> (-1, 8, 49, 49)[FLOAT]], [onnx::MatMul_826 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_334 for ONNX node: MatMul_334\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_834 for ONNX tensor: onnx::Transpose_834\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_334 [MatMul] outputs: [onnx::Transpose_834 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_335 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_834\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_335 [Transpose] inputs: [onnx::Transpose_834 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_335 for ONNX node: Transpose_335\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_835 for ONNX tensor: onnx::Reshape_835\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_335 [Transpose] outputs: [onnx::Reshape_835 -> (-1, 49, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_336 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_804\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_336 [Unsqueeze] inputs: [onnx::Unsqueeze_804 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_336 for ONNX node: Unsqueeze_336\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_837 for ONNX tensor: onnx::Concat_837\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_336 [Unsqueeze] outputs: [onnx::Concat_837 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_337 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_807\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_337 [Unsqueeze] inputs: [onnx::Unsqueeze_807 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_337 for ONNX node: Unsqueeze_337\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_838 for ONNX tensor: onnx::Concat_838\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_337 [Unsqueeze] outputs: [onnx::Concat_838 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_338 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_837\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_838\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1488\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_338 [Concat] inputs: [onnx::Concat_837 -> (1)[INT32]], [onnx::Concat_838 -> (1)[INT32]], [onnx::Concat_1488 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1488 for ONNX node: onnx::Concat_1488\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_338 for ONNX node: Concat_338\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_840 for ONNX tensor: onnx::Reshape_840\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_338 [Concat] outputs: [onnx::Reshape_840 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_339 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_835\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_840\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_339 [Reshape] inputs: [onnx::Reshape_835 -> (-1, 49, 8, 32)[FLOAT]], [onnx::Reshape_840 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_339 for ONNX node: Reshape_339\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.168 for ONNX tensor: input.168\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_339 [Reshape] outputs: [input.168 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_340 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.168\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_340 [HardSigmoid] inputs: [input.168 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_340 for ONNX node: HardSigmoid_340\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_842 for ONNX tensor: onnx::Mul_842\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_340 [HardSigmoid] outputs: [onnx::Mul_842 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_341 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.168\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_842\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_341 [Mul] inputs: [input.168 -> (-1, -1, 256)[FLOAT]], [onnx::Mul_842 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_341 for ONNX node: Mul_341\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_843 for ONNX tensor: onnx::MatMul_843\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_341 [Mul] outputs: [onnx::MatMul_843 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_342 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_843\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1489\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_342 [MatMul] inputs: [onnx::MatMul_843 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1489 -> (256, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1489 for ONNX node: onnx::MatMul_1489\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_342 for ONNX node: MatMul_342\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_845 for ONNX tensor: onnx::Flatten_845\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_342 [MatMul] outputs: [onnx::Flatten_845 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_343 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_845\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_343 [Flatten] inputs: [onnx::Flatten_845 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_343 for ONNX node: Flatten_343\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.172 for ONNX tensor: input.172\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_343 [Flatten] outputs: [input.172 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_344 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.172\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.10.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_344 [BatchNormalization] inputs: [input.172 -> (-1, 256)[FLOAT]], [blocks.10.m.proj.1.bn.weight -> (256)[FLOAT]], [blocks.10.m.proj.1.bn.bias -> (256)[FLOAT]], [blocks.10.m.proj.1.bn.running_mean -> (256)[FLOAT]], [blocks.10.m.proj.1.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_344 for ONNX node: BatchNormalization_344\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_847 for ONNX tensor: onnx::Reshape_847\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_344 [BatchNormalization] outputs: [onnx::Reshape_847 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_345 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_845\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_345 [Shape] inputs: [onnx::Flatten_845 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_345 for ONNX node: Shape_345\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_848 for ONNX tensor: onnx::Reshape_848\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_345 [Shape] outputs: [onnx::Reshape_848 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_346 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_847\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_848\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_346 [Reshape] inputs: [onnx::Reshape_847 -> (-1, 256)[FLOAT]], [onnx::Reshape_848 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_346 for ONNX node: Reshape_346\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_849 for ONNX tensor: onnx::Add_849\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_346 [Reshape] outputs: [onnx::Add_849 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_347 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_801\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_849\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_347 [Add] inputs: [onnx::Shape_801 -> (-1, -1, 256)[FLOAT]], [onnx::Add_849 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_347 for ONNX node: Add_347\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_850 for ONNX tensor: onnx::MatMul_850\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_347 [Add] outputs: [onnx::MatMul_850 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_348 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_850\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1490\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_348 [MatMul] inputs: [onnx::MatMul_850 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1490 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1490 for ONNX node: onnx::MatMul_1490\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_348 for ONNX node: MatMul_348\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_852 for ONNX tensor: onnx::Flatten_852\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_348 [MatMul] outputs: [onnx::Flatten_852 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_349 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_852\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_349 [Flatten] inputs: [onnx::Flatten_852 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_349 for ONNX node: Flatten_349\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.176 for ONNX tensor: input.176\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_349 [Flatten] outputs: [input.176 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_350 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.176\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.0.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.0.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.0.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_350 [BatchNormalization] inputs: [input.176 -> (-1, 512)[FLOAT]], [blocks.11.m.0.bn.weight -> (512)[FLOAT]], [blocks.11.m.0.bn.bias -> (512)[FLOAT]], [blocks.11.m.0.bn.running_mean -> (512)[FLOAT]], [blocks.11.m.0.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_350 for ONNX node: BatchNormalization_350\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_854 for ONNX tensor: onnx::Reshape_854\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_350 [BatchNormalization] outputs: [onnx::Reshape_854 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_351 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_852\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_351 [Shape] inputs: [onnx::Flatten_852 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_351 for ONNX node: Shape_351\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_855 for ONNX tensor: onnx::Reshape_855\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_351 [Shape] outputs: [onnx::Reshape_855 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_352 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_854\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_855\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_352 [Reshape] inputs: [onnx::Reshape_854 -> (-1, 512)[FLOAT]], [onnx::Reshape_855 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_352 for ONNX node: Reshape_352\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.180 for ONNX tensor: input.180\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_352 [Reshape] outputs: [input.180 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_353 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.180\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_353 [HardSigmoid] inputs: [input.180 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_353 for ONNX node: HardSigmoid_353\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_857 for ONNX tensor: onnx::Mul_857\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_353 [HardSigmoid] outputs: [onnx::Mul_857 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_354 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.180\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_857\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_354 [Mul] inputs: [input.180 -> (-1, -1, 512)[FLOAT]], [onnx::Mul_857 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_354 for ONNX node: Mul_354\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_858 for ONNX tensor: onnx::MatMul_858\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_354 [Mul] outputs: [onnx::MatMul_858 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_355 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_858\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1491\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_355 [MatMul] inputs: [onnx::MatMul_858 -> (-1, -1, 512)[FLOAT]], [onnx::MatMul_1491 -> (512, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1491 for ONNX node: onnx::MatMul_1491\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_355 for ONNX node: MatMul_355\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_860 for ONNX tensor: onnx::Flatten_860\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_355 [MatMul] outputs: [onnx::Flatten_860 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_356 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_860\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_356 [Flatten] inputs: [onnx::Flatten_860 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_356 for ONNX node: Flatten_356\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.184 for ONNX tensor: input.184\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_356 [Flatten] outputs: [input.184 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_357 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.184\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.2.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.2.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.11.m.2.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_357 [BatchNormalization] inputs: [input.184 -> (-1, 256)[FLOAT]], [blocks.11.m.2.bn.weight -> (256)[FLOAT]], [blocks.11.m.2.bn.bias -> (256)[FLOAT]], [blocks.11.m.2.bn.running_mean -> (256)[FLOAT]], [blocks.11.m.2.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_357 for ONNX node: BatchNormalization_357\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_862 for ONNX tensor: onnx::Reshape_862\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_357 [BatchNormalization] outputs: [onnx::Reshape_862 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_358 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_860\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_358 [Shape] inputs: [onnx::Flatten_860 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_358 for ONNX node: Shape_358\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_863 for ONNX tensor: onnx::Reshape_863\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_358 [Shape] outputs: [onnx::Reshape_863 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_359 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_862\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_863\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_359 [Reshape] inputs: [onnx::Reshape_862 -> (-1, 256)[FLOAT]], [onnx::Reshape_863 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_359 for ONNX node: Reshape_359\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_864 for ONNX tensor: onnx::Add_864\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_359 [Reshape] outputs: [onnx::Add_864 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_360 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_850\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_864\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_360 [Add] inputs: [onnx::MatMul_850 -> (-1, -1, 256)[FLOAT]], [onnx::Add_864 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_360 for ONNX node: Add_360\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Shape_865 for ONNX tensor: onnx::Shape_865\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_360 [Add] outputs: [onnx::Shape_865 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_361 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_865\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_361 [Shape] inputs: [onnx::Shape_865 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_361 for ONNX node: Shape_361\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_866 for ONNX tensor: onnx::Gather_866\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_361 [Shape] outputs: [onnx::Gather_866 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_362 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_362 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_362 [Constant] outputs: [onnx::Gather_867 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_363 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_866\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_867\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_363 [Gather] inputs: [onnx::Gather_866 -> (3)[INT32]], [onnx::Gather_867 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_867 for ONNX node: onnx::Gather_867\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_363 for ONNX node: Gather_363\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_868 for ONNX tensor: onnx::Unsqueeze_868\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_363 [Gather] outputs: [onnx::Unsqueeze_868 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_364 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_865\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_364 [Shape] inputs: [onnx::Shape_865 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_364 for ONNX node: Shape_364\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_869 for ONNX tensor: onnx::Gather_869\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_364 [Shape] outputs: [onnx::Gather_869 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_365 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_365 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_365 [Constant] outputs: [onnx::Gather_870 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_366 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_869\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_870\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_366 [Gather] inputs: [onnx::Gather_869 -> (3)[INT32]], [onnx::Gather_870 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_870 for ONNX node: onnx::Gather_870\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_366 for ONNX node: Gather_366\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_871 for ONNX tensor: onnx::Unsqueeze_871\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_366 [Gather] outputs: [onnx::Unsqueeze_871 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_367 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_865\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1492\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_367 [MatMul] inputs: [onnx::Shape_865 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1492 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1492 for ONNX node: onnx::MatMul_1492\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_367 for ONNX node: MatMul_367\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_873 for ONNX tensor: onnx::Flatten_873\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_367 [MatMul] outputs: [onnx::Flatten_873 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_368 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_873\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_368 [Flatten] inputs: [onnx::Flatten_873 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_368 for ONNX node: Flatten_368\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.188 for ONNX tensor: input.188\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_368 [Flatten] outputs: [input.188 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_369 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.188\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_369 [BatchNormalization] inputs: [input.188 -> (-1, 512)[FLOAT]], [blocks.12.m.qkv.bn.weight -> (512)[FLOAT]], [blocks.12.m.qkv.bn.bias -> (512)[FLOAT]], [blocks.12.m.qkv.bn.running_mean -> (512)[FLOAT]], [blocks.12.m.qkv.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_369 for ONNX node: BatchNormalization_369\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_875 for ONNX tensor: onnx::Reshape_875\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_369 [BatchNormalization] outputs: [onnx::Reshape_875 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_370 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_873\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_370 [Shape] inputs: [onnx::Flatten_873 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_370 for ONNX node: Shape_370\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_876 for ONNX tensor: onnx::Reshape_876\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_370 [Shape] outputs: [onnx::Reshape_876 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_371 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_875\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_876\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_371 [Reshape] inputs: [onnx::Reshape_875 -> (-1, 512)[FLOAT]], [onnx::Reshape_876 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_371 for ONNX node: Reshape_371\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_877 for ONNX tensor: onnx::Reshape_877\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_371 [Reshape] outputs: [onnx::Reshape_877 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_372 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_868\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_372 [Unsqueeze] inputs: [onnx::Unsqueeze_868 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_372 for ONNX node: Unsqueeze_372\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_880 for ONNX tensor: onnx::Concat_880\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_372 [Unsqueeze] outputs: [onnx::Concat_880 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_373 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_871\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_373 [Unsqueeze] inputs: [onnx::Unsqueeze_871 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_373 for ONNX node: Unsqueeze_373\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_881 for ONNX tensor: onnx::Concat_881\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_373 [Unsqueeze] outputs: [onnx::Concat_881 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_374 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_880\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_881\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1493\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1494\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_374 [Concat] inputs: [onnx::Concat_880 -> (1)[INT32]], [onnx::Concat_881 -> (1)[INT32]], [onnx::Concat_1493 -> (1)[INT32]], [onnx::Concat_1494 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1493 for ONNX node: onnx::Concat_1493\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1494 for ONNX node: onnx::Concat_1494\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_374 for ONNX node: Concat_374\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_884 for ONNX tensor: onnx::Reshape_884\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_374 [Concat] outputs: [onnx::Reshape_884 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_375 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_877\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_884\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_375 [Reshape] inputs: [onnx::Reshape_877 -> (-1, -1, 512)[FLOAT]], [onnx::Reshape_884 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_375 for ONNX node: Reshape_375\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Split_885 for ONNX tensor: onnx::Split_885\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_375 [Reshape] outputs: [onnx::Split_885 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Split_376 [Split]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Split_885\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_376 [Split] inputs: [onnx::Split_885 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_376 for ONNX node: Split_376\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_376_346 for ONNX node: Split_376\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_376_348 for ONNX node: Split_376\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_886 for ONNX tensor: onnx::Transpose_886\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_887 for ONNX tensor: onnx::Transpose_887\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_888 for ONNX tensor: onnx::Transpose_888\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_376 [Split] outputs: [onnx::Transpose_886 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_887 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_888 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_377 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_886\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_377 [Transpose] inputs: [onnx::Transpose_886 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_377 for ONNX node: Transpose_377\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_889 for ONNX tensor: onnx::MatMul_889\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_377 [Transpose] outputs: [onnx::MatMul_889 -> (-1, 8, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_378 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_888\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_378 [Transpose] inputs: [onnx::Transpose_888 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_378 for ONNX node: Transpose_378\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_890 for ONNX tensor: onnx::MatMul_890\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_378 [Transpose] outputs: [onnx::MatMul_890 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_379 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_887\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_379 [Transpose] inputs: [onnx::Transpose_887 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_379 for ONNX node: Transpose_379\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_891 for ONNX tensor: onnx::MatMul_891\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_379 [Transpose] outputs: [onnx::MatMul_891 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_380 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_889\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_891\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_380 [MatMul] inputs: [onnx::MatMul_889 -> (-1, 8, -1, 16)[FLOAT]], [onnx::MatMul_891 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_380 for ONNX node: MatMul_380\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_892 for ONNX tensor: onnx::Mul_892\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_380 [MatMul] outputs: [onnx::Mul_892 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_381 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_381 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_381 [Constant] outputs: [onnx::Mul_893 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_382 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_892\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_893\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_382 [Mul] inputs: [onnx::Mul_892 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Mul_893 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Mul_893 for ONNX node: onnx::Mul_893\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_382 for ONNX node: Mul_382\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_894 for ONNX tensor: onnx::Add_894\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_382 [Mul] outputs: [onnx::Add_894 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_383 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_383 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_383 [Constant] outputs: [onnx::Add_895 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_384 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_894\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_895\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_384 [Add] inputs: [onnx::Add_894 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Add_895 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Add_895 for ONNX node: onnx::Add_895\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_384 for ONNX node: Add_384\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Softmax_896 for ONNX tensor: onnx::Softmax_896\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_384 [Add] outputs: [onnx::Softmax_896 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Softmax_385 [Softmax]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Softmax_896\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_385 [Softmax] inputs: [onnx::Softmax_896 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Softmax_385 for ONNX node: Softmax_385\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_897 for ONNX tensor: onnx::MatMul_897\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_385 [Softmax] outputs: [onnx::MatMul_897 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_386 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_897\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_890\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_386 [MatMul] inputs: [onnx::MatMul_897 -> (-1, 8, 49, 49)[FLOAT]], [onnx::MatMul_890 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_386 for ONNX node: MatMul_386\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_898 for ONNX tensor: onnx::Transpose_898\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_386 [MatMul] outputs: [onnx::Transpose_898 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_387 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_898\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_387 [Transpose] inputs: [onnx::Transpose_898 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_387 for ONNX node: Transpose_387\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_899 for ONNX tensor: onnx::Reshape_899\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_387 [Transpose] outputs: [onnx::Reshape_899 -> (-1, 49, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_388 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_868\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_388 [Unsqueeze] inputs: [onnx::Unsqueeze_868 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_388 for ONNX node: Unsqueeze_388\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_901 for ONNX tensor: onnx::Concat_901\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_388 [Unsqueeze] outputs: [onnx::Concat_901 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_389 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_871\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_389 [Unsqueeze] inputs: [onnx::Unsqueeze_871 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_389 for ONNX node: Unsqueeze_389\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_902 for ONNX tensor: onnx::Concat_902\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_389 [Unsqueeze] outputs: [onnx::Concat_902 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_390 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_901\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_902\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1495\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_390 [Concat] inputs: [onnx::Concat_901 -> (1)[INT32]], [onnx::Concat_902 -> (1)[INT32]], [onnx::Concat_1495 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1495 for ONNX node: onnx::Concat_1495\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_390 for ONNX node: Concat_390\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_904 for ONNX tensor: onnx::Reshape_904\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_390 [Concat] outputs: [onnx::Reshape_904 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_391 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_899\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_904\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_391 [Reshape] inputs: [onnx::Reshape_899 -> (-1, 49, 8, 32)[FLOAT]], [onnx::Reshape_904 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_391 for ONNX node: Reshape_391\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.192 for ONNX tensor: input.192\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_391 [Reshape] outputs: [input.192 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_392 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.192\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_392 [HardSigmoid] inputs: [input.192 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_392 for ONNX node: HardSigmoid_392\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_906 for ONNX tensor: onnx::Mul_906\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_392 [HardSigmoid] outputs: [onnx::Mul_906 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_393 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.192\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_906\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_393 [Mul] inputs: [input.192 -> (-1, -1, 256)[FLOAT]], [onnx::Mul_906 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_393 for ONNX node: Mul_393\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_907 for ONNX tensor: onnx::MatMul_907\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_393 [Mul] outputs: [onnx::MatMul_907 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_394 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_907\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1496\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_394 [MatMul] inputs: [onnx::MatMul_907 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1496 -> (256, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1496 for ONNX node: onnx::MatMul_1496\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_394 for ONNX node: MatMul_394\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_909 for ONNX tensor: onnx::Flatten_909\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_394 [MatMul] outputs: [onnx::Flatten_909 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_395 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_909\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_395 [Flatten] inputs: [onnx::Flatten_909 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_395 for ONNX node: Flatten_395\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.196 for ONNX tensor: input.196\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_395 [Flatten] outputs: [input.196 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_396 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.196\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.12.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_396 [BatchNormalization] inputs: [input.196 -> (-1, 256)[FLOAT]], [blocks.12.m.proj.1.bn.weight -> (256)[FLOAT]], [blocks.12.m.proj.1.bn.bias -> (256)[FLOAT]], [blocks.12.m.proj.1.bn.running_mean -> (256)[FLOAT]], [blocks.12.m.proj.1.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_396 for ONNX node: BatchNormalization_396\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_911 for ONNX tensor: onnx::Reshape_911\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_396 [BatchNormalization] outputs: [onnx::Reshape_911 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_397 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_909\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_397 [Shape] inputs: [onnx::Flatten_909 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_397 for ONNX node: Shape_397\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_912 for ONNX tensor: onnx::Reshape_912\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_397 [Shape] outputs: [onnx::Reshape_912 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_398 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_911\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_912\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_398 [Reshape] inputs: [onnx::Reshape_911 -> (-1, 256)[FLOAT]], [onnx::Reshape_912 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_398 for ONNX node: Reshape_398\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_913 for ONNX tensor: onnx::Add_913\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_398 [Reshape] outputs: [onnx::Add_913 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_399 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_865\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_913\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_399 [Add] inputs: [onnx::Shape_865 -> (-1, -1, 256)[FLOAT]], [onnx::Add_913 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_399 for ONNX node: Add_399\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_914 for ONNX tensor: onnx::MatMul_914\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_399 [Add] outputs: [onnx::MatMul_914 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_400 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_914\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1497\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_400 [MatMul] inputs: [onnx::MatMul_914 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1497 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1497 for ONNX node: onnx::MatMul_1497\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_400 for ONNX node: MatMul_400\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_916 for ONNX tensor: onnx::Flatten_916\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_400 [MatMul] outputs: [onnx::Flatten_916 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_401 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_916\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_401 [Flatten] inputs: [onnx::Flatten_916 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_401 for ONNX node: Flatten_401\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.200 for ONNX tensor: input.200\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_401 [Flatten] outputs: [input.200 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_402 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.200\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.0.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.0.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.0.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_402 [BatchNormalization] inputs: [input.200 -> (-1, 512)[FLOAT]], [blocks.13.m.0.bn.weight -> (512)[FLOAT]], [blocks.13.m.0.bn.bias -> (512)[FLOAT]], [blocks.13.m.0.bn.running_mean -> (512)[FLOAT]], [blocks.13.m.0.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_402 for ONNX node: BatchNormalization_402\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_918 for ONNX tensor: onnx::Reshape_918\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_402 [BatchNormalization] outputs: [onnx::Reshape_918 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_403 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_916\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_403 [Shape] inputs: [onnx::Flatten_916 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_403 for ONNX node: Shape_403\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_919 for ONNX tensor: onnx::Reshape_919\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_403 [Shape] outputs: [onnx::Reshape_919 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_404 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_918\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_919\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_404 [Reshape] inputs: [onnx::Reshape_918 -> (-1, 512)[FLOAT]], [onnx::Reshape_919 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_404 for ONNX node: Reshape_404\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.204 for ONNX tensor: input.204\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_404 [Reshape] outputs: [input.204 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_405 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.204\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_405 [HardSigmoid] inputs: [input.204 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_405 for ONNX node: HardSigmoid_405\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_921 for ONNX tensor: onnx::Mul_921\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_405 [HardSigmoid] outputs: [onnx::Mul_921 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_406 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.204\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_921\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_406 [Mul] inputs: [input.204 -> (-1, -1, 512)[FLOAT]], [onnx::Mul_921 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_406 for ONNX node: Mul_406\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_922 for ONNX tensor: onnx::MatMul_922\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_406 [Mul] outputs: [onnx::MatMul_922 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_407 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_922\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1498\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_407 [MatMul] inputs: [onnx::MatMul_922 -> (-1, -1, 512)[FLOAT]], [onnx::MatMul_1498 -> (512, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1498 for ONNX node: onnx::MatMul_1498\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_407 for ONNX node: MatMul_407\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_924 for ONNX tensor: onnx::Flatten_924\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_407 [MatMul] outputs: [onnx::Flatten_924 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_408 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_924\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_408 [Flatten] inputs: [onnx::Flatten_924 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_408 for ONNX node: Flatten_408\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.208 for ONNX tensor: input.208\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_408 [Flatten] outputs: [input.208 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_409 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.208\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.2.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.2.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.13.m.2.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_409 [BatchNormalization] inputs: [input.208 -> (-1, 256)[FLOAT]], [blocks.13.m.2.bn.weight -> (256)[FLOAT]], [blocks.13.m.2.bn.bias -> (256)[FLOAT]], [blocks.13.m.2.bn.running_mean -> (256)[FLOAT]], [blocks.13.m.2.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_409 for ONNX node: BatchNormalization_409\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_926 for ONNX tensor: onnx::Reshape_926\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_409 [BatchNormalization] outputs: [onnx::Reshape_926 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_410 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_924\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_410 [Shape] inputs: [onnx::Flatten_924 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_410 for ONNX node: Shape_410\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_927 for ONNX tensor: onnx::Reshape_927\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_410 [Shape] outputs: [onnx::Reshape_927 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_411 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_926\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_927\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_411 [Reshape] inputs: [onnx::Reshape_926 -> (-1, 256)[FLOAT]], [onnx::Reshape_927 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_411 for ONNX node: Reshape_411\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_928 for ONNX tensor: onnx::Add_928\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_411 [Reshape] outputs: [onnx::Add_928 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_412 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_914\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_928\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_412 [Add] inputs: [onnx::MatMul_914 -> (-1, -1, 256)[FLOAT]], [onnx::Add_928 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_412 for ONNX node: Add_412\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Shape_929 for ONNX tensor: onnx::Shape_929\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_412 [Add] outputs: [onnx::Shape_929 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_413 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_929\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_413 [Shape] inputs: [onnx::Shape_929 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_413 for ONNX node: Shape_413\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_930 for ONNX tensor: onnx::Gather_930\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_413 [Shape] outputs: [onnx::Gather_930 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_414 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_414 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_414 [Constant] outputs: [onnx::Gather_931 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_415 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_930\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_931\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_415 [Gather] inputs: [onnx::Gather_930 -> (3)[INT32]], [onnx::Gather_931 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_931 for ONNX node: onnx::Gather_931\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_415 for ONNX node: Gather_415\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_932 for ONNX tensor: onnx::Unsqueeze_932\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_415 [Gather] outputs: [onnx::Unsqueeze_932 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_416 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_929\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_416 [Shape] inputs: [onnx::Shape_929 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_416 for ONNX node: Shape_416\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_933 for ONNX tensor: onnx::Gather_933\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_416 [Shape] outputs: [onnx::Gather_933 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_417 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_417 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_417 [Constant] outputs: [onnx::Gather_934 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_418 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_933\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_934\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_418 [Gather] inputs: [onnx::Gather_933 -> (3)[INT32]], [onnx::Gather_934 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_934 for ONNX node: onnx::Gather_934\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_418 for ONNX node: Gather_418\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_935 for ONNX tensor: onnx::Unsqueeze_935\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_418 [Gather] outputs: [onnx::Unsqueeze_935 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_419 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_929\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1499\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_419 [MatMul] inputs: [onnx::Shape_929 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1499 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1499 for ONNX node: onnx::MatMul_1499\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_419 for ONNX node: MatMul_419\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_937 for ONNX tensor: onnx::Flatten_937\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_419 [MatMul] outputs: [onnx::Flatten_937 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_420 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_937\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_420 [Flatten] inputs: [onnx::Flatten_937 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_420 for ONNX node: Flatten_420\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.212 for ONNX tensor: input.212\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_420 [Flatten] outputs: [input.212 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_421 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.212\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_421 [BatchNormalization] inputs: [input.212 -> (-1, 512)[FLOAT]], [blocks.14.m.qkv.bn.weight -> (512)[FLOAT]], [blocks.14.m.qkv.bn.bias -> (512)[FLOAT]], [blocks.14.m.qkv.bn.running_mean -> (512)[FLOAT]], [blocks.14.m.qkv.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_421 for ONNX node: BatchNormalization_421\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_939 for ONNX tensor: onnx::Reshape_939\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_421 [BatchNormalization] outputs: [onnx::Reshape_939 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_422 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_937\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_422 [Shape] inputs: [onnx::Flatten_937 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_422 for ONNX node: Shape_422\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_940 for ONNX tensor: onnx::Reshape_940\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_422 [Shape] outputs: [onnx::Reshape_940 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_423 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_939\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_940\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_423 [Reshape] inputs: [onnx::Reshape_939 -> (-1, 512)[FLOAT]], [onnx::Reshape_940 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_423 for ONNX node: Reshape_423\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_941 for ONNX tensor: onnx::Reshape_941\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_423 [Reshape] outputs: [onnx::Reshape_941 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_424 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_932\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_424 [Unsqueeze] inputs: [onnx::Unsqueeze_932 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_424 for ONNX node: Unsqueeze_424\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_944 for ONNX tensor: onnx::Concat_944\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_424 [Unsqueeze] outputs: [onnx::Concat_944 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_425 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_935\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_425 [Unsqueeze] inputs: [onnx::Unsqueeze_935 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_425 for ONNX node: Unsqueeze_425\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_945 for ONNX tensor: onnx::Concat_945\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_425 [Unsqueeze] outputs: [onnx::Concat_945 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_426 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_944\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_945\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1500\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1501\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_426 [Concat] inputs: [onnx::Concat_944 -> (1)[INT32]], [onnx::Concat_945 -> (1)[INT32]], [onnx::Concat_1500 -> (1)[INT32]], [onnx::Concat_1501 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1500 for ONNX node: onnx::Concat_1500\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1501 for ONNX node: onnx::Concat_1501\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_426 for ONNX node: Concat_426\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_948 for ONNX tensor: onnx::Reshape_948\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_426 [Concat] outputs: [onnx::Reshape_948 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_427 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_941\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_948\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_427 [Reshape] inputs: [onnx::Reshape_941 -> (-1, -1, 512)[FLOAT]], [onnx::Reshape_948 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_427 for ONNX node: Reshape_427\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Split_949 for ONNX tensor: onnx::Split_949\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_427 [Reshape] outputs: [onnx::Split_949 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Split_428 [Split]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Split_949\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_428 [Split] inputs: [onnx::Split_949 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_428 for ONNX node: Split_428\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_428_386 for ONNX node: Split_428\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_428_388 for ONNX node: Split_428\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_950 for ONNX tensor: onnx::Transpose_950\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_951 for ONNX tensor: onnx::Transpose_951\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_952 for ONNX tensor: onnx::Transpose_952\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_428 [Split] outputs: [onnx::Transpose_950 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_951 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_952 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_429 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_950\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_429 [Transpose] inputs: [onnx::Transpose_950 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_429 for ONNX node: Transpose_429\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_953 for ONNX tensor: onnx::MatMul_953\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_429 [Transpose] outputs: [onnx::MatMul_953 -> (-1, 8, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_430 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_952\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_430 [Transpose] inputs: [onnx::Transpose_952 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_430 for ONNX node: Transpose_430\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_954 for ONNX tensor: onnx::MatMul_954\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_430 [Transpose] outputs: [onnx::MatMul_954 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_431 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_951\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_431 [Transpose] inputs: [onnx::Transpose_951 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_431 for ONNX node: Transpose_431\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_955 for ONNX tensor: onnx::MatMul_955\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_431 [Transpose] outputs: [onnx::MatMul_955 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_432 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_953\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_955\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_432 [MatMul] inputs: [onnx::MatMul_953 -> (-1, 8, -1, 16)[FLOAT]], [onnx::MatMul_955 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_432 for ONNX node: MatMul_432\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_956 for ONNX tensor: onnx::Mul_956\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_432 [MatMul] outputs: [onnx::Mul_956 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_433 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_433 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_433 [Constant] outputs: [onnx::Mul_957 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_434 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_956\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_957\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_434 [Mul] inputs: [onnx::Mul_956 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Mul_957 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Mul_957 for ONNX node: onnx::Mul_957\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_434 for ONNX node: Mul_434\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_958 for ONNX tensor: onnx::Add_958\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_434 [Mul] outputs: [onnx::Add_958 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_435 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_435 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_435 [Constant] outputs: [onnx::Add_959 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_436 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_958\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_959\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_436 [Add] inputs: [onnx::Add_958 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Add_959 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Add_959 for ONNX node: onnx::Add_959\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_436 for ONNX node: Add_436\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Softmax_960 for ONNX tensor: onnx::Softmax_960\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_436 [Add] outputs: [onnx::Softmax_960 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Softmax_437 [Softmax]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Softmax_960\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_437 [Softmax] inputs: [onnx::Softmax_960 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Softmax_437 for ONNX node: Softmax_437\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_961 for ONNX tensor: onnx::MatMul_961\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_437 [Softmax] outputs: [onnx::MatMul_961 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_438 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_961\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_954\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_438 [MatMul] inputs: [onnx::MatMul_961 -> (-1, 8, 49, 49)[FLOAT]], [onnx::MatMul_954 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_438 for ONNX node: MatMul_438\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_962 for ONNX tensor: onnx::Transpose_962\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_438 [MatMul] outputs: [onnx::Transpose_962 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_439 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_962\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_439 [Transpose] inputs: [onnx::Transpose_962 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_439 for ONNX node: Transpose_439\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_963 for ONNX tensor: onnx::Reshape_963\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_439 [Transpose] outputs: [onnx::Reshape_963 -> (-1, 49, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_440 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_932\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_440 [Unsqueeze] inputs: [onnx::Unsqueeze_932 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_440 for ONNX node: Unsqueeze_440\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_965 for ONNX tensor: onnx::Concat_965\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_440 [Unsqueeze] outputs: [onnx::Concat_965 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_441 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_935\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_441 [Unsqueeze] inputs: [onnx::Unsqueeze_935 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_441 for ONNX node: Unsqueeze_441\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_966 for ONNX tensor: onnx::Concat_966\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_441 [Unsqueeze] outputs: [onnx::Concat_966 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_442 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_965\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_966\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1502\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_442 [Concat] inputs: [onnx::Concat_965 -> (1)[INT32]], [onnx::Concat_966 -> (1)[INT32]], [onnx::Concat_1502 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1502 for ONNX node: onnx::Concat_1502\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_442 for ONNX node: Concat_442\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_968 for ONNX tensor: onnx::Reshape_968\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_442 [Concat] outputs: [onnx::Reshape_968 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_443 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_963\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_968\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_443 [Reshape] inputs: [onnx::Reshape_963 -> (-1, 49, 8, 32)[FLOAT]], [onnx::Reshape_968 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_443 for ONNX node: Reshape_443\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.216 for ONNX tensor: input.216\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_443 [Reshape] outputs: [input.216 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_444 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.216\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_444 [HardSigmoid] inputs: [input.216 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_444 for ONNX node: HardSigmoid_444\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_970 for ONNX tensor: onnx::Mul_970\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_444 [HardSigmoid] outputs: [onnx::Mul_970 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_445 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.216\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_970\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_445 [Mul] inputs: [input.216 -> (-1, -1, 256)[FLOAT]], [onnx::Mul_970 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_445 for ONNX node: Mul_445\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_971 for ONNX tensor: onnx::MatMul_971\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_445 [Mul] outputs: [onnx::MatMul_971 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_446 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_971\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1503\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_446 [MatMul] inputs: [onnx::MatMul_971 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1503 -> (256, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1503 for ONNX node: onnx::MatMul_1503\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_446 for ONNX node: MatMul_446\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_973 for ONNX tensor: onnx::Flatten_973\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_446 [MatMul] outputs: [onnx::Flatten_973 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_447 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_973\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_447 [Flatten] inputs: [onnx::Flatten_973 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_447 for ONNX node: Flatten_447\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.220 for ONNX tensor: input.220\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_447 [Flatten] outputs: [input.220 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_448 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.220\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.14.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_448 [BatchNormalization] inputs: [input.220 -> (-1, 256)[FLOAT]], [blocks.14.m.proj.1.bn.weight -> (256)[FLOAT]], [blocks.14.m.proj.1.bn.bias -> (256)[FLOAT]], [blocks.14.m.proj.1.bn.running_mean -> (256)[FLOAT]], [blocks.14.m.proj.1.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_448 for ONNX node: BatchNormalization_448\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_975 for ONNX tensor: onnx::Reshape_975\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_448 [BatchNormalization] outputs: [onnx::Reshape_975 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_449 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_973\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_449 [Shape] inputs: [onnx::Flatten_973 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_449 for ONNX node: Shape_449\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_976 for ONNX tensor: onnx::Reshape_976\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_449 [Shape] outputs: [onnx::Reshape_976 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_450 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_975\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_976\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_450 [Reshape] inputs: [onnx::Reshape_975 -> (-1, 256)[FLOAT]], [onnx::Reshape_976 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_450 for ONNX node: Reshape_450\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_977 for ONNX tensor: onnx::Add_977\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_450 [Reshape] outputs: [onnx::Add_977 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_451 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_929\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_977\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_451 [Add] inputs: [onnx::Shape_929 -> (-1, -1, 256)[FLOAT]], [onnx::Add_977 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_451 for ONNX node: Add_451\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_978 for ONNX tensor: onnx::MatMul_978\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_451 [Add] outputs: [onnx::MatMul_978 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_452 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_978\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1504\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_452 [MatMul] inputs: [onnx::MatMul_978 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1504 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1504 for ONNX node: onnx::MatMul_1504\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_452 for ONNX node: MatMul_452\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_980 for ONNX tensor: onnx::Flatten_980\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_452 [MatMul] outputs: [onnx::Flatten_980 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_453 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_980\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_453 [Flatten] inputs: [onnx::Flatten_980 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_453 for ONNX node: Flatten_453\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.224 for ONNX tensor: input.224\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_453 [Flatten] outputs: [input.224 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_454 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.224\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.0.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.0.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.0.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_454 [BatchNormalization] inputs: [input.224 -> (-1, 512)[FLOAT]], [blocks.15.m.0.bn.weight -> (512)[FLOAT]], [blocks.15.m.0.bn.bias -> (512)[FLOAT]], [blocks.15.m.0.bn.running_mean -> (512)[FLOAT]], [blocks.15.m.0.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_454 for ONNX node: BatchNormalization_454\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_982 for ONNX tensor: onnx::Reshape_982\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_454 [BatchNormalization] outputs: [onnx::Reshape_982 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_455 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_980\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_455 [Shape] inputs: [onnx::Flatten_980 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_455 for ONNX node: Shape_455\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_983 for ONNX tensor: onnx::Reshape_983\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_455 [Shape] outputs: [onnx::Reshape_983 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_456 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_982\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_983\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_456 [Reshape] inputs: [onnx::Reshape_982 -> (-1, 512)[FLOAT]], [onnx::Reshape_983 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_456 for ONNX node: Reshape_456\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.228 for ONNX tensor: input.228\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_456 [Reshape] outputs: [input.228 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: HardSigmoid_457 [HardSigmoid]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.228\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_457 [HardSigmoid] inputs: [input.228 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: HardSigmoid_457 for ONNX node: HardSigmoid_457\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_985 for ONNX tensor: onnx::Mul_985\n",
      "[05/24/2022-15:21:30] [TRT] [V] HardSigmoid_457 [HardSigmoid] outputs: [onnx::Mul_985 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_458 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.228\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_985\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_458 [Mul] inputs: [input.228 -> (-1, -1, 512)[FLOAT]], [onnx::Mul_985 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_458 for ONNX node: Mul_458\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_986 for ONNX tensor: onnx::MatMul_986\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_458 [Mul] outputs: [onnx::MatMul_986 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_459 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_986\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1505\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_459 [MatMul] inputs: [onnx::MatMul_986 -> (-1, -1, 512)[FLOAT]], [onnx::MatMul_1505 -> (512, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1505 for ONNX node: onnx::MatMul_1505\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_459 for ONNX node: MatMul_459\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_988 for ONNX tensor: onnx::Flatten_988\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_459 [MatMul] outputs: [onnx::Flatten_988 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_460 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_988\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_460 [Flatten] inputs: [onnx::Flatten_988 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_460 for ONNX node: Flatten_460\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.232 for ONNX tensor: input.232\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_460 [Flatten] outputs: [input.232 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_461 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.232\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.2.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.2.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.15.m.2.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_461 [BatchNormalization] inputs: [input.232 -> (-1, 256)[FLOAT]], [blocks.15.m.2.bn.weight -> (256)[FLOAT]], [blocks.15.m.2.bn.bias -> (256)[FLOAT]], [blocks.15.m.2.bn.running_mean -> (256)[FLOAT]], [blocks.15.m.2.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_461 for ONNX node: BatchNormalization_461\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_990 for ONNX tensor: onnx::Reshape_990\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_461 [BatchNormalization] outputs: [onnx::Reshape_990 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_462 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_988\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_462 [Shape] inputs: [onnx::Flatten_988 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_462 for ONNX node: Shape_462\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_991 for ONNX tensor: onnx::Reshape_991\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_462 [Shape] outputs: [onnx::Reshape_991 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_463 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_990\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_991\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_463 [Reshape] inputs: [onnx::Reshape_990 -> (-1, 256)[FLOAT]], [onnx::Reshape_991 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_463 for ONNX node: Reshape_463\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_992 for ONNX tensor: onnx::Add_992\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_463 [Reshape] outputs: [onnx::Add_992 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_464 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_978\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_992\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_464 [Add] inputs: [onnx::MatMul_978 -> (-1, -1, 256)[FLOAT]], [onnx::Add_992 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_464 for ONNX node: Add_464\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Shape_993 for ONNX tensor: onnx::Shape_993\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_464 [Add] outputs: [onnx::Shape_993 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_465 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_993\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_465 [Shape] inputs: [onnx::Shape_993 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_465 for ONNX node: Shape_465\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_994 for ONNX tensor: onnx::Gather_994\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_465 [Shape] outputs: [onnx::Gather_994 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_466 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_466 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_466 [Constant] outputs: [onnx::Gather_995 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_467 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_994\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_995\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_467 [Gather] inputs: [onnx::Gather_994 -> (3)[INT32]], [onnx::Gather_995 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_995 for ONNX node: onnx::Gather_995\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_467 for ONNX node: Gather_467\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_996 for ONNX tensor: onnx::Unsqueeze_996\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_467 [Gather] outputs: [onnx::Unsqueeze_996 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_468 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_993\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_468 [Shape] inputs: [onnx::Shape_993 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_468 for ONNX node: Shape_468\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Gather_997 for ONNX tensor: onnx::Gather_997\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_468 [Shape] outputs: [onnx::Gather_997 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_469 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_469 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_469 [Constant] outputs: [onnx::Gather_998 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Gather_470 [Gather]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_997\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Gather_998\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_470 [Gather] inputs: [onnx::Gather_997 -> (3)[INT32]], [onnx::Gather_998 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Gather_998 for ONNX node: onnx::Gather_998\n",
      "[05/24/2022-15:21:30] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Gather_470 for ONNX node: Gather_470\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Unsqueeze_999 for ONNX tensor: onnx::Unsqueeze_999\n",
      "[05/24/2022-15:21:30] [TRT] [V] Gather_470 [Gather] outputs: [onnx::Unsqueeze_999 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_471 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Shape_993\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1506\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_471 [MatMul] inputs: [onnx::Shape_993 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1506 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::MatMul_1506 for ONNX node: onnx::MatMul_1506\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_471 for ONNX node: MatMul_471\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Flatten_1001 for ONNX tensor: onnx::Flatten_1001\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_471 [MatMul] outputs: [onnx::Flatten_1001 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Flatten_472 [Flatten]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_1001\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_472 [Flatten] inputs: [onnx::Flatten_1001 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Flatten_472 for ONNX node: Flatten_472\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: input.236 for ONNX tensor: input.236\n",
      "[05/24/2022-15:21:30] [TRT] [V] Flatten_472 [Flatten] outputs: [input.236 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: BatchNormalization_473 [BatchNormalization]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: input.236\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.16.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.16.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.16.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: blocks.16.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_473 [BatchNormalization] inputs: [input.236 -> (-1, 512)[FLOAT]], [blocks.16.m.qkv.bn.weight -> (512)[FLOAT]], [blocks.16.m.qkv.bn.bias -> (512)[FLOAT]], [blocks.16.m.qkv.bn.running_mean -> (512)[FLOAT]], [blocks.16.m.qkv.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: BatchNormalization_473 for ONNX node: BatchNormalization_473\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_1003 for ONNX tensor: onnx::Reshape_1003\n",
      "[05/24/2022-15:21:30] [TRT] [V] BatchNormalization_473 [BatchNormalization] outputs: [onnx::Reshape_1003 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Shape_474 [Shape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Flatten_1001\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_474 [Shape] inputs: [onnx::Flatten_1001 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Shape_474 for ONNX node: Shape_474\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_1004 for ONNX tensor: onnx::Reshape_1004\n",
      "[05/24/2022-15:21:30] [TRT] [V] Shape_474 [Shape] outputs: [onnx::Reshape_1004 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_475 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_1003\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_1004\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_475 [Reshape] inputs: [onnx::Reshape_1003 -> (-1, 512)[FLOAT]], [onnx::Reshape_1004 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_475 for ONNX node: Reshape_475\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_1005 for ONNX tensor: onnx::Reshape_1005\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_475 [Reshape] outputs: [onnx::Reshape_1005 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_476 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_996\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_476 [Unsqueeze] inputs: [onnx::Unsqueeze_996 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_476 for ONNX node: Unsqueeze_476\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_1008 for ONNX tensor: onnx::Concat_1008\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_476 [Unsqueeze] outputs: [onnx::Concat_1008 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Unsqueeze_477 [Unsqueeze]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Unsqueeze_999\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_477 [Unsqueeze] inputs: [onnx::Unsqueeze_999 -> ()[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Unsqueeze_477 for ONNX node: Unsqueeze_477\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Concat_1009 for ONNX tensor: onnx::Concat_1009\n",
      "[05/24/2022-15:21:30] [TRT] [V] Unsqueeze_477 [Unsqueeze] outputs: [onnx::Concat_1009 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Concat_478 [Concat]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1008\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1009\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1507\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Concat_1508\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_478 [Concat] inputs: [onnx::Concat_1008 -> (1)[INT32]], [onnx::Concat_1009 -> (1)[INT32]], [onnx::Concat_1507 -> (1)[INT32]], [onnx::Concat_1508 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1507 for ONNX node: onnx::Concat_1507\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Concat_1508 for ONNX node: onnx::Concat_1508\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Concat_478 for ONNX node: Concat_478\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Reshape_1012 for ONNX tensor: onnx::Reshape_1012\n",
      "[05/24/2022-15:21:30] [TRT] [V] Concat_478 [Concat] outputs: [onnx::Reshape_1012 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Reshape_479 [Reshape]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_1005\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Reshape_1012\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_479 [Reshape] inputs: [onnx::Reshape_1005 -> (-1, -1, 512)[FLOAT]], [onnx::Reshape_1012 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Reshape_479 for ONNX node: Reshape_479\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Split_1013 for ONNX tensor: onnx::Split_1013\n",
      "[05/24/2022-15:21:30] [TRT] [V] Reshape_479 [Reshape] outputs: [onnx::Split_1013 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Split_480 [Split]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Split_1013\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_480 [Split] inputs: [onnx::Split_1013 -> (-1, -1, 8, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_480 for ONNX node: Split_480\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_480_426 for ONNX node: Split_480\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Split_480_428 for ONNX node: Split_480\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_1014 for ONNX tensor: onnx::Transpose_1014\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_1015 for ONNX tensor: onnx::Transpose_1015\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Transpose_1016 for ONNX tensor: onnx::Transpose_1016\n",
      "[05/24/2022-15:21:30] [TRT] [V] Split_480 [Split] outputs: [onnx::Transpose_1014 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_1015 -> (-1, -1, 8, 16)[FLOAT]], [onnx::Transpose_1016 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_481 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_1014\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_481 [Transpose] inputs: [onnx::Transpose_1014 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_481 for ONNX node: Transpose_481\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_1017 for ONNX tensor: onnx::MatMul_1017\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_481 [Transpose] outputs: [onnx::MatMul_1017 -> (-1, 8, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_482 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_1016\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_482 [Transpose] inputs: [onnx::Transpose_1016 -> (-1, -1, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_482 for ONNX node: Transpose_482\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_1018 for ONNX tensor: onnx::MatMul_1018\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_482 [Transpose] outputs: [onnx::MatMul_1018 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Transpose_483 [Transpose]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Transpose_1015\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_483 [Transpose] inputs: [onnx::Transpose_1015 -> (-1, -1, 8, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Transpose_483 for ONNX node: Transpose_483\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::MatMul_1019 for ONNX tensor: onnx::MatMul_1019\n",
      "[05/24/2022-15:21:30] [TRT] [V] Transpose_483 [Transpose] outputs: [onnx::MatMul_1019 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: MatMul_484 [MatMul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1017\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::MatMul_1019\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_484 [MatMul] inputs: [onnx::MatMul_1017 -> (-1, 8, -1, 16)[FLOAT]], [onnx::MatMul_1019 -> (-1, 8, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: MatMul_484 for ONNX node: MatMul_484\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Mul_1020 for ONNX tensor: onnx::Mul_1020\n",
      "[05/24/2022-15:21:30] [TRT] [V] MatMul_484 [MatMul] outputs: [onnx::Mul_1020 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_485 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_485 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_485 [Constant] outputs: [onnx::Mul_1021 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Mul_486 [Mul]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_1020\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Mul_1021\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_486 [Mul] inputs: [onnx::Mul_1020 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Mul_1021 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Mul_1021 for ONNX node: onnx::Mul_1021\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Mul_486 for ONNX node: Mul_486\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Add_1022 for ONNX tensor: onnx::Add_1022\n",
      "[05/24/2022-15:21:30] [TRT] [V] Mul_486 [Mul] outputs: [onnx::Add_1022 -> (-1, 8, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Constant_487 [Constant]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_487 [Constant] inputs: \n",
      "[05/24/2022-15:21:30] [TRT] [V] Constant_487 [Constant] outputs: [onnx::Add_1023 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Add_488 [Add]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_1022\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Add_1023\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_488 [Add] inputs: [onnx::Add_1022 -> (-1, 8, -1, -1)[FLOAT]], [onnx::Add_1023 -> (8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: onnx::Add_1023 for ONNX node: onnx::Add_1023\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering layer: Add_488 for ONNX node: Add_488\n",
      "[05/24/2022-15:21:30] [TRT] [V] Registering tensor: onnx::Softmax_1024 for ONNX tensor: onnx::Softmax_1024\n",
      "[05/24/2022-15:21:30] [TRT] [V] Add_488 [Add] outputs: [onnx::Softmax_1024 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:30] [TRT] [V] Parsing node: Softmax_489 [Softmax]\n",
      "[05/24/2022-15:21:30] [TRT] [V] Searching for input: onnx::Softmax_1024\n",
      "[05/24/2022-15:21:30] [TRT] [V] Softmax_489 [Softmax] inputs: [onnx::Softmax_1024 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Softmax_489 for ONNX node: Softmax_489\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1025 for ONNX tensor: onnx::MatMul_1025\n",
      "[05/24/2022-15:21:31] [TRT] [V] Softmax_489 [Softmax] outputs: [onnx::MatMul_1025 -> (-1, 8, 49, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_490 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1025\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1018\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_490 [MatMul] inputs: [onnx::MatMul_1025 -> (-1, 8, 49, 49)[FLOAT]], [onnx::MatMul_1018 -> (-1, 8, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_490 for ONNX node: MatMul_490\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1026 for ONNX tensor: onnx::Transpose_1026\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_490 [MatMul] outputs: [onnx::Transpose_1026 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_491 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1026\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_491 [Transpose] inputs: [onnx::Transpose_1026 -> (-1, 8, 49, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_491 for ONNX node: Transpose_491\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1027 for ONNX tensor: onnx::Reshape_1027\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_491 [Transpose] outputs: [onnx::Reshape_1027 -> (-1, 49, 8, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_492 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_996\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_492 [Unsqueeze] inputs: [onnx::Unsqueeze_996 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_492 for ONNX node: Unsqueeze_492\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1029 for ONNX tensor: onnx::Concat_1029\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_492 [Unsqueeze] outputs: [onnx::Concat_1029 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_493 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_999\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_493 [Unsqueeze] inputs: [onnx::Unsqueeze_999 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_493 for ONNX node: Unsqueeze_493\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1030 for ONNX tensor: onnx::Concat_1030\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_493 [Unsqueeze] outputs: [onnx::Concat_1030 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_494 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1029\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1030\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1509\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_494 [Concat] inputs: [onnx::Concat_1029 -> (1)[INT32]], [onnx::Concat_1030 -> (1)[INT32]], [onnx::Concat_1509 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1509 for ONNX node: onnx::Concat_1509\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_494 for ONNX node: Concat_494\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1032 for ONNX tensor: onnx::Reshape_1032\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_494 [Concat] outputs: [onnx::Reshape_1032 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_495 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1027\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1032\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_495 [Reshape] inputs: [onnx::Reshape_1027 -> (-1, 49, 8, 32)[FLOAT]], [onnx::Reshape_1032 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_495 for ONNX node: Reshape_495\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.240 for ONNX tensor: input.240\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_495 [Reshape] outputs: [input.240 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: HardSigmoid_496 [HardSigmoid]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.240\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_496 [HardSigmoid] inputs: [input.240 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: HardSigmoid_496 for ONNX node: HardSigmoid_496\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Mul_1034 for ONNX tensor: onnx::Mul_1034\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_496 [HardSigmoid] outputs: [onnx::Mul_1034 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Mul_497 [Mul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.240\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1034\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_497 [Mul] inputs: [input.240 -> (-1, -1, 256)[FLOAT]], [onnx::Mul_1034 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Mul_497 for ONNX node: Mul_497\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1035 for ONNX tensor: onnx::MatMul_1035\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_497 [Mul] outputs: [onnx::MatMul_1035 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_498 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1035\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1510\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_498 [MatMul] inputs: [onnx::MatMul_1035 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1510 -> (256, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1510 for ONNX node: onnx::MatMul_1510\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_498 for ONNX node: MatMul_498\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1037 for ONNX tensor: onnx::Flatten_1037\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_498 [MatMul] outputs: [onnx::Flatten_1037 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_499 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1037\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_499 [Flatten] inputs: [onnx::Flatten_1037 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_499 for ONNX node: Flatten_499\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.244 for ONNX tensor: input.244\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_499 [Flatten] outputs: [input.244 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_500 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.244\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.16.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.16.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.16.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.16.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_500 [BatchNormalization] inputs: [input.244 -> (-1, 256)[FLOAT]], [blocks.16.m.proj.1.bn.weight -> (256)[FLOAT]], [blocks.16.m.proj.1.bn.bias -> (256)[FLOAT]], [blocks.16.m.proj.1.bn.running_mean -> (256)[FLOAT]], [blocks.16.m.proj.1.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_500 for ONNX node: BatchNormalization_500\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1039 for ONNX tensor: onnx::Reshape_1039\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_500 [BatchNormalization] outputs: [onnx::Reshape_1039 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_501 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1037\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_501 [Shape] inputs: [onnx::Flatten_1037 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_501 for ONNX node: Shape_501\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1040 for ONNX tensor: onnx::Reshape_1040\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_501 [Shape] outputs: [onnx::Reshape_1040 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_502 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1039\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1040\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_502 [Reshape] inputs: [onnx::Reshape_1039 -> (-1, 256)[FLOAT]], [onnx::Reshape_1040 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_502 for ONNX node: Reshape_502\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Add_1041 for ONNX tensor: onnx::Add_1041\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_502 [Reshape] outputs: [onnx::Add_1041 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Add_503 [Add]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_993\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1041\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_503 [Add] inputs: [onnx::Shape_993 -> (-1, -1, 256)[FLOAT]], [onnx::Add_1041 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Add_503 for ONNX node: Add_503\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1042 for ONNX tensor: onnx::MatMul_1042\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_503 [Add] outputs: [onnx::MatMul_1042 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_504 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1042\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1511\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_504 [MatMul] inputs: [onnx::MatMul_1042 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1511 -> (256, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1511 for ONNX node: onnx::MatMul_1511\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_504 for ONNX node: MatMul_504\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1044 for ONNX tensor: onnx::Flatten_1044\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_504 [MatMul] outputs: [onnx::Flatten_1044 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_505 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1044\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_505 [Flatten] inputs: [onnx::Flatten_1044 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_505 for ONNX node: Flatten_505\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.248 for ONNX tensor: input.248\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_505 [Flatten] outputs: [input.248 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_506 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.248\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.0.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.0.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.0.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_506 [BatchNormalization] inputs: [input.248 -> (-1, 512)[FLOAT]], [blocks.17.m.0.bn.weight -> (512)[FLOAT]], [blocks.17.m.0.bn.bias -> (512)[FLOAT]], [blocks.17.m.0.bn.running_mean -> (512)[FLOAT]], [blocks.17.m.0.bn.running_var -> (512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 512), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_506 for ONNX node: BatchNormalization_506\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1046 for ONNX tensor: onnx::Reshape_1046\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_506 [BatchNormalization] outputs: [onnx::Reshape_1046 -> (-1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_507 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1044\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_507 [Shape] inputs: [onnx::Flatten_1044 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_507 for ONNX node: Shape_507\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1047 for ONNX tensor: onnx::Reshape_1047\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_507 [Shape] outputs: [onnx::Reshape_1047 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_508 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1046\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1047\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_508 [Reshape] inputs: [onnx::Reshape_1046 -> (-1, 512)[FLOAT]], [onnx::Reshape_1047 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_508 for ONNX node: Reshape_508\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.252 for ONNX tensor: input.252\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_508 [Reshape] outputs: [input.252 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: HardSigmoid_509 [HardSigmoid]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.252\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_509 [HardSigmoid] inputs: [input.252 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: HardSigmoid_509 for ONNX node: HardSigmoid_509\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Mul_1049 for ONNX tensor: onnx::Mul_1049\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_509 [HardSigmoid] outputs: [onnx::Mul_1049 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Mul_510 [Mul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.252\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1049\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_510 [Mul] inputs: [input.252 -> (-1, -1, 512)[FLOAT]], [onnx::Mul_1049 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Mul_510 for ONNX node: Mul_510\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1050 for ONNX tensor: onnx::MatMul_1050\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_510 [Mul] outputs: [onnx::MatMul_1050 -> (-1, -1, 512)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_511 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1050\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1512\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_511 [MatMul] inputs: [onnx::MatMul_1050 -> (-1, -1, 512)[FLOAT]], [onnx::MatMul_1512 -> (512, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1512 for ONNX node: onnx::MatMul_1512\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_511 for ONNX node: MatMul_511\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1052 for ONNX tensor: onnx::Flatten_1052\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_511 [MatMul] outputs: [onnx::Flatten_1052 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_512 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1052\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_512 [Flatten] inputs: [onnx::Flatten_1052 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_512 for ONNX node: Flatten_512\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.256 for ONNX tensor: input.256\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_512 [Flatten] outputs: [input.256 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_513 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.256\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.2.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.2.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.17.m.2.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_513 [BatchNormalization] inputs: [input.256 -> (-1, 256)[FLOAT]], [blocks.17.m.2.bn.weight -> (256)[FLOAT]], [blocks.17.m.2.bn.bias -> (256)[FLOAT]], [blocks.17.m.2.bn.running_mean -> (256)[FLOAT]], [blocks.17.m.2.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_513 for ONNX node: BatchNormalization_513\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1054 for ONNX tensor: onnx::Reshape_1054\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_513 [BatchNormalization] outputs: [onnx::Reshape_1054 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_514 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1052\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_514 [Shape] inputs: [onnx::Flatten_1052 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_514 for ONNX node: Shape_514\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1055 for ONNX tensor: onnx::Reshape_1055\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_514 [Shape] outputs: [onnx::Reshape_1055 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_515 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1054\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1055\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_515 [Reshape] inputs: [onnx::Reshape_1054 -> (-1, 256)[FLOAT]], [onnx::Reshape_1055 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_515 for ONNX node: Reshape_515\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Add_1056 for ONNX tensor: onnx::Add_1056\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_515 [Reshape] outputs: [onnx::Add_1056 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Add_516 [Add]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1042\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1056\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_516 [Add] inputs: [onnx::MatMul_1042 -> (-1, -1, 256)[FLOAT]], [onnx::Add_1056 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Add_516 for ONNX node: Add_516\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Shape_1057 for ONNX tensor: onnx::Shape_1057\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_516 [Add] outputs: [onnx::Shape_1057 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_517 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1057\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_517 [Shape] inputs: [onnx::Shape_1057 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_517 for ONNX node: Shape_517\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Gather_1058 for ONNX tensor: onnx::Gather_1058\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_517 [Shape] outputs: [onnx::Gather_1058 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_518 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_518 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_518 [Constant] outputs: [onnx::Gather_1059 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Gather_519 [Gather]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1058\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1059\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_519 [Gather] inputs: [onnx::Gather_1058 -> (3)[INT32]], [onnx::Gather_1059 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Gather_1059 for ONNX node: onnx::Gather_1059\n",
      "[05/24/2022-15:21:31] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Gather_519 for ONNX node: Gather_519\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Unsqueeze_1060 for ONNX tensor: onnx::Unsqueeze_1060\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_519 [Gather] outputs: [onnx::Unsqueeze_1060 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_520 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1057\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_520 [Shape] inputs: [onnx::Shape_1057 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_520 for ONNX node: Shape_520\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Gather_1061 for ONNX tensor: onnx::Gather_1061\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_520 [Shape] outputs: [onnx::Gather_1061 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_521 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_521 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_521 [Constant] outputs: [onnx::Gather_1062 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Gather_522 [Gather]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1061\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1062\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_522 [Gather] inputs: [onnx::Gather_1061 -> (3)[INT32]], [onnx::Gather_1062 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Gather_1062 for ONNX node: onnx::Gather_1062\n",
      "[05/24/2022-15:21:31] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Gather_522 for ONNX node: Gather_522\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Unsqueeze_1063 for ONNX tensor: onnx::Unsqueeze_1063\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_522 [Gather] outputs: [onnx::Unsqueeze_1063 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_523 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1057\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1513\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_523 [MatMul] inputs: [onnx::Shape_1057 -> (-1, -1, 256)[FLOAT]], [onnx::MatMul_1513 -> (256, 1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1513 for ONNX node: onnx::MatMul_1513\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_523 for ONNX node: MatMul_523\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1065 for ONNX tensor: onnx::Flatten_1065\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_523 [MatMul] outputs: [onnx::Flatten_1065 -> (-1, -1, 1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_524 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1065\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_524 [Flatten] inputs: [onnx::Flatten_1065 -> (-1, -1, 1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_524 for ONNX node: Flatten_524\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.260 for ONNX tensor: input.260\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_524 [Flatten] outputs: [input.260 -> (-1, 1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_525 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.260\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.kv.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.kv.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.kv.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.kv.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_525 [BatchNormalization] inputs: [input.260 -> (-1, 1280)[FLOAT]], [blocks.18.kv.bn.weight -> (1280)[FLOAT]], [blocks.18.kv.bn.bias -> (1280)[FLOAT]], [blocks.18.kv.bn.running_mean -> (1280)[FLOAT]], [blocks.18.kv.bn.running_var -> (1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 1280), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_525 for ONNX node: BatchNormalization_525\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1067 for ONNX tensor: onnx::Reshape_1067\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_525 [BatchNormalization] outputs: [onnx::Reshape_1067 -> (-1, 1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_526 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1065\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_526 [Shape] inputs: [onnx::Flatten_1065 -> (-1, -1, 1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_526 for ONNX node: Shape_526\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1068 for ONNX tensor: onnx::Reshape_1068\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_526 [Shape] outputs: [onnx::Reshape_1068 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_527 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1067\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1068\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_527 [Reshape] inputs: [onnx::Reshape_1067 -> (-1, 1280)[FLOAT]], [onnx::Reshape_1068 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_527 for ONNX node: Reshape_527\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1069 for ONNX tensor: onnx::Reshape_1069\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_527 [Reshape] outputs: [onnx::Reshape_1069 -> (-1, -1, 1280)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_528 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1060\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_528 [Unsqueeze] inputs: [onnx::Unsqueeze_1060 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_528 for ONNX node: Unsqueeze_528\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1072 for ONNX tensor: onnx::Concat_1072\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_528 [Unsqueeze] outputs: [onnx::Concat_1072 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_529 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1063\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_529 [Unsqueeze] inputs: [onnx::Unsqueeze_1063 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_529 for ONNX node: Unsqueeze_529\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1073 for ONNX tensor: onnx::Concat_1073\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_529 [Unsqueeze] outputs: [onnx::Concat_1073 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_530 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1072\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1073\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1514\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1515\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_530 [Concat] inputs: [onnx::Concat_1072 -> (1)[INT32]], [onnx::Concat_1073 -> (1)[INT32]], [onnx::Concat_1514 -> (1)[INT32]], [onnx::Concat_1515 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1514 for ONNX node: onnx::Concat_1514\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1515 for ONNX node: onnx::Concat_1515\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_530 for ONNX node: Concat_530\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1076 for ONNX tensor: onnx::Reshape_1076\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_530 [Concat] outputs: [onnx::Reshape_1076 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_531 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1069\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1076\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_531 [Reshape] inputs: [onnx::Reshape_1069 -> (-1, -1, 1280)[FLOAT]], [onnx::Reshape_1076 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_531 for ONNX node: Reshape_531\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Split_1077 for ONNX tensor: onnx::Split_1077\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_531 [Reshape] outputs: [onnx::Split_1077 -> (-1, -1, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Split_532 [Split]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Split_1077\n",
      "[05/24/2022-15:21:31] [TRT] [V] Split_532 [Split] inputs: [onnx::Split_1077 -> (-1, -1, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Split_532 for ONNX node: Split_532\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Split_532_466 for ONNX node: Split_532\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1078 for ONNX tensor: onnx::Transpose_1078\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1079 for ONNX tensor: onnx::Transpose_1079\n",
      "[05/24/2022-15:21:31] [TRT] [V] Split_532 [Split] outputs: [onnx::Transpose_1078 -> (-1, -1, 16, 16)[FLOAT]], [onnx::Transpose_1079 -> (-1, -1, 16, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_533 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1079\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_533 [Transpose] inputs: [onnx::Transpose_1079 -> (-1, -1, 16, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_533 for ONNX node: Transpose_533\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1080 for ONNX tensor: onnx::MatMul_1080\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_533 [Transpose] outputs: [onnx::MatMul_1080 -> (-1, 16, -1, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_534 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1057\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_534 [Shape] inputs: [onnx::Shape_1057 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_534 for ONNX node: Shape_534\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Gather_1081 for ONNX tensor: onnx::Gather_1081\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_534 [Shape] outputs: [onnx::Gather_1081 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_535 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_535 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_535 [Constant] outputs: [onnx::Gather_1082 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Gather_536 [Gather]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1081\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1082\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_536 [Gather] inputs: [onnx::Gather_1081 -> (3)[INT32]], [onnx::Gather_1082 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Gather_1082 for ONNX node: onnx::Gather_1082\n",
      "[05/24/2022-15:21:31] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Gather_536 for ONNX node: Gather_536\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Unsqueeze_1083 for ONNX tensor: onnx::Unsqueeze_1083\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_536 [Gather] outputs: [onnx::Unsqueeze_1083 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_537 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1057\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_537 [Shape] inputs: [onnx::Shape_1057 -> (-1, -1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_537 for ONNX node: Shape_537\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Gather_1084 for ONNX tensor: onnx::Gather_1084\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_537 [Shape] outputs: [onnx::Gather_1084 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_538 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_538 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_538 [Constant] outputs: [onnx::Gather_1085 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Gather_539 [Gather]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1084\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1085\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_539 [Gather] inputs: [onnx::Gather_1084 -> (3)[INT32]], [onnx::Gather_1085 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Gather_1085 for ONNX node: onnx::Gather_1085\n",
      "[05/24/2022-15:21:31] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Gather_539 for ONNX node: Gather_539\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Unsqueeze_1086 for ONNX tensor: onnx::Unsqueeze_1086\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_539 [Gather] outputs: [onnx::Unsqueeze_1086 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_540 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1083\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_540 [Unsqueeze] inputs: [onnx::Unsqueeze_1083 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_540 for ONNX node: Unsqueeze_540\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1089 for ONNX tensor: onnx::Concat_1089\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_540 [Unsqueeze] outputs: [onnx::Concat_1089 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_541 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1086\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_541 [Unsqueeze] inputs: [onnx::Unsqueeze_1086 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_541 for ONNX node: Unsqueeze_541\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1092 for ONNX tensor: onnx::Concat_1092\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_541 [Unsqueeze] outputs: [onnx::Concat_1092 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_542 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1089\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1516\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1517\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1092\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_542 [Concat] inputs: [onnx::Concat_1089 -> (1)[INT32]], [onnx::Concat_1516 -> (1)[INT32]], [onnx::Concat_1517 -> (1)[INT32]], [onnx::Concat_1092 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1516 for ONNX node: onnx::Concat_1516\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1517 for ONNX node: onnx::Concat_1517\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_542 for ONNX node: Concat_542\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1093 for ONNX tensor: onnx::Reshape_1093\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_542 [Concat] outputs: [onnx::Reshape_1093 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_543 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1057\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1093\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_543 [Reshape] inputs: [onnx::Shape_1057 -> (-1, -1, 256)[FLOAT]], [onnx::Reshape_1093 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_543 for ONNX node: Reshape_543\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Slice_1094 for ONNX tensor: onnx::Slice_1094\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_543 [Reshape] outputs: [onnx::Slice_1094 -> (-1, 7, 7, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_544 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_544 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_544 [Constant] outputs: [onnx::Slice_1095 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_545 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_545 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_545 [Constant] outputs: [onnx::Slice_1096 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_546 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_546 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Weight at index 0: 9223372036854775807 is out of range. Clamping to: 2147483647\n",
      "[05/24/2022-15:21:31] [TRT] [W] onnx2trt_utils.cpp:391: One or more weights outside the range of INT32 was clamped\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_546 [Constant] outputs: [onnx::Slice_1097 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_547 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_547 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_547 [Constant] outputs: [onnx::Slice_1098 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Slice_548 [Slice]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1094\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1096\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1097\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1095\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1098\n",
      "[05/24/2022-15:21:31] [TRT] [V] Slice_548 [Slice] inputs: [onnx::Slice_1094 -> (-1, 7, 7, 256)[FLOAT]], [onnx::Slice_1096 -> (1)[INT32]], [onnx::Slice_1097 -> (1)[INT32]], [onnx::Slice_1095 -> (1)[INT32]], [onnx::Slice_1098 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Slice_548 for ONNX node: Slice_548\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Slice_1099 for ONNX tensor: onnx::Slice_1099\n",
      "[05/24/2022-15:21:31] [TRT] [V] Slice_548 [Slice] outputs: [onnx::Slice_1099 -> (-1, 4, 7, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_549 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_549 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_549 [Constant] outputs: [onnx::Slice_1100 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_550 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_550 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_550 [Constant] outputs: [onnx::Slice_1101 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_551 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_551 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Weight at index 0: 9223372036854775807 is out of range. Clamping to: 2147483647\n",
      "[05/24/2022-15:21:31] [TRT] [W] onnx2trt_utils.cpp:391: One or more weights outside the range of INT32 was clamped\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_551 [Constant] outputs: [onnx::Slice_1102 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_552 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_552 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_552 [Constant] outputs: [onnx::Slice_1103 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Slice_553 [Slice]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1099\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1101\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1102\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1100\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Slice_1103\n",
      "[05/24/2022-15:21:31] [TRT] [V] Slice_553 [Slice] inputs: [onnx::Slice_1099 -> (-1, 4, 7, 256)[FLOAT]], [onnx::Slice_1101 -> (1)[INT32]], [onnx::Slice_1102 -> (1)[INT32]], [onnx::Slice_1100 -> (1)[INT32]], [onnx::Slice_1103 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Slice_553 for ONNX node: Slice_553\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1104 for ONNX tensor: onnx::Reshape_1104\n",
      "[05/24/2022-15:21:31] [TRT] [V] Slice_553 [Slice] outputs: [onnx::Reshape_1104 -> (-1, 4, 4, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_554 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1083\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_554 [Unsqueeze] inputs: [onnx::Unsqueeze_1083 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_554 for ONNX node: Unsqueeze_554\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1106 for ONNX tensor: onnx::Concat_1106\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_554 [Unsqueeze] outputs: [onnx::Concat_1106 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_555 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1086\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_555 [Unsqueeze] inputs: [onnx::Unsqueeze_1086 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_555 for ONNX node: Unsqueeze_555\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1108 for ONNX tensor: onnx::Concat_1108\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_555 [Unsqueeze] outputs: [onnx::Concat_1108 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_556 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1106\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1518\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1108\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_556 [Concat] inputs: [onnx::Concat_1106 -> (1)[INT32]], [onnx::Concat_1518 -> (1)[INT32]], [onnx::Concat_1108 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1518 for ONNX node: onnx::Concat_1518\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_556 for ONNX node: Concat_556\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1109 for ONNX tensor: onnx::Reshape_1109\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_556 [Concat] outputs: [onnx::Reshape_1109 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_557 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1104\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1109\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_557 [Reshape] inputs: [onnx::Reshape_1104 -> (-1, 4, 4, 256)[FLOAT]], [onnx::Reshape_1109 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_557 for ONNX node: Reshape_557\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1110 for ONNX tensor: onnx::MatMul_1110\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_557 [Reshape] outputs: [onnx::MatMul_1110 -> (-1, 16, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_558 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1110\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1519\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_558 [MatMul] inputs: [onnx::MatMul_1110 -> (-1, 16, 256)[FLOAT]], [onnx::MatMul_1519 -> (256, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1519 for ONNX node: onnx::MatMul_1519\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_558 for ONNX node: MatMul_558\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1112 for ONNX tensor: onnx::Flatten_1112\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_558 [MatMul] outputs: [onnx::Flatten_1112 -> (-1, 16, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_559 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1112\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_559 [Flatten] inputs: [onnx::Flatten_1112 -> (-1, 16, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_559 for ONNX node: Flatten_559\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.264 for ONNX tensor: input.264\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_559 [Flatten] outputs: [input.264 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_560 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.264\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.q.1.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.q.1.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.q.1.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.q.1.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_560 [BatchNormalization] inputs: [input.264 -> (-1, 256)[FLOAT]], [blocks.18.q.1.bn.weight -> (256)[FLOAT]], [blocks.18.q.1.bn.bias -> (256)[FLOAT]], [blocks.18.q.1.bn.running_mean -> (256)[FLOAT]], [blocks.18.q.1.bn.running_var -> (256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 256), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_560 for ONNX node: BatchNormalization_560\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1114 for ONNX tensor: onnx::Reshape_1114\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_560 [BatchNormalization] outputs: [onnx::Reshape_1114 -> (-1, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_561 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1112\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_561 [Shape] inputs: [onnx::Flatten_1112 -> (-1, 16, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_561 for ONNX node: Shape_561\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1115 for ONNX tensor: onnx::Reshape_1115\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_561 [Shape] outputs: [onnx::Reshape_1115 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_562 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1114\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1115\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_562 [Reshape] inputs: [onnx::Reshape_1114 -> (-1, 256)[FLOAT]], [onnx::Reshape_1115 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_562 for ONNX node: Reshape_562\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1116 for ONNX tensor: onnx::Reshape_1116\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_562 [Reshape] outputs: [onnx::Reshape_1116 -> (-1, 16, 256)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_563 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1060\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_563 [Unsqueeze] inputs: [onnx::Unsqueeze_1060 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_563 for ONNX node: Unsqueeze_563\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1120 for ONNX tensor: onnx::Concat_1120\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_563 [Unsqueeze] outputs: [onnx::Concat_1120 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_564 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1120\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1520\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1521\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1522\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_564 [Concat] inputs: [onnx::Concat_1120 -> (1)[INT32]], [onnx::Concat_1520 -> (1)[INT32]], [onnx::Concat_1521 -> (1)[INT32]], [onnx::Concat_1522 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1520 for ONNX node: onnx::Concat_1520\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1521 for ONNX node: onnx::Concat_1521\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1522 for ONNX node: onnx::Concat_1522\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_564 for ONNX node: Concat_564\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1124 for ONNX tensor: onnx::Reshape_1124\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_564 [Concat] outputs: [onnx::Reshape_1124 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_565 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1116\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1124\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_565 [Reshape] inputs: [onnx::Reshape_1116 -> (-1, 16, 256)[FLOAT]], [onnx::Reshape_1124 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_565 for ONNX node: Reshape_565\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1125 for ONNX tensor: onnx::Transpose_1125\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_565 [Reshape] outputs: [onnx::Transpose_1125 -> (-1, 16, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_566 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1125\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_566 [Transpose] inputs: [onnx::Transpose_1125 -> (-1, 16, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_566 for ONNX node: Transpose_566\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1126 for ONNX tensor: onnx::MatMul_1126\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_566 [Transpose] outputs: [onnx::MatMul_1126 -> (-1, 16, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_567 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1078\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_567 [Transpose] inputs: [onnx::Transpose_1078 -> (-1, -1, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_567 for ONNX node: Transpose_567\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1127 for ONNX tensor: onnx::MatMul_1127\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_567 [Transpose] outputs: [onnx::MatMul_1127 -> (-1, 16, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_568 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1126\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1127\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_568 [MatMul] inputs: [onnx::MatMul_1126 -> (-1, 16, 16, 16)[FLOAT]], [onnx::MatMul_1127 -> (-1, 16, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_568 for ONNX node: MatMul_568\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Mul_1128 for ONNX tensor: onnx::Mul_1128\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_568 [MatMul] outputs: [onnx::Mul_1128 -> (-1, 16, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_569 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_569 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_569 [Constant] outputs: [onnx::Mul_1129 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Mul_570 [Mul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1128\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1129\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_570 [Mul] inputs: [onnx::Mul_1128 -> (-1, 16, 16, -1)[FLOAT]], [onnx::Mul_1129 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Mul_1129 for ONNX node: onnx::Mul_1129\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Mul_570 for ONNX node: Mul_570\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Add_1130 for ONNX tensor: onnx::Add_1130\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_570 [Mul] outputs: [onnx::Add_1130 -> (-1, 16, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_571 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_571 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_571 [Constant] outputs: [onnx::Add_1131 -> (16, 16, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Add_572 [Add]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1130\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1131\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_572 [Add] inputs: [onnx::Add_1130 -> (-1, 16, 16, -1)[FLOAT]], [onnx::Add_1131 -> (16, 16, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Add_1131 for ONNX node: onnx::Add_1131\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Add_572 for ONNX node: Add_572\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Softmax_1132 for ONNX tensor: onnx::Softmax_1132\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_572 [Add] outputs: [onnx::Softmax_1132 -> (-1, 16, 16, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Softmax_573 [Softmax]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Softmax_1132\n",
      "[05/24/2022-15:21:31] [TRT] [V] Softmax_573 [Softmax] inputs: [onnx::Softmax_1132 -> (-1, 16, 16, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Softmax_573 for ONNX node: Softmax_573\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1133 for ONNX tensor: onnx::MatMul_1133\n",
      "[05/24/2022-15:21:31] [TRT] [V] Softmax_573 [Softmax] outputs: [onnx::MatMul_1133 -> (-1, 16, 16, 49)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_574 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1133\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1080\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_574 [MatMul] inputs: [onnx::MatMul_1133 -> (-1, 16, 16, 49)[FLOAT]], [onnx::MatMul_1080 -> (-1, 16, -1, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_574 for ONNX node: MatMul_574\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1134 for ONNX tensor: onnx::Transpose_1134\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_574 [MatMul] outputs: [onnx::Transpose_1134 -> (-1, 16, 16, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_575 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1134\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_575 [Transpose] inputs: [onnx::Transpose_1134 -> (-1, 16, 16, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_575 for ONNX node: Transpose_575\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1135 for ONNX tensor: onnx::Reshape_1135\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_575 [Transpose] outputs: [onnx::Reshape_1135 -> (-1, 16, 16, 64)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_576 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1060\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_576 [Unsqueeze] inputs: [onnx::Unsqueeze_1060 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_576 for ONNX node: Unsqueeze_576\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1138 for ONNX tensor: onnx::Concat_1138\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_576 [Unsqueeze] outputs: [onnx::Concat_1138 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_577 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1138\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1523\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1524\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_577 [Concat] inputs: [onnx::Concat_1138 -> (1)[INT32]], [onnx::Concat_1523 -> (1)[INT32]], [onnx::Concat_1524 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1523 for ONNX node: onnx::Concat_1523\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1524 for ONNX node: onnx::Concat_1524\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_577 for ONNX node: Concat_577\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1141 for ONNX tensor: onnx::Reshape_1141\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_577 [Concat] outputs: [onnx::Reshape_1141 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_578 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1135\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1141\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_578 [Reshape] inputs: [onnx::Reshape_1135 -> (-1, 16, 16, 64)[FLOAT]], [onnx::Reshape_1141 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_578 for ONNX node: Reshape_578\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.268 for ONNX tensor: input.268\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_578 [Reshape] outputs: [input.268 -> (-1, -1, 1024)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: HardSigmoid_579 [HardSigmoid]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.268\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_579 [HardSigmoid] inputs: [input.268 -> (-1, -1, 1024)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: HardSigmoid_579 for ONNX node: HardSigmoid_579\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Mul_1143 for ONNX tensor: onnx::Mul_1143\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_579 [HardSigmoid] outputs: [onnx::Mul_1143 -> (-1, -1, 1024)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Mul_580 [Mul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.268\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1143\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_580 [Mul] inputs: [input.268 -> (-1, -1, 1024)[FLOAT]], [onnx::Mul_1143 -> (-1, -1, 1024)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Mul_580 for ONNX node: Mul_580\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1144 for ONNX tensor: onnx::MatMul_1144\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_580 [Mul] outputs: [onnx::MatMul_1144 -> (-1, -1, 1024)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_581 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1144\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1525\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_581 [MatMul] inputs: [onnx::MatMul_1144 -> (-1, -1, 1024)[FLOAT]], [onnx::MatMul_1525 -> (1024, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1525 for ONNX node: onnx::MatMul_1525\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_581 for ONNX node: MatMul_581\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1146 for ONNX tensor: onnx::Flatten_1146\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_581 [MatMul] outputs: [onnx::Flatten_1146 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_582 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1146\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_582 [Flatten] inputs: [onnx::Flatten_1146 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_582 for ONNX node: Flatten_582\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.272 for ONNX tensor: input.272\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_582 [Flatten] outputs: [input.272 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_583 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.272\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.proj.1.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.proj.1.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.18.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_583 [BatchNormalization] inputs: [input.272 -> (-1, 384)[FLOAT]], [blocks.18.proj.1.bn.weight -> (384)[FLOAT]], [blocks.18.proj.1.bn.bias -> (384)[FLOAT]], [blocks.18.proj.1.bn.running_mean -> (384)[FLOAT]], [blocks.18.proj.1.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_583 for ONNX node: BatchNormalization_583\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1148 for ONNX tensor: onnx::Reshape_1148\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_583 [BatchNormalization] outputs: [onnx::Reshape_1148 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_584 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1146\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_584 [Shape] inputs: [onnx::Flatten_1146 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_584 for ONNX node: Shape_584\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1149 for ONNX tensor: onnx::Reshape_1149\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_584 [Shape] outputs: [onnx::Reshape_1149 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_585 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1148\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1149\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_585 [Reshape] inputs: [onnx::Reshape_1148 -> (-1, 384)[FLOAT]], [onnx::Reshape_1149 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_585 for ONNX node: Reshape_585\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1150 for ONNX tensor: onnx::MatMul_1150\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_585 [Reshape] outputs: [onnx::MatMul_1150 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_586 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1150\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1526\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_586 [MatMul] inputs: [onnx::MatMul_1150 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1526 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1526 for ONNX node: onnx::MatMul_1526\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_586 for ONNX node: MatMul_586\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1152 for ONNX tensor: onnx::Flatten_1152\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_586 [MatMul] outputs: [onnx::Flatten_1152 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_587 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1152\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_587 [Flatten] inputs: [onnx::Flatten_1152 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_587 for ONNX node: Flatten_587\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.276 for ONNX tensor: input.276\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_587 [Flatten] outputs: [input.276 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_588 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.276\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.0.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.0.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.0.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_588 [BatchNormalization] inputs: [input.276 -> (-1, 768)[FLOAT]], [blocks.19.m.0.bn.weight -> (768)[FLOAT]], [blocks.19.m.0.bn.bias -> (768)[FLOAT]], [blocks.19.m.0.bn.running_mean -> (768)[FLOAT]], [blocks.19.m.0.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_588 for ONNX node: BatchNormalization_588\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1154 for ONNX tensor: onnx::Reshape_1154\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_588 [BatchNormalization] outputs: [onnx::Reshape_1154 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_589 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1152\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_589 [Shape] inputs: [onnx::Flatten_1152 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_589 for ONNX node: Shape_589\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1155 for ONNX tensor: onnx::Reshape_1155\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_589 [Shape] outputs: [onnx::Reshape_1155 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_590 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1154\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1155\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_590 [Reshape] inputs: [onnx::Reshape_1154 -> (-1, 768)[FLOAT]], [onnx::Reshape_1155 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_590 for ONNX node: Reshape_590\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.280 for ONNX tensor: input.280\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_590 [Reshape] outputs: [input.280 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: HardSigmoid_591 [HardSigmoid]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.280\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_591 [HardSigmoid] inputs: [input.280 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: HardSigmoid_591 for ONNX node: HardSigmoid_591\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Mul_1157 for ONNX tensor: onnx::Mul_1157\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_591 [HardSigmoid] outputs: [onnx::Mul_1157 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Mul_592 [Mul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.280\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1157\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_592 [Mul] inputs: [input.280 -> (-1, -1, 768)[FLOAT]], [onnx::Mul_1157 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Mul_592 for ONNX node: Mul_592\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1158 for ONNX tensor: onnx::MatMul_1158\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_592 [Mul] outputs: [onnx::MatMul_1158 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_593 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1158\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1527\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_593 [MatMul] inputs: [onnx::MatMul_1158 -> (-1, -1, 768)[FLOAT]], [onnx::MatMul_1527 -> (768, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1527 for ONNX node: onnx::MatMul_1527\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_593 for ONNX node: MatMul_593\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1160 for ONNX tensor: onnx::Flatten_1160\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_593 [MatMul] outputs: [onnx::Flatten_1160 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_594 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1160\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_594 [Flatten] inputs: [onnx::Flatten_1160 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_594 for ONNX node: Flatten_594\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.284 for ONNX tensor: input.284\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_594 [Flatten] outputs: [input.284 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_595 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.284\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.2.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.2.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.19.m.2.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_595 [BatchNormalization] inputs: [input.284 -> (-1, 384)[FLOAT]], [blocks.19.m.2.bn.weight -> (384)[FLOAT]], [blocks.19.m.2.bn.bias -> (384)[FLOAT]], [blocks.19.m.2.bn.running_mean -> (384)[FLOAT]], [blocks.19.m.2.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_595 for ONNX node: BatchNormalization_595\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1162 for ONNX tensor: onnx::Reshape_1162\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_595 [BatchNormalization] outputs: [onnx::Reshape_1162 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_596 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1160\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_596 [Shape] inputs: [onnx::Flatten_1160 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_596 for ONNX node: Shape_596\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1163 for ONNX tensor: onnx::Reshape_1163\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_596 [Shape] outputs: [onnx::Reshape_1163 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_597 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1162\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1163\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_597 [Reshape] inputs: [onnx::Reshape_1162 -> (-1, 384)[FLOAT]], [onnx::Reshape_1163 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_597 for ONNX node: Reshape_597\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Add_1164 for ONNX tensor: onnx::Add_1164\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_597 [Reshape] outputs: [onnx::Add_1164 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Add_598 [Add]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1150\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1164\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_598 [Add] inputs: [onnx::MatMul_1150 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1164 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Add_598 for ONNX node: Add_598\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Shape_1165 for ONNX tensor: onnx::Shape_1165\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_598 [Add] outputs: [onnx::Shape_1165 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_599 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1165\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_599 [Shape] inputs: [onnx::Shape_1165 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_599 for ONNX node: Shape_599\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Gather_1166 for ONNX tensor: onnx::Gather_1166\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_599 [Shape] outputs: [onnx::Gather_1166 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_600 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_600 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_600 [Constant] outputs: [onnx::Gather_1167 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Gather_601 [Gather]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1166\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1167\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_601 [Gather] inputs: [onnx::Gather_1166 -> (3)[INT32]], [onnx::Gather_1167 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Gather_1167 for ONNX node: onnx::Gather_1167\n",
      "[05/24/2022-15:21:31] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Gather_601 for ONNX node: Gather_601\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Unsqueeze_1168 for ONNX tensor: onnx::Unsqueeze_1168\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_601 [Gather] outputs: [onnx::Unsqueeze_1168 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_602 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1165\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_602 [Shape] inputs: [onnx::Shape_1165 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_602 for ONNX node: Shape_602\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Gather_1169 for ONNX tensor: onnx::Gather_1169\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_602 [Shape] outputs: [onnx::Gather_1169 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_603 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_603 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_603 [Constant] outputs: [onnx::Gather_1170 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Gather_604 [Gather]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1169\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Gather_1170\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_604 [Gather] inputs: [onnx::Gather_1169 -> (3)[INT32]], [onnx::Gather_1170 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Gather_1170 for ONNX node: onnx::Gather_1170\n",
      "[05/24/2022-15:21:31] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Gather_604 for ONNX node: Gather_604\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Unsqueeze_1171 for ONNX tensor: onnx::Unsqueeze_1171\n",
      "[05/24/2022-15:21:31] [TRT] [V] Gather_604 [Gather] outputs: [onnx::Unsqueeze_1171 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_605 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1165\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1528\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_605 [MatMul] inputs: [onnx::Shape_1165 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1528 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1528 for ONNX node: onnx::MatMul_1528\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_605 for ONNX node: MatMul_605\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1173 for ONNX tensor: onnx::Flatten_1173\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_605 [MatMul] outputs: [onnx::Flatten_1173 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_606 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1173\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_606 [Flatten] inputs: [onnx::Flatten_1173 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_606 for ONNX node: Flatten_606\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.288 for ONNX tensor: input.288\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_606 [Flatten] outputs: [input.288 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_607 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.288\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_607 [BatchNormalization] inputs: [input.288 -> (-1, 768)[FLOAT]], [blocks.20.m.qkv.bn.weight -> (768)[FLOAT]], [blocks.20.m.qkv.bn.bias -> (768)[FLOAT]], [blocks.20.m.qkv.bn.running_mean -> (768)[FLOAT]], [blocks.20.m.qkv.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_607 for ONNX node: BatchNormalization_607\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1175 for ONNX tensor: onnx::Reshape_1175\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_607 [BatchNormalization] outputs: [onnx::Reshape_1175 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_608 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1173\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_608 [Shape] inputs: [onnx::Flatten_1173 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_608 for ONNX node: Shape_608\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1176 for ONNX tensor: onnx::Reshape_1176\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_608 [Shape] outputs: [onnx::Reshape_1176 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_609 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1175\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1176\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_609 [Reshape] inputs: [onnx::Reshape_1175 -> (-1, 768)[FLOAT]], [onnx::Reshape_1176 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_609 for ONNX node: Reshape_609\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1177 for ONNX tensor: onnx::Reshape_1177\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_609 [Reshape] outputs: [onnx::Reshape_1177 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_610 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1168\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_610 [Unsqueeze] inputs: [onnx::Unsqueeze_1168 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_610 for ONNX node: Unsqueeze_610\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1180 for ONNX tensor: onnx::Concat_1180\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_610 [Unsqueeze] outputs: [onnx::Concat_1180 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_611 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1171\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_611 [Unsqueeze] inputs: [onnx::Unsqueeze_1171 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_611 for ONNX node: Unsqueeze_611\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1181 for ONNX tensor: onnx::Concat_1181\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_611 [Unsqueeze] outputs: [onnx::Concat_1181 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_612 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1180\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1181\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1529\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1530\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_612 [Concat] inputs: [onnx::Concat_1180 -> (1)[INT32]], [onnx::Concat_1181 -> (1)[INT32]], [onnx::Concat_1529 -> (1)[INT32]], [onnx::Concat_1530 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1529 for ONNX node: onnx::Concat_1529\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1530 for ONNX node: onnx::Concat_1530\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_612 for ONNX node: Concat_612\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1184 for ONNX tensor: onnx::Reshape_1184\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_612 [Concat] outputs: [onnx::Reshape_1184 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_613 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1177\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1184\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_613 [Reshape] inputs: [onnx::Reshape_1177 -> (-1, -1, 768)[FLOAT]], [onnx::Reshape_1184 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_613 for ONNX node: Reshape_613\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Split_1185 for ONNX tensor: onnx::Split_1185\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_613 [Reshape] outputs: [onnx::Split_1185 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Split_614 [Split]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Split_1185\n",
      "[05/24/2022-15:21:31] [TRT] [V] Split_614 [Split] inputs: [onnx::Split_1185 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Split_614 for ONNX node: Split_614\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Split_614_541 for ONNX node: Split_614\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Split_614_543 for ONNX node: Split_614\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1186 for ONNX tensor: onnx::Transpose_1186\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1187 for ONNX tensor: onnx::Transpose_1187\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1188 for ONNX tensor: onnx::Transpose_1188\n",
      "[05/24/2022-15:21:31] [TRT] [V] Split_614 [Split] outputs: [onnx::Transpose_1186 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1187 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1188 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_615 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1186\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_615 [Transpose] inputs: [onnx::Transpose_1186 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_615 for ONNX node: Transpose_615\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1189 for ONNX tensor: onnx::MatMul_1189\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_615 [Transpose] outputs: [onnx::MatMul_1189 -> (-1, 12, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_616 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1188\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_616 [Transpose] inputs: [onnx::Transpose_1188 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_616 for ONNX node: Transpose_616\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1190 for ONNX tensor: onnx::MatMul_1190\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_616 [Transpose] outputs: [onnx::MatMul_1190 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_617 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1187\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_617 [Transpose] inputs: [onnx::Transpose_1187 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_617 for ONNX node: Transpose_617\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1191 for ONNX tensor: onnx::MatMul_1191\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_617 [Transpose] outputs: [onnx::MatMul_1191 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_618 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1189\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1191\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_618 [MatMul] inputs: [onnx::MatMul_1189 -> (-1, 12, -1, 16)[FLOAT]], [onnx::MatMul_1191 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_618 for ONNX node: MatMul_618\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Mul_1192 for ONNX tensor: onnx::Mul_1192\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_618 [MatMul] outputs: [onnx::Mul_1192 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_619 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_619 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_619 [Constant] outputs: [onnx::Mul_1193 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Mul_620 [Mul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1192\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1193\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_620 [Mul] inputs: [onnx::Mul_1192 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Mul_1193 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Mul_1193 for ONNX node: onnx::Mul_1193\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Mul_620 for ONNX node: Mul_620\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Add_1194 for ONNX tensor: onnx::Add_1194\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_620 [Mul] outputs: [onnx::Add_1194 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Constant_621 [Constant]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_621 [Constant] inputs: \n",
      "[05/24/2022-15:21:31] [TRT] [V] Constant_621 [Constant] outputs: [onnx::Add_1195 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Add_622 [Add]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1194\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1195\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_622 [Add] inputs: [onnx::Add_1194 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Add_1195 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Add_1195 for ONNX node: onnx::Add_1195\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Add_622 for ONNX node: Add_622\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Softmax_1196 for ONNX tensor: onnx::Softmax_1196\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_622 [Add] outputs: [onnx::Softmax_1196 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Softmax_623 [Softmax]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Softmax_1196\n",
      "[05/24/2022-15:21:31] [TRT] [V] Softmax_623 [Softmax] inputs: [onnx::Softmax_1196 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Softmax_623 for ONNX node: Softmax_623\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1197 for ONNX tensor: onnx::MatMul_1197\n",
      "[05/24/2022-15:21:31] [TRT] [V] Softmax_623 [Softmax] outputs: [onnx::MatMul_1197 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_624 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1197\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1190\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_624 [MatMul] inputs: [onnx::MatMul_1197 -> (-1, 12, 16, 16)[FLOAT]], [onnx::MatMul_1190 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_624 for ONNX node: MatMul_624\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Transpose_1198 for ONNX tensor: onnx::Transpose_1198\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_624 [MatMul] outputs: [onnx::Transpose_1198 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Transpose_625 [Transpose]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Transpose_1198\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_625 [Transpose] inputs: [onnx::Transpose_1198 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Transpose_625 for ONNX node: Transpose_625\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1199 for ONNX tensor: onnx::Reshape_1199\n",
      "[05/24/2022-15:21:31] [TRT] [V] Transpose_625 [Transpose] outputs: [onnx::Reshape_1199 -> (-1, 16, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_626 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1168\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_626 [Unsqueeze] inputs: [onnx::Unsqueeze_1168 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_626 for ONNX node: Unsqueeze_626\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1201 for ONNX tensor: onnx::Concat_1201\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_626 [Unsqueeze] outputs: [onnx::Concat_1201 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Unsqueeze_627 [Unsqueeze]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Unsqueeze_1171\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_627 [Unsqueeze] inputs: [onnx::Unsqueeze_1171 -> ()[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Unsqueeze_627 for ONNX node: Unsqueeze_627\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Concat_1202 for ONNX tensor: onnx::Concat_1202\n",
      "[05/24/2022-15:21:31] [TRT] [V] Unsqueeze_627 [Unsqueeze] outputs: [onnx::Concat_1202 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Concat_628 [Concat]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1201\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1202\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Concat_1531\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_628 [Concat] inputs: [onnx::Concat_1201 -> (1)[INT32]], [onnx::Concat_1202 -> (1)[INT32]], [onnx::Concat_1531 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::Concat_1531 for ONNX node: onnx::Concat_1531\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Concat_628 for ONNX node: Concat_628\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1204 for ONNX tensor: onnx::Reshape_1204\n",
      "[05/24/2022-15:21:31] [TRT] [V] Concat_628 [Concat] outputs: [onnx::Reshape_1204 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_629 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1199\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1204\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_629 [Reshape] inputs: [onnx::Reshape_1199 -> (-1, 16, 12, 32)[FLOAT]], [onnx::Reshape_1204 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_629 for ONNX node: Reshape_629\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.292 for ONNX tensor: input.292\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_629 [Reshape] outputs: [input.292 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: HardSigmoid_630 [HardSigmoid]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.292\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_630 [HardSigmoid] inputs: [input.292 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: HardSigmoid_630 for ONNX node: HardSigmoid_630\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Mul_1206 for ONNX tensor: onnx::Mul_1206\n",
      "[05/24/2022-15:21:31] [TRT] [V] HardSigmoid_630 [HardSigmoid] outputs: [onnx::Mul_1206 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Mul_631 [Mul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.292\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Mul_1206\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_631 [Mul] inputs: [input.292 -> (-1, -1, 384)[FLOAT]], [onnx::Mul_1206 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Mul_631 for ONNX node: Mul_631\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1207 for ONNX tensor: onnx::MatMul_1207\n",
      "[05/24/2022-15:21:31] [TRT] [V] Mul_631 [Mul] outputs: [onnx::MatMul_1207 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_632 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1207\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1532\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_632 [MatMul] inputs: [onnx::MatMul_1207 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1532 -> (384, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1532 for ONNX node: onnx::MatMul_1532\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_632 for ONNX node: MatMul_632\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1209 for ONNX tensor: onnx::Flatten_1209\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_632 [MatMul] outputs: [onnx::Flatten_1209 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_633 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1209\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_633 [Flatten] inputs: [onnx::Flatten_1209 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_633 for ONNX node: Flatten_633\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.296 for ONNX tensor: input.296\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_633 [Flatten] outputs: [input.296 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_634 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.296\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.20.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_634 [BatchNormalization] inputs: [input.296 -> (-1, 384)[FLOAT]], [blocks.20.m.proj.1.bn.weight -> (384)[FLOAT]], [blocks.20.m.proj.1.bn.bias -> (384)[FLOAT]], [blocks.20.m.proj.1.bn.running_mean -> (384)[FLOAT]], [blocks.20.m.proj.1.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_634 for ONNX node: BatchNormalization_634\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1211 for ONNX tensor: onnx::Reshape_1211\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_634 [BatchNormalization] outputs: [onnx::Reshape_1211 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Shape_635 [Shape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1209\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_635 [Shape] inputs: [onnx::Flatten_1209 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Shape_635 for ONNX node: Shape_635\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Reshape_1212 for ONNX tensor: onnx::Reshape_1212\n",
      "[05/24/2022-15:21:31] [TRT] [V] Shape_635 [Shape] outputs: [onnx::Reshape_1212 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Reshape_636 [Reshape]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1211\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Reshape_1212\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_636 [Reshape] inputs: [onnx::Reshape_1211 -> (-1, 384)[FLOAT]], [onnx::Reshape_1212 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Reshape_636 for ONNX node: Reshape_636\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Add_1213 for ONNX tensor: onnx::Add_1213\n",
      "[05/24/2022-15:21:31] [TRT] [V] Reshape_636 [Reshape] outputs: [onnx::Add_1213 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Add_637 [Add]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Shape_1165\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Add_1213\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_637 [Add] inputs: [onnx::Shape_1165 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1213 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Add_637 for ONNX node: Add_637\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::MatMul_1214 for ONNX tensor: onnx::MatMul_1214\n",
      "[05/24/2022-15:21:31] [TRT] [V] Add_637 [Add] outputs: [onnx::MatMul_1214 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: MatMul_638 [MatMul]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1214\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::MatMul_1533\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_638 [MatMul] inputs: [onnx::MatMul_1214 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1533 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: onnx::MatMul_1533 for ONNX node: onnx::MatMul_1533\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: MatMul_638 for ONNX node: MatMul_638\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: onnx::Flatten_1216 for ONNX tensor: onnx::Flatten_1216\n",
      "[05/24/2022-15:21:31] [TRT] [V] MatMul_638 [MatMul] outputs: [onnx::Flatten_1216 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: Flatten_639 [Flatten]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: onnx::Flatten_1216\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_639 [Flatten] inputs: [onnx::Flatten_1216 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: Flatten_639 for ONNX node: Flatten_639\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering tensor: input.300 for ONNX tensor: input.300\n",
      "[05/24/2022-15:21:31] [TRT] [V] Flatten_639 [Flatten] outputs: [input.300 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Parsing node: BatchNormalization_640 [BatchNormalization]\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: input.300\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.21.m.0.bn.weight\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.21.m.0.bn.bias\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.21.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:31] [TRT] [V] Searching for input: blocks.21.m.0.bn.running_var\n",
      "[05/24/2022-15:21:31] [TRT] [V] BatchNormalization_640 [BatchNormalization] inputs: [input.300 -> (-1, 768)[FLOAT]], [blocks.21.m.0.bn.weight -> (768)[FLOAT]], [blocks.21.m.0.bn.bias -> (768)[FLOAT]], [blocks.21.m.0.bn.running_mean -> (768)[FLOAT]], [blocks.21.m.0.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:31] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:31] [TRT] [V] Registering layer: BatchNormalization_640 for ONNX node: BatchNormalization_640\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1218 for ONNX tensor: onnx::Reshape_1218\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_640 [BatchNormalization] outputs: [onnx::Reshape_1218 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_641 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1216\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_641 [Shape] inputs: [onnx::Flatten_1216 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_641 for ONNX node: Shape_641\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1219 for ONNX tensor: onnx::Reshape_1219\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_641 [Shape] outputs: [onnx::Reshape_1219 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_642 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1218\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1219\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_642 [Reshape] inputs: [onnx::Reshape_1218 -> (-1, 768)[FLOAT]], [onnx::Reshape_1219 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_642 for ONNX node: Reshape_642\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.304 for ONNX tensor: input.304\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_642 [Reshape] outputs: [input.304 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: HardSigmoid_643 [HardSigmoid]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.304\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_643 [HardSigmoid] inputs: [input.304 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: HardSigmoid_643 for ONNX node: HardSigmoid_643\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Mul_1221 for ONNX tensor: onnx::Mul_1221\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_643 [HardSigmoid] outputs: [onnx::Mul_1221 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Mul_644 [Mul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.304\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1221\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_644 [Mul] inputs: [input.304 -> (-1, -1, 768)[FLOAT]], [onnx::Mul_1221 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Mul_644 for ONNX node: Mul_644\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1222 for ONNX tensor: onnx::MatMul_1222\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_644 [Mul] outputs: [onnx::MatMul_1222 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_645 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1222\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1534\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_645 [MatMul] inputs: [onnx::MatMul_1222 -> (-1, -1, 768)[FLOAT]], [onnx::MatMul_1534 -> (768, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1534 for ONNX node: onnx::MatMul_1534\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_645 for ONNX node: MatMul_645\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1224 for ONNX tensor: onnx::Flatten_1224\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_645 [MatMul] outputs: [onnx::Flatten_1224 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_646 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1224\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_646 [Flatten] inputs: [onnx::Flatten_1224 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_646 for ONNX node: Flatten_646\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.308 for ONNX tensor: input.308\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_646 [Flatten] outputs: [input.308 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_647 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.308\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.21.m.2.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.21.m.2.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.21.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.21.m.2.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_647 [BatchNormalization] inputs: [input.308 -> (-1, 384)[FLOAT]], [blocks.21.m.2.bn.weight -> (384)[FLOAT]], [blocks.21.m.2.bn.bias -> (384)[FLOAT]], [blocks.21.m.2.bn.running_mean -> (384)[FLOAT]], [blocks.21.m.2.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_647 for ONNX node: BatchNormalization_647\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1226 for ONNX tensor: onnx::Reshape_1226\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_647 [BatchNormalization] outputs: [onnx::Reshape_1226 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_648 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1224\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_648 [Shape] inputs: [onnx::Flatten_1224 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_648 for ONNX node: Shape_648\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1227 for ONNX tensor: onnx::Reshape_1227\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_648 [Shape] outputs: [onnx::Reshape_1227 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_649 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1226\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1227\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_649 [Reshape] inputs: [onnx::Reshape_1226 -> (-1, 384)[FLOAT]], [onnx::Reshape_1227 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_649 for ONNX node: Reshape_649\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Add_1228 for ONNX tensor: onnx::Add_1228\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_649 [Reshape] outputs: [onnx::Add_1228 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Add_650 [Add]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1214\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1228\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_650 [Add] inputs: [onnx::MatMul_1214 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1228 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Add_650 for ONNX node: Add_650\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Shape_1229 for ONNX tensor: onnx::Shape_1229\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_650 [Add] outputs: [onnx::Shape_1229 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_651 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1229\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_651 [Shape] inputs: [onnx::Shape_1229 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_651 for ONNX node: Shape_651\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Gather_1230 for ONNX tensor: onnx::Gather_1230\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_651 [Shape] outputs: [onnx::Gather_1230 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_652 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_652 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_652 [Constant] outputs: [onnx::Gather_1231 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Gather_653 [Gather]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1230\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1231\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_653 [Gather] inputs: [onnx::Gather_1230 -> (3)[INT32]], [onnx::Gather_1231 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Gather_1231 for ONNX node: onnx::Gather_1231\n",
      "[05/24/2022-15:21:32] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Gather_653 for ONNX node: Gather_653\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Unsqueeze_1232 for ONNX tensor: onnx::Unsqueeze_1232\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_653 [Gather] outputs: [onnx::Unsqueeze_1232 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_654 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1229\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_654 [Shape] inputs: [onnx::Shape_1229 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_654 for ONNX node: Shape_654\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Gather_1233 for ONNX tensor: onnx::Gather_1233\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_654 [Shape] outputs: [onnx::Gather_1233 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_655 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_655 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_655 [Constant] outputs: [onnx::Gather_1234 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Gather_656 [Gather]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1233\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1234\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_656 [Gather] inputs: [onnx::Gather_1233 -> (3)[INT32]], [onnx::Gather_1234 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Gather_1234 for ONNX node: onnx::Gather_1234\n",
      "[05/24/2022-15:21:32] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Gather_656 for ONNX node: Gather_656\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Unsqueeze_1235 for ONNX tensor: onnx::Unsqueeze_1235\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_656 [Gather] outputs: [onnx::Unsqueeze_1235 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_657 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1229\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1535\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_657 [MatMul] inputs: [onnx::Shape_1229 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1535 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1535 for ONNX node: onnx::MatMul_1535\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_657 for ONNX node: MatMul_657\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1237 for ONNX tensor: onnx::Flatten_1237\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_657 [MatMul] outputs: [onnx::Flatten_1237 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_658 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1237\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_658 [Flatten] inputs: [onnx::Flatten_1237 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_658 for ONNX node: Flatten_658\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.312 for ONNX tensor: input.312\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_658 [Flatten] outputs: [input.312 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_659 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.312\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_659 [BatchNormalization] inputs: [input.312 -> (-1, 768)[FLOAT]], [blocks.22.m.qkv.bn.weight -> (768)[FLOAT]], [blocks.22.m.qkv.bn.bias -> (768)[FLOAT]], [blocks.22.m.qkv.bn.running_mean -> (768)[FLOAT]], [blocks.22.m.qkv.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_659 for ONNX node: BatchNormalization_659\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1239 for ONNX tensor: onnx::Reshape_1239\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_659 [BatchNormalization] outputs: [onnx::Reshape_1239 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_660 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1237\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_660 [Shape] inputs: [onnx::Flatten_1237 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_660 for ONNX node: Shape_660\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1240 for ONNX tensor: onnx::Reshape_1240\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_660 [Shape] outputs: [onnx::Reshape_1240 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_661 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1239\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1240\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_661 [Reshape] inputs: [onnx::Reshape_1239 -> (-1, 768)[FLOAT]], [onnx::Reshape_1240 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_661 for ONNX node: Reshape_661\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1241 for ONNX tensor: onnx::Reshape_1241\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_661 [Reshape] outputs: [onnx::Reshape_1241 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_662 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1232\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_662 [Unsqueeze] inputs: [onnx::Unsqueeze_1232 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_662 for ONNX node: Unsqueeze_662\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1244 for ONNX tensor: onnx::Concat_1244\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_662 [Unsqueeze] outputs: [onnx::Concat_1244 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_663 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1235\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_663 [Unsqueeze] inputs: [onnx::Unsqueeze_1235 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_663 for ONNX node: Unsqueeze_663\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1245 for ONNX tensor: onnx::Concat_1245\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_663 [Unsqueeze] outputs: [onnx::Concat_1245 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Concat_664 [Concat]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1244\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1245\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1536\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1537\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_664 [Concat] inputs: [onnx::Concat_1244 -> (1)[INT32]], [onnx::Concat_1245 -> (1)[INT32]], [onnx::Concat_1536 -> (1)[INT32]], [onnx::Concat_1537 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Concat_1536 for ONNX node: onnx::Concat_1536\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Concat_1537 for ONNX node: onnx::Concat_1537\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Concat_664 for ONNX node: Concat_664\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1248 for ONNX tensor: onnx::Reshape_1248\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_664 [Concat] outputs: [onnx::Reshape_1248 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_665 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1241\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1248\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_665 [Reshape] inputs: [onnx::Reshape_1241 -> (-1, -1, 768)[FLOAT]], [onnx::Reshape_1248 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_665 for ONNX node: Reshape_665\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Split_1249 for ONNX tensor: onnx::Split_1249\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_665 [Reshape] outputs: [onnx::Split_1249 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Split_666 [Split]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Split_1249\n",
      "[05/24/2022-15:21:32] [TRT] [V] Split_666 [Split] inputs: [onnx::Split_1249 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Split_666 for ONNX node: Split_666\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Split_666_581 for ONNX node: Split_666\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Split_666_583 for ONNX node: Split_666\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1250 for ONNX tensor: onnx::Transpose_1250\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1251 for ONNX tensor: onnx::Transpose_1251\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1252 for ONNX tensor: onnx::Transpose_1252\n",
      "[05/24/2022-15:21:32] [TRT] [V] Split_666 [Split] outputs: [onnx::Transpose_1250 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1251 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1252 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_667 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1250\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_667 [Transpose] inputs: [onnx::Transpose_1250 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_667 for ONNX node: Transpose_667\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1253 for ONNX tensor: onnx::MatMul_1253\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_667 [Transpose] outputs: [onnx::MatMul_1253 -> (-1, 12, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_668 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1252\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_668 [Transpose] inputs: [onnx::Transpose_1252 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_668 for ONNX node: Transpose_668\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1254 for ONNX tensor: onnx::MatMul_1254\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_668 [Transpose] outputs: [onnx::MatMul_1254 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_669 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1251\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_669 [Transpose] inputs: [onnx::Transpose_1251 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_669 for ONNX node: Transpose_669\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1255 for ONNX tensor: onnx::MatMul_1255\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_669 [Transpose] outputs: [onnx::MatMul_1255 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_670 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1253\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1255\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_670 [MatMul] inputs: [onnx::MatMul_1253 -> (-1, 12, -1, 16)[FLOAT]], [onnx::MatMul_1255 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_670 for ONNX node: MatMul_670\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Mul_1256 for ONNX tensor: onnx::Mul_1256\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_670 [MatMul] outputs: [onnx::Mul_1256 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_671 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_671 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_671 [Constant] outputs: [onnx::Mul_1257 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Mul_672 [Mul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1256\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1257\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_672 [Mul] inputs: [onnx::Mul_1256 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Mul_1257 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Mul_1257 for ONNX node: onnx::Mul_1257\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Mul_672 for ONNX node: Mul_672\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Add_1258 for ONNX tensor: onnx::Add_1258\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_672 [Mul] outputs: [onnx::Add_1258 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_673 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_673 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_673 [Constant] outputs: [onnx::Add_1259 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Add_674 [Add]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1258\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1259\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_674 [Add] inputs: [onnx::Add_1258 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Add_1259 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Add_1259 for ONNX node: onnx::Add_1259\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Add_674 for ONNX node: Add_674\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Softmax_1260 for ONNX tensor: onnx::Softmax_1260\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_674 [Add] outputs: [onnx::Softmax_1260 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Softmax_675 [Softmax]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Softmax_1260\n",
      "[05/24/2022-15:21:32] [TRT] [V] Softmax_675 [Softmax] inputs: [onnx::Softmax_1260 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Softmax_675 for ONNX node: Softmax_675\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1261 for ONNX tensor: onnx::MatMul_1261\n",
      "[05/24/2022-15:21:32] [TRT] [V] Softmax_675 [Softmax] outputs: [onnx::MatMul_1261 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_676 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1261\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1254\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_676 [MatMul] inputs: [onnx::MatMul_1261 -> (-1, 12, 16, 16)[FLOAT]], [onnx::MatMul_1254 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_676 for ONNX node: MatMul_676\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1262 for ONNX tensor: onnx::Transpose_1262\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_676 [MatMul] outputs: [onnx::Transpose_1262 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_677 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1262\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_677 [Transpose] inputs: [onnx::Transpose_1262 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_677 for ONNX node: Transpose_677\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1263 for ONNX tensor: onnx::Reshape_1263\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_677 [Transpose] outputs: [onnx::Reshape_1263 -> (-1, 16, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_678 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1232\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_678 [Unsqueeze] inputs: [onnx::Unsqueeze_1232 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_678 for ONNX node: Unsqueeze_678\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1265 for ONNX tensor: onnx::Concat_1265\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_678 [Unsqueeze] outputs: [onnx::Concat_1265 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_679 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1235\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_679 [Unsqueeze] inputs: [onnx::Unsqueeze_1235 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_679 for ONNX node: Unsqueeze_679\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1266 for ONNX tensor: onnx::Concat_1266\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_679 [Unsqueeze] outputs: [onnx::Concat_1266 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Concat_680 [Concat]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1265\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1266\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1538\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_680 [Concat] inputs: [onnx::Concat_1265 -> (1)[INT32]], [onnx::Concat_1266 -> (1)[INT32]], [onnx::Concat_1538 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Concat_1538 for ONNX node: onnx::Concat_1538\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Concat_680 for ONNX node: Concat_680\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1268 for ONNX tensor: onnx::Reshape_1268\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_680 [Concat] outputs: [onnx::Reshape_1268 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_681 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1263\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1268\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_681 [Reshape] inputs: [onnx::Reshape_1263 -> (-1, 16, 12, 32)[FLOAT]], [onnx::Reshape_1268 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_681 for ONNX node: Reshape_681\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.316 for ONNX tensor: input.316\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_681 [Reshape] outputs: [input.316 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: HardSigmoid_682 [HardSigmoid]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.316\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_682 [HardSigmoid] inputs: [input.316 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: HardSigmoid_682 for ONNX node: HardSigmoid_682\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Mul_1270 for ONNX tensor: onnx::Mul_1270\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_682 [HardSigmoid] outputs: [onnx::Mul_1270 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Mul_683 [Mul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.316\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1270\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_683 [Mul] inputs: [input.316 -> (-1, -1, 384)[FLOAT]], [onnx::Mul_1270 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Mul_683 for ONNX node: Mul_683\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1271 for ONNX tensor: onnx::MatMul_1271\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_683 [Mul] outputs: [onnx::MatMul_1271 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_684 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1271\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1539\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_684 [MatMul] inputs: [onnx::MatMul_1271 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1539 -> (384, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1539 for ONNX node: onnx::MatMul_1539\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_684 for ONNX node: MatMul_684\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1273 for ONNX tensor: onnx::Flatten_1273\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_684 [MatMul] outputs: [onnx::Flatten_1273 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_685 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1273\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_685 [Flatten] inputs: [onnx::Flatten_1273 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_685 for ONNX node: Flatten_685\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.320 for ONNX tensor: input.320\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_685 [Flatten] outputs: [input.320 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_686 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.320\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.22.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_686 [BatchNormalization] inputs: [input.320 -> (-1, 384)[FLOAT]], [blocks.22.m.proj.1.bn.weight -> (384)[FLOAT]], [blocks.22.m.proj.1.bn.bias -> (384)[FLOAT]], [blocks.22.m.proj.1.bn.running_mean -> (384)[FLOAT]], [blocks.22.m.proj.1.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_686 for ONNX node: BatchNormalization_686\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1275 for ONNX tensor: onnx::Reshape_1275\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_686 [BatchNormalization] outputs: [onnx::Reshape_1275 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_687 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1273\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_687 [Shape] inputs: [onnx::Flatten_1273 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_687 for ONNX node: Shape_687\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1276 for ONNX tensor: onnx::Reshape_1276\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_687 [Shape] outputs: [onnx::Reshape_1276 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_688 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1275\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1276\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_688 [Reshape] inputs: [onnx::Reshape_1275 -> (-1, 384)[FLOAT]], [onnx::Reshape_1276 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_688 for ONNX node: Reshape_688\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Add_1277 for ONNX tensor: onnx::Add_1277\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_688 [Reshape] outputs: [onnx::Add_1277 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Add_689 [Add]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1229\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1277\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_689 [Add] inputs: [onnx::Shape_1229 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1277 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Add_689 for ONNX node: Add_689\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1278 for ONNX tensor: onnx::MatMul_1278\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_689 [Add] outputs: [onnx::MatMul_1278 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_690 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1278\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1540\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_690 [MatMul] inputs: [onnx::MatMul_1278 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1540 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1540 for ONNX node: onnx::MatMul_1540\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_690 for ONNX node: MatMul_690\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1280 for ONNX tensor: onnx::Flatten_1280\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_690 [MatMul] outputs: [onnx::Flatten_1280 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_691 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1280\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_691 [Flatten] inputs: [onnx::Flatten_1280 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_691 for ONNX node: Flatten_691\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.324 for ONNX tensor: input.324\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_691 [Flatten] outputs: [input.324 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_692 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.324\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.0.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.0.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.0.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_692 [BatchNormalization] inputs: [input.324 -> (-1, 768)[FLOAT]], [blocks.23.m.0.bn.weight -> (768)[FLOAT]], [blocks.23.m.0.bn.bias -> (768)[FLOAT]], [blocks.23.m.0.bn.running_mean -> (768)[FLOAT]], [blocks.23.m.0.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_692 for ONNX node: BatchNormalization_692\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1282 for ONNX tensor: onnx::Reshape_1282\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_692 [BatchNormalization] outputs: [onnx::Reshape_1282 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_693 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1280\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_693 [Shape] inputs: [onnx::Flatten_1280 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_693 for ONNX node: Shape_693\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1283 for ONNX tensor: onnx::Reshape_1283\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_693 [Shape] outputs: [onnx::Reshape_1283 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_694 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1282\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1283\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_694 [Reshape] inputs: [onnx::Reshape_1282 -> (-1, 768)[FLOAT]], [onnx::Reshape_1283 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_694 for ONNX node: Reshape_694\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.328 for ONNX tensor: input.328\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_694 [Reshape] outputs: [input.328 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: HardSigmoid_695 [HardSigmoid]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.328\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_695 [HardSigmoid] inputs: [input.328 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: HardSigmoid_695 for ONNX node: HardSigmoid_695\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Mul_1285 for ONNX tensor: onnx::Mul_1285\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_695 [HardSigmoid] outputs: [onnx::Mul_1285 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Mul_696 [Mul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.328\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1285\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_696 [Mul] inputs: [input.328 -> (-1, -1, 768)[FLOAT]], [onnx::Mul_1285 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Mul_696 for ONNX node: Mul_696\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1286 for ONNX tensor: onnx::MatMul_1286\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_696 [Mul] outputs: [onnx::MatMul_1286 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_697 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1286\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1541\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_697 [MatMul] inputs: [onnx::MatMul_1286 -> (-1, -1, 768)[FLOAT]], [onnx::MatMul_1541 -> (768, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1541 for ONNX node: onnx::MatMul_1541\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_697 for ONNX node: MatMul_697\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1288 for ONNX tensor: onnx::Flatten_1288\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_697 [MatMul] outputs: [onnx::Flatten_1288 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_698 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1288\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_698 [Flatten] inputs: [onnx::Flatten_1288 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_698 for ONNX node: Flatten_698\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.332 for ONNX tensor: input.332\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_698 [Flatten] outputs: [input.332 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_699 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.332\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.2.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.2.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.23.m.2.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_699 [BatchNormalization] inputs: [input.332 -> (-1, 384)[FLOAT]], [blocks.23.m.2.bn.weight -> (384)[FLOAT]], [blocks.23.m.2.bn.bias -> (384)[FLOAT]], [blocks.23.m.2.bn.running_mean -> (384)[FLOAT]], [blocks.23.m.2.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_699 for ONNX node: BatchNormalization_699\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1290 for ONNX tensor: onnx::Reshape_1290\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_699 [BatchNormalization] outputs: [onnx::Reshape_1290 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_700 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1288\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_700 [Shape] inputs: [onnx::Flatten_1288 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_700 for ONNX node: Shape_700\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1291 for ONNX tensor: onnx::Reshape_1291\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_700 [Shape] outputs: [onnx::Reshape_1291 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_701 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1290\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1291\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_701 [Reshape] inputs: [onnx::Reshape_1290 -> (-1, 384)[FLOAT]], [onnx::Reshape_1291 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_701 for ONNX node: Reshape_701\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Add_1292 for ONNX tensor: onnx::Add_1292\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_701 [Reshape] outputs: [onnx::Add_1292 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Add_702 [Add]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1278\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1292\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_702 [Add] inputs: [onnx::MatMul_1278 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1292 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Add_702 for ONNX node: Add_702\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Shape_1293 for ONNX tensor: onnx::Shape_1293\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_702 [Add] outputs: [onnx::Shape_1293 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_703 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1293\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_703 [Shape] inputs: [onnx::Shape_1293 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_703 for ONNX node: Shape_703\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Gather_1294 for ONNX tensor: onnx::Gather_1294\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_703 [Shape] outputs: [onnx::Gather_1294 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_704 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_704 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_704 [Constant] outputs: [onnx::Gather_1295 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Gather_705 [Gather]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1294\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1295\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_705 [Gather] inputs: [onnx::Gather_1294 -> (3)[INT32]], [onnx::Gather_1295 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Gather_1295 for ONNX node: onnx::Gather_1295\n",
      "[05/24/2022-15:21:32] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Gather_705 for ONNX node: Gather_705\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Unsqueeze_1296 for ONNX tensor: onnx::Unsqueeze_1296\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_705 [Gather] outputs: [onnx::Unsqueeze_1296 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_706 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1293\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_706 [Shape] inputs: [onnx::Shape_1293 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_706 for ONNX node: Shape_706\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Gather_1297 for ONNX tensor: onnx::Gather_1297\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_706 [Shape] outputs: [onnx::Gather_1297 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_707 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_707 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_707 [Constant] outputs: [onnx::Gather_1298 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Gather_708 [Gather]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1297\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1298\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_708 [Gather] inputs: [onnx::Gather_1297 -> (3)[INT32]], [onnx::Gather_1298 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Gather_1298 for ONNX node: onnx::Gather_1298\n",
      "[05/24/2022-15:21:32] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Gather_708 for ONNX node: Gather_708\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Unsqueeze_1299 for ONNX tensor: onnx::Unsqueeze_1299\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_708 [Gather] outputs: [onnx::Unsqueeze_1299 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_709 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1293\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1542\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_709 [MatMul] inputs: [onnx::Shape_1293 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1542 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1542 for ONNX node: onnx::MatMul_1542\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_709 for ONNX node: MatMul_709\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1301 for ONNX tensor: onnx::Flatten_1301\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_709 [MatMul] outputs: [onnx::Flatten_1301 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_710 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1301\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_710 [Flatten] inputs: [onnx::Flatten_1301 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_710 for ONNX node: Flatten_710\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.336 for ONNX tensor: input.336\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_710 [Flatten] outputs: [input.336 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_711 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.336\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_711 [BatchNormalization] inputs: [input.336 -> (-1, 768)[FLOAT]], [blocks.24.m.qkv.bn.weight -> (768)[FLOAT]], [blocks.24.m.qkv.bn.bias -> (768)[FLOAT]], [blocks.24.m.qkv.bn.running_mean -> (768)[FLOAT]], [blocks.24.m.qkv.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_711 for ONNX node: BatchNormalization_711\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1303 for ONNX tensor: onnx::Reshape_1303\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_711 [BatchNormalization] outputs: [onnx::Reshape_1303 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_712 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1301\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_712 [Shape] inputs: [onnx::Flatten_1301 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_712 for ONNX node: Shape_712\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1304 for ONNX tensor: onnx::Reshape_1304\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_712 [Shape] outputs: [onnx::Reshape_1304 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_713 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1303\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1304\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_713 [Reshape] inputs: [onnx::Reshape_1303 -> (-1, 768)[FLOAT]], [onnx::Reshape_1304 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_713 for ONNX node: Reshape_713\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1305 for ONNX tensor: onnx::Reshape_1305\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_713 [Reshape] outputs: [onnx::Reshape_1305 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_714 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1296\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_714 [Unsqueeze] inputs: [onnx::Unsqueeze_1296 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_714 for ONNX node: Unsqueeze_714\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1308 for ONNX tensor: onnx::Concat_1308\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_714 [Unsqueeze] outputs: [onnx::Concat_1308 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_715 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1299\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_715 [Unsqueeze] inputs: [onnx::Unsqueeze_1299 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_715 for ONNX node: Unsqueeze_715\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1309 for ONNX tensor: onnx::Concat_1309\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_715 [Unsqueeze] outputs: [onnx::Concat_1309 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Concat_716 [Concat]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1308\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1309\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1543\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1544\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_716 [Concat] inputs: [onnx::Concat_1308 -> (1)[INT32]], [onnx::Concat_1309 -> (1)[INT32]], [onnx::Concat_1543 -> (1)[INT32]], [onnx::Concat_1544 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Concat_1543 for ONNX node: onnx::Concat_1543\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Concat_1544 for ONNX node: onnx::Concat_1544\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Concat_716 for ONNX node: Concat_716\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1312 for ONNX tensor: onnx::Reshape_1312\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_716 [Concat] outputs: [onnx::Reshape_1312 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_717 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1305\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1312\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_717 [Reshape] inputs: [onnx::Reshape_1305 -> (-1, -1, 768)[FLOAT]], [onnx::Reshape_1312 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_717 for ONNX node: Reshape_717\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Split_1313 for ONNX tensor: onnx::Split_1313\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_717 [Reshape] outputs: [onnx::Split_1313 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Split_718 [Split]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Split_1313\n",
      "[05/24/2022-15:21:32] [TRT] [V] Split_718 [Split] inputs: [onnx::Split_1313 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Split_718 for ONNX node: Split_718\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Split_718_621 for ONNX node: Split_718\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Split_718_623 for ONNX node: Split_718\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1314 for ONNX tensor: onnx::Transpose_1314\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1315 for ONNX tensor: onnx::Transpose_1315\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1316 for ONNX tensor: onnx::Transpose_1316\n",
      "[05/24/2022-15:21:32] [TRT] [V] Split_718 [Split] outputs: [onnx::Transpose_1314 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1315 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1316 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_719 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1314\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_719 [Transpose] inputs: [onnx::Transpose_1314 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_719 for ONNX node: Transpose_719\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1317 for ONNX tensor: onnx::MatMul_1317\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_719 [Transpose] outputs: [onnx::MatMul_1317 -> (-1, 12, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_720 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1316\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_720 [Transpose] inputs: [onnx::Transpose_1316 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_720 for ONNX node: Transpose_720\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1318 for ONNX tensor: onnx::MatMul_1318\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_720 [Transpose] outputs: [onnx::MatMul_1318 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_721 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1315\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_721 [Transpose] inputs: [onnx::Transpose_1315 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_721 for ONNX node: Transpose_721\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1319 for ONNX tensor: onnx::MatMul_1319\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_721 [Transpose] outputs: [onnx::MatMul_1319 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_722 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1317\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1319\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_722 [MatMul] inputs: [onnx::MatMul_1317 -> (-1, 12, -1, 16)[FLOAT]], [onnx::MatMul_1319 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_722 for ONNX node: MatMul_722\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Mul_1320 for ONNX tensor: onnx::Mul_1320\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_722 [MatMul] outputs: [onnx::Mul_1320 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_723 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_723 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_723 [Constant] outputs: [onnx::Mul_1321 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Mul_724 [Mul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1320\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1321\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_724 [Mul] inputs: [onnx::Mul_1320 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Mul_1321 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Mul_1321 for ONNX node: onnx::Mul_1321\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Mul_724 for ONNX node: Mul_724\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Add_1322 for ONNX tensor: onnx::Add_1322\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_724 [Mul] outputs: [onnx::Add_1322 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_725 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_725 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_725 [Constant] outputs: [onnx::Add_1323 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Add_726 [Add]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1322\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1323\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_726 [Add] inputs: [onnx::Add_1322 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Add_1323 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Add_1323 for ONNX node: onnx::Add_1323\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Add_726 for ONNX node: Add_726\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Softmax_1324 for ONNX tensor: onnx::Softmax_1324\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_726 [Add] outputs: [onnx::Softmax_1324 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Softmax_727 [Softmax]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Softmax_1324\n",
      "[05/24/2022-15:21:32] [TRT] [V] Softmax_727 [Softmax] inputs: [onnx::Softmax_1324 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Softmax_727 for ONNX node: Softmax_727\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1325 for ONNX tensor: onnx::MatMul_1325\n",
      "[05/24/2022-15:21:32] [TRT] [V] Softmax_727 [Softmax] outputs: [onnx::MatMul_1325 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_728 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1325\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1318\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_728 [MatMul] inputs: [onnx::MatMul_1325 -> (-1, 12, 16, 16)[FLOAT]], [onnx::MatMul_1318 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_728 for ONNX node: MatMul_728\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Transpose_1326 for ONNX tensor: onnx::Transpose_1326\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_728 [MatMul] outputs: [onnx::Transpose_1326 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Transpose_729 [Transpose]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Transpose_1326\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_729 [Transpose] inputs: [onnx::Transpose_1326 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Transpose_729 for ONNX node: Transpose_729\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1327 for ONNX tensor: onnx::Reshape_1327\n",
      "[05/24/2022-15:21:32] [TRT] [V] Transpose_729 [Transpose] outputs: [onnx::Reshape_1327 -> (-1, 16, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_730 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1296\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_730 [Unsqueeze] inputs: [onnx::Unsqueeze_1296 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_730 for ONNX node: Unsqueeze_730\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1329 for ONNX tensor: onnx::Concat_1329\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_730 [Unsqueeze] outputs: [onnx::Concat_1329 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Unsqueeze_731 [Unsqueeze]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Unsqueeze_1299\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_731 [Unsqueeze] inputs: [onnx::Unsqueeze_1299 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Unsqueeze_731 for ONNX node: Unsqueeze_731\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Concat_1330 for ONNX tensor: onnx::Concat_1330\n",
      "[05/24/2022-15:21:32] [TRT] [V] Unsqueeze_731 [Unsqueeze] outputs: [onnx::Concat_1330 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Concat_732 [Concat]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1329\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1330\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Concat_1545\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_732 [Concat] inputs: [onnx::Concat_1329 -> (1)[INT32]], [onnx::Concat_1330 -> (1)[INT32]], [onnx::Concat_1545 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Concat_1545 for ONNX node: onnx::Concat_1545\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Concat_732 for ONNX node: Concat_732\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1332 for ONNX tensor: onnx::Reshape_1332\n",
      "[05/24/2022-15:21:32] [TRT] [V] Concat_732 [Concat] outputs: [onnx::Reshape_1332 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_733 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1327\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1332\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_733 [Reshape] inputs: [onnx::Reshape_1327 -> (-1, 16, 12, 32)[FLOAT]], [onnx::Reshape_1332 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_733 for ONNX node: Reshape_733\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.340 for ONNX tensor: input.340\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_733 [Reshape] outputs: [input.340 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: HardSigmoid_734 [HardSigmoid]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.340\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_734 [HardSigmoid] inputs: [input.340 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: HardSigmoid_734 for ONNX node: HardSigmoid_734\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Mul_1334 for ONNX tensor: onnx::Mul_1334\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_734 [HardSigmoid] outputs: [onnx::Mul_1334 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Mul_735 [Mul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.340\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1334\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_735 [Mul] inputs: [input.340 -> (-1, -1, 384)[FLOAT]], [onnx::Mul_1334 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Mul_735 for ONNX node: Mul_735\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1335 for ONNX tensor: onnx::MatMul_1335\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_735 [Mul] outputs: [onnx::MatMul_1335 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_736 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1335\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1546\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_736 [MatMul] inputs: [onnx::MatMul_1335 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1546 -> (384, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1546 for ONNX node: onnx::MatMul_1546\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_736 for ONNX node: MatMul_736\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1337 for ONNX tensor: onnx::Flatten_1337\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_736 [MatMul] outputs: [onnx::Flatten_1337 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_737 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1337\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_737 [Flatten] inputs: [onnx::Flatten_1337 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_737 for ONNX node: Flatten_737\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.344 for ONNX tensor: input.344\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_737 [Flatten] outputs: [input.344 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_738 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.344\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.24.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_738 [BatchNormalization] inputs: [input.344 -> (-1, 384)[FLOAT]], [blocks.24.m.proj.1.bn.weight -> (384)[FLOAT]], [blocks.24.m.proj.1.bn.bias -> (384)[FLOAT]], [blocks.24.m.proj.1.bn.running_mean -> (384)[FLOAT]], [blocks.24.m.proj.1.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_738 for ONNX node: BatchNormalization_738\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1339 for ONNX tensor: onnx::Reshape_1339\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_738 [BatchNormalization] outputs: [onnx::Reshape_1339 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_739 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1337\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_739 [Shape] inputs: [onnx::Flatten_1337 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_739 for ONNX node: Shape_739\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1340 for ONNX tensor: onnx::Reshape_1340\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_739 [Shape] outputs: [onnx::Reshape_1340 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_740 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1339\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1340\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_740 [Reshape] inputs: [onnx::Reshape_1339 -> (-1, 384)[FLOAT]], [onnx::Reshape_1340 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_740 for ONNX node: Reshape_740\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Add_1341 for ONNX tensor: onnx::Add_1341\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_740 [Reshape] outputs: [onnx::Add_1341 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Add_741 [Add]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1293\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1341\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_741 [Add] inputs: [onnx::Shape_1293 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1341 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Add_741 for ONNX node: Add_741\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1342 for ONNX tensor: onnx::MatMul_1342\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_741 [Add] outputs: [onnx::MatMul_1342 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_742 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1342\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1547\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_742 [MatMul] inputs: [onnx::MatMul_1342 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1547 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1547 for ONNX node: onnx::MatMul_1547\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_742 for ONNX node: MatMul_742\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1344 for ONNX tensor: onnx::Flatten_1344\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_742 [MatMul] outputs: [onnx::Flatten_1344 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_743 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1344\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_743 [Flatten] inputs: [onnx::Flatten_1344 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_743 for ONNX node: Flatten_743\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.348 for ONNX tensor: input.348\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_743 [Flatten] outputs: [input.348 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_744 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.348\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.0.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.0.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.0.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_744 [BatchNormalization] inputs: [input.348 -> (-1, 768)[FLOAT]], [blocks.25.m.0.bn.weight -> (768)[FLOAT]], [blocks.25.m.0.bn.bias -> (768)[FLOAT]], [blocks.25.m.0.bn.running_mean -> (768)[FLOAT]], [blocks.25.m.0.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_744 for ONNX node: BatchNormalization_744\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1346 for ONNX tensor: onnx::Reshape_1346\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_744 [BatchNormalization] outputs: [onnx::Reshape_1346 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_745 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1344\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_745 [Shape] inputs: [onnx::Flatten_1344 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_745 for ONNX node: Shape_745\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1347 for ONNX tensor: onnx::Reshape_1347\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_745 [Shape] outputs: [onnx::Reshape_1347 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_746 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1346\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1347\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_746 [Reshape] inputs: [onnx::Reshape_1346 -> (-1, 768)[FLOAT]], [onnx::Reshape_1347 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_746 for ONNX node: Reshape_746\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.352 for ONNX tensor: input.352\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_746 [Reshape] outputs: [input.352 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: HardSigmoid_747 [HardSigmoid]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.352\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_747 [HardSigmoid] inputs: [input.352 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: HardSigmoid_747 for ONNX node: HardSigmoid_747\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Mul_1349 for ONNX tensor: onnx::Mul_1349\n",
      "[05/24/2022-15:21:32] [TRT] [V] HardSigmoid_747 [HardSigmoid] outputs: [onnx::Mul_1349 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Mul_748 [Mul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.352\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Mul_1349\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_748 [Mul] inputs: [input.352 -> (-1, -1, 768)[FLOAT]], [onnx::Mul_1349 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Mul_748 for ONNX node: Mul_748\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::MatMul_1350 for ONNX tensor: onnx::MatMul_1350\n",
      "[05/24/2022-15:21:32] [TRT] [V] Mul_748 [Mul] outputs: [onnx::MatMul_1350 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_749 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1350\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1548\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_749 [MatMul] inputs: [onnx::MatMul_1350 -> (-1, -1, 768)[FLOAT]], [onnx::MatMul_1548 -> (768, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1548 for ONNX node: onnx::MatMul_1548\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_749 for ONNX node: MatMul_749\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1352 for ONNX tensor: onnx::Flatten_1352\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_749 [MatMul] outputs: [onnx::Flatten_1352 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_750 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1352\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_750 [Flatten] inputs: [onnx::Flatten_1352 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_750 for ONNX node: Flatten_750\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: input.356 for ONNX tensor: input.356\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_750 [Flatten] outputs: [input.356 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: BatchNormalization_751 [BatchNormalization]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: input.356\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.2.bn.weight\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.2.bn.bias\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: blocks.25.m.2.bn.running_var\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_751 [BatchNormalization] inputs: [input.356 -> (-1, 384)[FLOAT]], [blocks.25.m.2.bn.weight -> (384)[FLOAT]], [blocks.25.m.2.bn.bias -> (384)[FLOAT]], [blocks.25.m.2.bn.running_mean -> (384)[FLOAT]], [blocks.25.m.2.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: BatchNormalization_751 for ONNX node: BatchNormalization_751\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1354 for ONNX tensor: onnx::Reshape_1354\n",
      "[05/24/2022-15:21:32] [TRT] [V] BatchNormalization_751 [BatchNormalization] outputs: [onnx::Reshape_1354 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_752 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1352\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_752 [Shape] inputs: [onnx::Flatten_1352 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_752 for ONNX node: Shape_752\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Reshape_1355 for ONNX tensor: onnx::Reshape_1355\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_752 [Shape] outputs: [onnx::Reshape_1355 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Reshape_753 [Reshape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1354\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Reshape_1355\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_753 [Reshape] inputs: [onnx::Reshape_1354 -> (-1, 384)[FLOAT]], [onnx::Reshape_1355 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Reshape_753 for ONNX node: Reshape_753\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Add_1356 for ONNX tensor: onnx::Add_1356\n",
      "[05/24/2022-15:21:32] [TRT] [V] Reshape_753 [Reshape] outputs: [onnx::Add_1356 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Add_754 [Add]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1342\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Add_1356\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_754 [Add] inputs: [onnx::MatMul_1342 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1356 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Add_754 for ONNX node: Add_754\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Shape_1357 for ONNX tensor: onnx::Shape_1357\n",
      "[05/24/2022-15:21:32] [TRT] [V] Add_754 [Add] outputs: [onnx::Shape_1357 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_755 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1357\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_755 [Shape] inputs: [onnx::Shape_1357 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_755 for ONNX node: Shape_755\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Gather_1358 for ONNX tensor: onnx::Gather_1358\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_755 [Shape] outputs: [onnx::Gather_1358 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_756 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_756 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_756 [Constant] outputs: [onnx::Gather_1359 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Gather_757 [Gather]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1358\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1359\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_757 [Gather] inputs: [onnx::Gather_1358 -> (3)[INT32]], [onnx::Gather_1359 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Gather_1359 for ONNX node: onnx::Gather_1359\n",
      "[05/24/2022-15:21:32] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Gather_757 for ONNX node: Gather_757\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Unsqueeze_1360 for ONNX tensor: onnx::Unsqueeze_1360\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_757 [Gather] outputs: [onnx::Unsqueeze_1360 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Shape_758 [Shape]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1357\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_758 [Shape] inputs: [onnx::Shape_1357 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Shape_758 for ONNX node: Shape_758\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Gather_1361 for ONNX tensor: onnx::Gather_1361\n",
      "[05/24/2022-15:21:32] [TRT] [V] Shape_758 [Shape] outputs: [onnx::Gather_1361 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Constant_759 [Constant]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_759 [Constant] inputs: \n",
      "[05/24/2022-15:21:32] [TRT] [V] Constant_759 [Constant] outputs: [onnx::Gather_1362 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Gather_760 [Gather]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1361\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Gather_1362\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_760 [Gather] inputs: [onnx::Gather_1361 -> (3)[INT32]], [onnx::Gather_1362 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::Gather_1362 for ONNX node: onnx::Gather_1362\n",
      "[05/24/2022-15:21:32] [TRT] [V] Using Gather axis: 0\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Gather_760 for ONNX node: Gather_760\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Unsqueeze_1363 for ONNX tensor: onnx::Unsqueeze_1363\n",
      "[05/24/2022-15:21:32] [TRT] [V] Gather_760 [Gather] outputs: [onnx::Unsqueeze_1363 -> ()[INT32]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: MatMul_761 [MatMul]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Shape_1357\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::MatMul_1549\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_761 [MatMul] inputs: [onnx::Shape_1357 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1549 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: onnx::MatMul_1549 for ONNX node: onnx::MatMul_1549\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: MatMul_761 for ONNX node: MatMul_761\n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering tensor: onnx::Flatten_1365 for ONNX tensor: onnx::Flatten_1365\n",
      "[05/24/2022-15:21:32] [TRT] [V] MatMul_761 [MatMul] outputs: [onnx::Flatten_1365 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Parsing node: Flatten_762 [Flatten]\n",
      "[05/24/2022-15:21:32] [TRT] [V] Searching for input: onnx::Flatten_1365\n",
      "[05/24/2022-15:21:32] [TRT] [V] Flatten_762 [Flatten] inputs: [onnx::Flatten_1365 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:32] [TRT] [V] Registering layer: Flatten_762 for ONNX node: Flatten_762\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: input.360 for ONNX tensor: input.360\n",
      "[05/24/2022-15:21:33] [TRT] [V] Flatten_762 [Flatten] outputs: [input.360 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: BatchNormalization_763 [BatchNormalization]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.360\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.qkv.bn.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.qkv.bn.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.qkv.bn.running_mean\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.qkv.bn.running_var\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_763 [BatchNormalization] inputs: [input.360 -> (-1, 768)[FLOAT]], [blocks.26.m.qkv.bn.weight -> (768)[FLOAT]], [blocks.26.m.qkv.bn.bias -> (768)[FLOAT]], [blocks.26.m.qkv.bn.running_mean -> (768)[FLOAT]], [blocks.26.m.qkv.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: BatchNormalization_763 for ONNX node: BatchNormalization_763\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1367 for ONNX tensor: onnx::Reshape_1367\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_763 [BatchNormalization] outputs: [onnx::Reshape_1367 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Shape_764 [Shape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Flatten_1365\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_764 [Shape] inputs: [onnx::Flatten_1365 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Shape_764 for ONNX node: Shape_764\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1368 for ONNX tensor: onnx::Reshape_1368\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_764 [Shape] outputs: [onnx::Reshape_1368 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Reshape_765 [Reshape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1367\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1368\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_765 [Reshape] inputs: [onnx::Reshape_1367 -> (-1, 768)[FLOAT]], [onnx::Reshape_1368 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Reshape_765 for ONNX node: Reshape_765\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1369 for ONNX tensor: onnx::Reshape_1369\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_765 [Reshape] outputs: [onnx::Reshape_1369 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Unsqueeze_766 [Unsqueeze]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Unsqueeze_1360\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_766 [Unsqueeze] inputs: [onnx::Unsqueeze_1360 -> ()[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Unsqueeze_766 for ONNX node: Unsqueeze_766\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Concat_1372 for ONNX tensor: onnx::Concat_1372\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_766 [Unsqueeze] outputs: [onnx::Concat_1372 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Unsqueeze_767 [Unsqueeze]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Unsqueeze_1363\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_767 [Unsqueeze] inputs: [onnx::Unsqueeze_1363 -> ()[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Unsqueeze_767 for ONNX node: Unsqueeze_767\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Concat_1373 for ONNX tensor: onnx::Concat_1373\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_767 [Unsqueeze] outputs: [onnx::Concat_1373 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Concat_768 [Concat]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Concat_1372\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Concat_1373\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Concat_1550\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Concat_1551\n",
      "[05/24/2022-15:21:33] [TRT] [V] Concat_768 [Concat] inputs: [onnx::Concat_1372 -> (1)[INT32]], [onnx::Concat_1373 -> (1)[INT32]], [onnx::Concat_1550 -> (1)[INT32]], [onnx::Concat_1551 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::Concat_1550 for ONNX node: onnx::Concat_1550\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::Concat_1551 for ONNX node: onnx::Concat_1551\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Concat_768 for ONNX node: Concat_768\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1376 for ONNX tensor: onnx::Reshape_1376\n",
      "[05/24/2022-15:21:33] [TRT] [V] Concat_768 [Concat] outputs: [onnx::Reshape_1376 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Reshape_769 [Reshape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1369\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1376\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_769 [Reshape] inputs: [onnx::Reshape_1369 -> (-1, -1, 768)[FLOAT]], [onnx::Reshape_1376 -> (4)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Reshape_769 for ONNX node: Reshape_769\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Split_1377 for ONNX tensor: onnx::Split_1377\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_769 [Reshape] outputs: [onnx::Split_1377 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Split_770 [Split]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Split_1377\n",
      "[05/24/2022-15:21:33] [TRT] [V] Split_770 [Split] inputs: [onnx::Split_1377 -> (-1, -1, 12, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Split_770 for ONNX node: Split_770\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Split_770_661 for ONNX node: Split_770\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Split_770_663 for ONNX node: Split_770\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Transpose_1378 for ONNX tensor: onnx::Transpose_1378\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Transpose_1379 for ONNX tensor: onnx::Transpose_1379\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Transpose_1380 for ONNX tensor: onnx::Transpose_1380\n",
      "[05/24/2022-15:21:33] [TRT] [V] Split_770 [Split] outputs: [onnx::Transpose_1378 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1379 -> (-1, -1, 12, 16)[FLOAT]], [onnx::Transpose_1380 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Transpose_771 [Transpose]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Transpose_1378\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_771 [Transpose] inputs: [onnx::Transpose_1378 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Transpose_771 for ONNX node: Transpose_771\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::MatMul_1381 for ONNX tensor: onnx::MatMul_1381\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_771 [Transpose] outputs: [onnx::MatMul_1381 -> (-1, 12, -1, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Transpose_772 [Transpose]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Transpose_1380\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_772 [Transpose] inputs: [onnx::Transpose_1380 -> (-1, -1, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Transpose_772 for ONNX node: Transpose_772\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::MatMul_1382 for ONNX tensor: onnx::MatMul_1382\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_772 [Transpose] outputs: [onnx::MatMul_1382 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Transpose_773 [Transpose]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Transpose_1379\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_773 [Transpose] inputs: [onnx::Transpose_1379 -> (-1, -1, 12, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Transpose_773 for ONNX node: Transpose_773\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::MatMul_1383 for ONNX tensor: onnx::MatMul_1383\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_773 [Transpose] outputs: [onnx::MatMul_1383 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: MatMul_774 [MatMul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1381\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1383\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_774 [MatMul] inputs: [onnx::MatMul_1381 -> (-1, 12, -1, 16)[FLOAT]], [onnx::MatMul_1383 -> (-1, 12, 16, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: MatMul_774 for ONNX node: MatMul_774\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Mul_1384 for ONNX tensor: onnx::Mul_1384\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_774 [MatMul] outputs: [onnx::Mul_1384 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Constant_775 [Constant]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Constant_775 [Constant] inputs: \n",
      "[05/24/2022-15:21:33] [TRT] [V] Constant_775 [Constant] outputs: [onnx::Mul_1385 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Mul_776 [Mul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Mul_1384\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Mul_1385\n",
      "[05/24/2022-15:21:33] [TRT] [V] Mul_776 [Mul] inputs: [onnx::Mul_1384 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Mul_1385 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::Mul_1385 for ONNX node: onnx::Mul_1385\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Mul_776 for ONNX node: Mul_776\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Add_1386 for ONNX tensor: onnx::Add_1386\n",
      "[05/24/2022-15:21:33] [TRT] [V] Mul_776 [Mul] outputs: [onnx::Add_1386 -> (-1, 12, -1, -1)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Constant_777 [Constant]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Constant_777 [Constant] inputs: \n",
      "[05/24/2022-15:21:33] [TRT] [V] Constant_777 [Constant] outputs: [onnx::Add_1387 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Add_778 [Add]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Add_1386\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Add_1387\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_778 [Add] inputs: [onnx::Add_1386 -> (-1, 12, -1, -1)[FLOAT]], [onnx::Add_1387 -> (12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::Add_1387 for ONNX node: onnx::Add_1387\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Add_778 for ONNX node: Add_778\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Softmax_1388 for ONNX tensor: onnx::Softmax_1388\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_778 [Add] outputs: [onnx::Softmax_1388 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Softmax_779 [Softmax]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Softmax_1388\n",
      "[05/24/2022-15:21:33] [TRT] [V] Softmax_779 [Softmax] inputs: [onnx::Softmax_1388 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Softmax_779 for ONNX node: Softmax_779\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::MatMul_1389 for ONNX tensor: onnx::MatMul_1389\n",
      "[05/24/2022-15:21:33] [TRT] [V] Softmax_779 [Softmax] outputs: [onnx::MatMul_1389 -> (-1, 12, 16, 16)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: MatMul_780 [MatMul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1389\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1382\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_780 [MatMul] inputs: [onnx::MatMul_1389 -> (-1, 12, 16, 16)[FLOAT]], [onnx::MatMul_1382 -> (-1, 12, -1, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: MatMul_780 for ONNX node: MatMul_780\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Transpose_1390 for ONNX tensor: onnx::Transpose_1390\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_780 [MatMul] outputs: [onnx::Transpose_1390 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Transpose_781 [Transpose]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Transpose_1390\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_781 [Transpose] inputs: [onnx::Transpose_1390 -> (-1, 12, 16, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Transpose_781 for ONNX node: Transpose_781\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1391 for ONNX tensor: onnx::Reshape_1391\n",
      "[05/24/2022-15:21:33] [TRT] [V] Transpose_781 [Transpose] outputs: [onnx::Reshape_1391 -> (-1, 16, 12, 32)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Unsqueeze_782 [Unsqueeze]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Unsqueeze_1360\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_782 [Unsqueeze] inputs: [onnx::Unsqueeze_1360 -> ()[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Unsqueeze_782 for ONNX node: Unsqueeze_782\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Concat_1393 for ONNX tensor: onnx::Concat_1393\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_782 [Unsqueeze] outputs: [onnx::Concat_1393 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Unsqueeze_783 [Unsqueeze]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Unsqueeze_1363\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_783 [Unsqueeze] inputs: [onnx::Unsqueeze_1363 -> ()[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (), unsqueezing to: (1,)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Unsqueeze_783 for ONNX node: Unsqueeze_783\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Concat_1394 for ONNX tensor: onnx::Concat_1394\n",
      "[05/24/2022-15:21:33] [TRT] [V] Unsqueeze_783 [Unsqueeze] outputs: [onnx::Concat_1394 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Concat_784 [Concat]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Concat_1393\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Concat_1394\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Concat_1552\n",
      "[05/24/2022-15:21:33] [TRT] [V] Concat_784 [Concat] inputs: [onnx::Concat_1393 -> (1)[INT32]], [onnx::Concat_1394 -> (1)[INT32]], [onnx::Concat_1552 -> (1)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::Concat_1552 for ONNX node: onnx::Concat_1552\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Concat_784 for ONNX node: Concat_784\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1396 for ONNX tensor: onnx::Reshape_1396\n",
      "[05/24/2022-15:21:33] [TRT] [V] Concat_784 [Concat] outputs: [onnx::Reshape_1396 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Reshape_785 [Reshape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1391\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1396\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_785 [Reshape] inputs: [onnx::Reshape_1391 -> (-1, 16, 12, 32)[FLOAT]], [onnx::Reshape_1396 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Reshape_785 for ONNX node: Reshape_785\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: input.364 for ONNX tensor: input.364\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_785 [Reshape] outputs: [input.364 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: HardSigmoid_786 [HardSigmoid]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.364\n",
      "[05/24/2022-15:21:33] [TRT] [V] HardSigmoid_786 [HardSigmoid] inputs: [input.364 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: HardSigmoid_786 for ONNX node: HardSigmoid_786\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Mul_1398 for ONNX tensor: onnx::Mul_1398\n",
      "[05/24/2022-15:21:33] [TRT] [V] HardSigmoid_786 [HardSigmoid] outputs: [onnx::Mul_1398 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Mul_787 [Mul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.364\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Mul_1398\n",
      "[05/24/2022-15:21:33] [TRT] [V] Mul_787 [Mul] inputs: [input.364 -> (-1, -1, 384)[FLOAT]], [onnx::Mul_1398 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Mul_787 for ONNX node: Mul_787\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::MatMul_1399 for ONNX tensor: onnx::MatMul_1399\n",
      "[05/24/2022-15:21:33] [TRT] [V] Mul_787 [Mul] outputs: [onnx::MatMul_1399 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: MatMul_788 [MatMul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1399\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1553\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_788 [MatMul] inputs: [onnx::MatMul_1399 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1553 -> (384, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::MatMul_1553 for ONNX node: onnx::MatMul_1553\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: MatMul_788 for ONNX node: MatMul_788\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Flatten_1401 for ONNX tensor: onnx::Flatten_1401\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_788 [MatMul] outputs: [onnx::Flatten_1401 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Flatten_789 [Flatten]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Flatten_1401\n",
      "[05/24/2022-15:21:33] [TRT] [V] Flatten_789 [Flatten] inputs: [onnx::Flatten_1401 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Flatten_789 for ONNX node: Flatten_789\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: input.368 for ONNX tensor: input.368\n",
      "[05/24/2022-15:21:33] [TRT] [V] Flatten_789 [Flatten] outputs: [input.368 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: BatchNormalization_790 [BatchNormalization]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.368\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.proj.1.bn.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.proj.1.bn.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.proj.1.bn.running_mean\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.26.m.proj.1.bn.running_var\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_790 [BatchNormalization] inputs: [input.368 -> (-1, 384)[FLOAT]], [blocks.26.m.proj.1.bn.weight -> (384)[FLOAT]], [blocks.26.m.proj.1.bn.bias -> (384)[FLOAT]], [blocks.26.m.proj.1.bn.running_mean -> (384)[FLOAT]], [blocks.26.m.proj.1.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: BatchNormalization_790 for ONNX node: BatchNormalization_790\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1403 for ONNX tensor: onnx::Reshape_1403\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_790 [BatchNormalization] outputs: [onnx::Reshape_1403 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Shape_791 [Shape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Flatten_1401\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_791 [Shape] inputs: [onnx::Flatten_1401 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Shape_791 for ONNX node: Shape_791\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1404 for ONNX tensor: onnx::Reshape_1404\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_791 [Shape] outputs: [onnx::Reshape_1404 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Reshape_792 [Reshape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1403\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1404\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_792 [Reshape] inputs: [onnx::Reshape_1403 -> (-1, 384)[FLOAT]], [onnx::Reshape_1404 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Reshape_792 for ONNX node: Reshape_792\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Add_1405 for ONNX tensor: onnx::Add_1405\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_792 [Reshape] outputs: [onnx::Add_1405 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Add_793 [Add]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Shape_1357\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Add_1405\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_793 [Add] inputs: [onnx::Shape_1357 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1405 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Add_793 for ONNX node: Add_793\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::MatMul_1406 for ONNX tensor: onnx::MatMul_1406\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_793 [Add] outputs: [onnx::MatMul_1406 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: MatMul_794 [MatMul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1406\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1554\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_794 [MatMul] inputs: [onnx::MatMul_1406 -> (-1, -1, 384)[FLOAT]], [onnx::MatMul_1554 -> (384, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::MatMul_1554 for ONNX node: onnx::MatMul_1554\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: MatMul_794 for ONNX node: MatMul_794\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Flatten_1408 for ONNX tensor: onnx::Flatten_1408\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_794 [MatMul] outputs: [onnx::Flatten_1408 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Flatten_795 [Flatten]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Flatten_1408\n",
      "[05/24/2022-15:21:33] [TRT] [V] Flatten_795 [Flatten] inputs: [onnx::Flatten_1408 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Flatten_795 for ONNX node: Flatten_795\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: input.372 for ONNX tensor: input.372\n",
      "[05/24/2022-15:21:33] [TRT] [V] Flatten_795 [Flatten] outputs: [input.372 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: BatchNormalization_796 [BatchNormalization]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.372\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.0.bn.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.0.bn.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.0.bn.running_mean\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.0.bn.running_var\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_796 [BatchNormalization] inputs: [input.372 -> (-1, 768)[FLOAT]], [blocks.27.m.0.bn.weight -> (768)[FLOAT]], [blocks.27.m.0.bn.bias -> (768)[FLOAT]], [blocks.27.m.0.bn.running_mean -> (768)[FLOAT]], [blocks.27.m.0.bn.running_var -> (768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (_, 768), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: BatchNormalization_796 for ONNX node: BatchNormalization_796\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1410 for ONNX tensor: onnx::Reshape_1410\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_796 [BatchNormalization] outputs: [onnx::Reshape_1410 -> (-1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Shape_797 [Shape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Flatten_1408\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_797 [Shape] inputs: [onnx::Flatten_1408 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Shape_797 for ONNX node: Shape_797\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1411 for ONNX tensor: onnx::Reshape_1411\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_797 [Shape] outputs: [onnx::Reshape_1411 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Reshape_798 [Reshape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1410\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1411\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_798 [Reshape] inputs: [onnx::Reshape_1410 -> (-1, 768)[FLOAT]], [onnx::Reshape_1411 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Reshape_798 for ONNX node: Reshape_798\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: input.376 for ONNX tensor: input.376\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_798 [Reshape] outputs: [input.376 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: HardSigmoid_799 [HardSigmoid]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.376\n",
      "[05/24/2022-15:21:33] [TRT] [V] HardSigmoid_799 [HardSigmoid] inputs: [input.376 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: HardSigmoid_799 for ONNX node: HardSigmoid_799\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Mul_1413 for ONNX tensor: onnx::Mul_1413\n",
      "[05/24/2022-15:21:33] [TRT] [V] HardSigmoid_799 [HardSigmoid] outputs: [onnx::Mul_1413 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Mul_800 [Mul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.376\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Mul_1413\n",
      "[05/24/2022-15:21:33] [TRT] [V] Mul_800 [Mul] inputs: [input.376 -> (-1, -1, 768)[FLOAT]], [onnx::Mul_1413 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Mul_800 for ONNX node: Mul_800\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::MatMul_1414 for ONNX tensor: onnx::MatMul_1414\n",
      "[05/24/2022-15:21:33] [TRT] [V] Mul_800 [Mul] outputs: [onnx::MatMul_1414 -> (-1, -1, 768)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: MatMul_801 [MatMul]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1414\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1555\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_801 [MatMul] inputs: [onnx::MatMul_1414 -> (-1, -1, 768)[FLOAT]], [onnx::MatMul_1555 -> (768, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::MatMul_1555 for ONNX node: onnx::MatMul_1555\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: MatMul_801 for ONNX node: MatMul_801\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Flatten_1416 for ONNX tensor: onnx::Flatten_1416\n",
      "[05/24/2022-15:21:33] [TRT] [V] MatMul_801 [MatMul] outputs: [onnx::Flatten_1416 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Flatten_802 [Flatten]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Flatten_1416\n",
      "[05/24/2022-15:21:33] [TRT] [V] Flatten_802 [Flatten] inputs: [onnx::Flatten_1416 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Flatten_802 for ONNX node: Flatten_802\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: input.380 for ONNX tensor: input.380\n",
      "[05/24/2022-15:21:33] [TRT] [V] Flatten_802 [Flatten] outputs: [input.380 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: BatchNormalization_803 [BatchNormalization]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.380\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.2.bn.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.2.bn.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.2.bn.running_mean\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: blocks.27.m.2.bn.running_var\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_803 [BatchNormalization] inputs: [input.380 -> (-1, 384)[FLOAT]], [blocks.27.m.2.bn.weight -> (384)[FLOAT]], [blocks.27.m.2.bn.bias -> (384)[FLOAT]], [blocks.27.m.2.bn.running_mean -> (384)[FLOAT]], [blocks.27.m.2.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: BatchNormalization_803 for ONNX node: BatchNormalization_803\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1418 for ONNX tensor: onnx::Reshape_1418\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_803 [BatchNormalization] outputs: [onnx::Reshape_1418 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Shape_804 [Shape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Flatten_1416\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_804 [Shape] inputs: [onnx::Flatten_1416 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Shape_804 for ONNX node: Shape_804\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Reshape_1419 for ONNX tensor: onnx::Reshape_1419\n",
      "[05/24/2022-15:21:33] [TRT] [V] Shape_804 [Shape] outputs: [onnx::Reshape_1419 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Reshape_805 [Reshape]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1418\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Reshape_1419\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_805 [Reshape] inputs: [onnx::Reshape_1418 -> (-1, 384)[FLOAT]], [onnx::Reshape_1419 -> (3)[INT32]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Reshape_805 for ONNX node: Reshape_805\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Add_1420 for ONNX tensor: onnx::Add_1420\n",
      "[05/24/2022-15:21:33] [TRT] [V] Reshape_805 [Reshape] outputs: [onnx::Add_1420 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Add_806 [Add]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::MatMul_1406\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Add_1420\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_806 [Add] inputs: [onnx::MatMul_1406 -> (-1, -1, 384)[FLOAT]], [onnx::Add_1420 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Add_806 for ONNX node: Add_806\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::ReduceMean_1421 for ONNX tensor: onnx::ReduceMean_1421\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_806 [Add] outputs: [onnx::ReduceMean_1421 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: ReduceMean_807 [ReduceMean]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::ReduceMean_1421\n",
      "[05/24/2022-15:21:33] [TRT] [V] ReduceMean_807 [ReduceMean] inputs: [onnx::ReduceMean_1421 -> (-1, -1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: ReduceMean_807 for ONNX node: ReduceMean_807\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: input.384 for ONNX tensor: input.384\n",
      "[05/24/2022-15:21:33] [TRT] [V] ReduceMean_807 [ReduceMean] outputs: [input.384 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: BatchNormalization_808 [BatchNormalization]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.384\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head.bn.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head.bn.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head.bn.running_mean\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head.bn.running_var\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_808 [BatchNormalization] inputs: [input.384 -> (-1, 384)[FLOAT]], [head.bn.weight -> (384)[FLOAT]], [head.bn.bias -> (384)[FLOAT]], [head.bn.running_mean -> (384)[FLOAT]], [head.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: BatchNormalization_808 for ONNX node: BatchNormalization_808\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Gemm_1423 for ONNX tensor: onnx::Gemm_1423\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_808 [BatchNormalization] outputs: [onnx::Gemm_1423 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Gemm_809 [Gemm]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Gemm_1423\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head.l.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head.l.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Gemm_809 [Gemm] inputs: [onnx::Gemm_1423 -> (-1, 384)[FLOAT]], [head.l.weight -> (1000, 384)[FLOAT]], [head.l.bias -> (1000)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: head.l.weight for ONNX node: head.l.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Using opA: 0 opB: 1\n",
      "[05/24/2022-15:21:33] [TRT] [V] GEMM: A, after squeezing: (-1, 384)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Gemm_809 for ONNX node: Gemm_809\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: head.l.bias for ONNX node: head.l.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Add_1424 for ONNX tensor: onnx::Add_1424\n",
      "[05/24/2022-15:21:33] [TRT] [V] Gemm_809 [Gemm] outputs: [onnx::Add_1424 -> (-1, 1000)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: BatchNormalization_810 [BatchNormalization]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: input.384\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head_dist.bn.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head_dist.bn.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head_dist.bn.running_mean\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head_dist.bn.running_var\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_810 [BatchNormalization] inputs: [input.384 -> (-1, 384)[FLOAT]], [head_dist.bn.weight -> (384)[FLOAT]], [head_dist.bn.bias -> (384)[FLOAT]], [head_dist.bn.running_mean -> (384)[FLOAT]], [head_dist.bn.running_var -> (384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Original shape: (_, 384), unsqueezing to: (_, _, _, _)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: BatchNormalization_810 for ONNX node: BatchNormalization_810\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Gemm_1425 for ONNX tensor: onnx::Gemm_1425\n",
      "[05/24/2022-15:21:33] [TRT] [V] BatchNormalization_810 [BatchNormalization] outputs: [onnx::Gemm_1425 -> (-1, 384)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Gemm_811 [Gemm]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Gemm_1425\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head_dist.l.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: head_dist.l.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Gemm_811 [Gemm] inputs: [onnx::Gemm_1425 -> (-1, 384)[FLOAT]], [head_dist.l.weight -> (1000, 384)[FLOAT]], [head_dist.l.bias -> (1000)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: head_dist.l.weight for ONNX node: head_dist.l.weight\n",
      "[05/24/2022-15:21:33] [TRT] [V] Using opA: 0 opB: 1\n",
      "[05/24/2022-15:21:33] [TRT] [V] GEMM: A, after squeezing: (-1, 384)\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Gemm_811 for ONNX node: Gemm_811\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: head_dist.l.bias for ONNX node: head_dist.l.bias\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Add_1426 for ONNX tensor: onnx::Add_1426\n",
      "[05/24/2022-15:21:33] [TRT] [V] Gemm_811 [Gemm] outputs: [onnx::Add_1426 -> (-1, 1000)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Add_812 [Add]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Add_1424\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Add_1426\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_812 [Add] inputs: [onnx::Add_1424 -> (-1, 1000)[FLOAT]], [onnx::Add_1426 -> (-1, 1000)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Add_812 for ONNX node: Add_812\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: onnx::Div_1427 for ONNX tensor: onnx::Div_1427\n",
      "[05/24/2022-15:21:33] [TRT] [V] Add_812 [Add] outputs: [onnx::Div_1427 -> (-1, 1000)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Constant_813 [Constant]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Constant_813 [Constant] inputs: \n",
      "[05/24/2022-15:21:33] [TRT] [V] Constant_813 [Constant] outputs: [onnx::Div_1428 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Parsing node: Div_814 [Div]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Div_1427\n",
      "[05/24/2022-15:21:33] [TRT] [V] Searching for input: onnx::Div_1428\n",
      "[05/24/2022-15:21:33] [TRT] [V] Div_814 [Div] inputs: [onnx::Div_1427 -> (-1, 1000)[FLOAT]], [onnx::Div_1428 -> ()[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: onnx::Div_1428 for ONNX node: onnx::Div_1428\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering layer: Div_814 for ONNX node: Div_814\n",
      "[05/24/2022-15:21:33] [TRT] [V] Registering tensor: output_697 for ONNX tensor: output\n",
      "[05/24/2022-15:21:33] [TRT] [V] Div_814 [Div] outputs: [output -> (-1, 1000)[FLOAT]], \n",
      "[05/24/2022-15:21:33] [TRT] [V] Marking output_697 as output: output\n",
      "[05/24/2022-15:21:33] [TRT] [V] Applying generic optimizations to the graph for inference.\n",
      "[05/24/2022-15:21:33] [TRT] [V] Original: 867 layers\n",
      "[05/24/2022-15:21:33] [TRT] [V] After dead-layer removal: 867 layers\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1442 with (Unnamed Layer* 23) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_465 with (Unnamed Layer* 69) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_467 with (Unnamed Layer* 72) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1446 with (Unnamed Layer* 97) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1447 with (Unnamed Layer* 120) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1448 with (Unnamed Layer* 144) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1449 with (Unnamed Layer* 173) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_529 with (Unnamed Layer* 219) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_531 with (Unnamed Layer* 222) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1453 with (Unnamed Layer* 247) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1454 with (Unnamed Layer* 270) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1455 with (Unnamed Layer* 294) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1456 with (Unnamed Layer* 323) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_593 with (Unnamed Layer* 369) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_595 with (Unnamed Layer* 372) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1460 with (Unnamed Layer* 397) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1461 with (Unnamed Layer* 420) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1462 with (Unnamed Layer* 444) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1463 with (Unnamed Layer* 473) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_657 with (Unnamed Layer* 519) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_659 with (Unnamed Layer* 522) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1467 with (Unnamed Layer* 547) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1468 with (Unnamed Layer* 570) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1469 with (Unnamed Layer* 594) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1470 with (Unnamed Layer* 623) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1476 with (Unnamed Layer* 733) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_765 with (Unnamed Layer* 764) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_767 with (Unnamed Layer* 767) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1482 with (Unnamed Layer* 792) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1483 with (Unnamed Layer* 815) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1484 with (Unnamed Layer* 840) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1485 with (Unnamed Layer* 870) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_829 with (Unnamed Layer* 917) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_831 with (Unnamed Layer* 920) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1489 with (Unnamed Layer* 945) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1490 with (Unnamed Layer* 969) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1491 with (Unnamed Layer* 994) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1492 with (Unnamed Layer* 1024) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_893 with (Unnamed Layer* 1071) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_895 with (Unnamed Layer* 1074) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1496 with (Unnamed Layer* 1099) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1497 with (Unnamed Layer* 1123) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1498 with (Unnamed Layer* 1148) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1499 with (Unnamed Layer* 1178) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_957 with (Unnamed Layer* 1225) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_959 with (Unnamed Layer* 1228) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1503 with (Unnamed Layer* 1253) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1504 with (Unnamed Layer* 1277) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1505 with (Unnamed Layer* 1302) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1506 with (Unnamed Layer* 1332) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_1021 with (Unnamed Layer* 1379) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_1023 with (Unnamed Layer* 1382) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1510 with (Unnamed Layer* 1407) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1511 with (Unnamed Layer* 1431) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1512 with (Unnamed Layer* 1456) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1513 with (Unnamed Layer* 1486) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1519 with (Unnamed Layer* 1597) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_1129 with (Unnamed Layer* 1628) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_1131 with (Unnamed Layer* 1631) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1525 with (Unnamed Layer* 1656) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1526 with (Unnamed Layer* 1679) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1527 with (Unnamed Layer* 1704) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1528 with (Unnamed Layer* 1734) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_1193 with (Unnamed Layer* 1781) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_1195 with (Unnamed Layer* 1784) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1532 with (Unnamed Layer* 1809) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1533 with (Unnamed Layer* 1833) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1534 with (Unnamed Layer* 1858) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1535 with (Unnamed Layer* 1888) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_1257 with (Unnamed Layer* 1935) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_1259 with (Unnamed Layer* 1938) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1539 with (Unnamed Layer* 1963) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1540 with (Unnamed Layer* 1987) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1541 with (Unnamed Layer* 2012) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1542 with (Unnamed Layer* 2042) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_1321 with (Unnamed Layer* 2089) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_1323 with (Unnamed Layer* 2092) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1546 with (Unnamed Layer* 2117) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1547 with (Unnamed Layer* 2141) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1548 with (Unnamed Layer* 2166) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1549 with (Unnamed Layer* 2196) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Mul_1385 with (Unnamed Layer* 2243) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Add_1387 with (Unnamed Layer* 2246) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1553 with (Unnamed Layer* 2271) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1554 with (Unnamed Layer* 2295) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::MatMul_1555 with (Unnamed Layer* 2320) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing head.l.bias with (Unnamed Layer* 2356) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Reshape_17 with Transpose_18\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_26 with (Unnamed Layer* 38) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 40) [Shuffle] with Reshape_29\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 40) [Shuffle] + Reshape_29 with Reshape_33\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_45 with Reshape_49\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_53 with (Unnamed Layer* 112) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 114) [Shuffle] with Reshape_56\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_59 with (Unnamed Layer* 135) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 137) [Shuffle] with Reshape_62\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_66 with (Unnamed Layer* 159) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 161) [Shuffle] with Reshape_69\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_78 with (Unnamed Layer* 188) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 190) [Shuffle] with Reshape_81\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 190) [Shuffle] + Reshape_81 with Reshape_85\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_97 with Reshape_101\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_105 with (Unnamed Layer* 262) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 264) [Shuffle] with Reshape_108\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_111 with (Unnamed Layer* 285) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 287) [Shuffle] with Reshape_114\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_118 with (Unnamed Layer* 309) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 311) [Shuffle] with Reshape_121\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_130 with (Unnamed Layer* 338) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 340) [Shuffle] with Reshape_133\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 340) [Shuffle] + Reshape_133 with Reshape_137\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_149 with Reshape_153\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_157 with (Unnamed Layer* 412) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 414) [Shuffle] with Reshape_160\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_163 with (Unnamed Layer* 435) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 437) [Shuffle] with Reshape_166\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_170 with (Unnamed Layer* 459) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 461) [Shuffle] with Reshape_173\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_182 with (Unnamed Layer* 488) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 490) [Shuffle] with Reshape_185\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 490) [Shuffle] + Reshape_185 with Reshape_189\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_201 with Reshape_205\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_209 with (Unnamed Layer* 562) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 564) [Shuffle] with Reshape_212\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_215 with (Unnamed Layer* 585) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 587) [Shuffle] with Reshape_218\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_222 with (Unnamed Layer* 609) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 611) [Shuffle] with Reshape_225\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_234 with (Unnamed Layer* 638) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 640) [Shuffle] with Reshape_237\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 640) [Shuffle] + Reshape_237 with Reshape_241\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_269 with (Unnamed Layer* 748) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 750) [Shuffle] with Reshape_272\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 750) [Shuffle] + Reshape_272 with Reshape_275\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 with Transpose_276\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_285 with Reshape_288\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_292 with (Unnamed Layer* 808) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 810) [Shuffle] with Reshape_295\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_297 with (Unnamed Layer* 831) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 833) [Shuffle] with Reshape_300\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_304 with (Unnamed Layer* 856) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 858) [Shuffle] with Reshape_307\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_316 with (Unnamed Layer* 886) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 888) [Shuffle] with Reshape_319\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 888) [Shuffle] + Reshape_319 with Reshape_323\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_335 with Reshape_339\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_343 with (Unnamed Layer* 961) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 963) [Shuffle] with Reshape_346\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_349 with (Unnamed Layer* 985) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 987) [Shuffle] with Reshape_352\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_356 with (Unnamed Layer* 1010) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1012) [Shuffle] with Reshape_359\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_368 with (Unnamed Layer* 1040) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1042) [Shuffle] with Reshape_371\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1042) [Shuffle] + Reshape_371 with Reshape_375\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_387 with Reshape_391\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_395 with (Unnamed Layer* 1115) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1117) [Shuffle] with Reshape_398\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_401 with (Unnamed Layer* 1139) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1141) [Shuffle] with Reshape_404\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_408 with (Unnamed Layer* 1164) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1166) [Shuffle] with Reshape_411\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_420 with (Unnamed Layer* 1194) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1196) [Shuffle] with Reshape_423\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1196) [Shuffle] + Reshape_423 with Reshape_427\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_439 with Reshape_443\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_447 with (Unnamed Layer* 1269) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1271) [Shuffle] with Reshape_450\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_453 with (Unnamed Layer* 1293) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1295) [Shuffle] with Reshape_456\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_460 with (Unnamed Layer* 1318) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1320) [Shuffle] with Reshape_463\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_472 with (Unnamed Layer* 1348) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1350) [Shuffle] with Reshape_475\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1350) [Shuffle] + Reshape_475 with Reshape_479\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_491 with Reshape_495\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_499 with (Unnamed Layer* 1423) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1425) [Shuffle] with Reshape_502\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_505 with (Unnamed Layer* 1447) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1449) [Shuffle] with Reshape_508\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_512 with (Unnamed Layer* 1472) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1474) [Shuffle] with Reshape_515\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_524 with (Unnamed Layer* 1502) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1504) [Shuffle] with Reshape_527\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1504) [Shuffle] + Reshape_527 with Reshape_531\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_559 with (Unnamed Layer* 1612) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1614) [Shuffle] with Reshape_562\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1614) [Shuffle] + Reshape_562 with Reshape_565\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 with Transpose_566\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_575 with Reshape_578\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_582 with (Unnamed Layer* 1672) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1674) [Shuffle] with Reshape_585\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_587 with (Unnamed Layer* 1695) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1697) [Shuffle] with Reshape_590\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_594 with (Unnamed Layer* 1720) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1722) [Shuffle] with Reshape_597\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_606 with (Unnamed Layer* 1750) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1752) [Shuffle] with Reshape_609\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1752) [Shuffle] + Reshape_609 with Reshape_613\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_625 with Reshape_629\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_633 with (Unnamed Layer* 1825) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1827) [Shuffle] with Reshape_636\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_639 with (Unnamed Layer* 1849) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1851) [Shuffle] with Reshape_642\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_646 with (Unnamed Layer* 1874) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1876) [Shuffle] with Reshape_649\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_658 with (Unnamed Layer* 1904) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1906) [Shuffle] with Reshape_661\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1906) [Shuffle] + Reshape_661 with Reshape_665\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_677 with Reshape_681\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_685 with (Unnamed Layer* 1979) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 1981) [Shuffle] with Reshape_688\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_691 with (Unnamed Layer* 2003) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2005) [Shuffle] with Reshape_694\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_698 with (Unnamed Layer* 2028) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2030) [Shuffle] with Reshape_701\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_710 with (Unnamed Layer* 2058) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2060) [Shuffle] with Reshape_713\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2060) [Shuffle] + Reshape_713 with Reshape_717\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_729 with Reshape_733\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_737 with (Unnamed Layer* 2133) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2135) [Shuffle] with Reshape_740\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_743 with (Unnamed Layer* 2157) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2159) [Shuffle] with Reshape_746\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_750 with (Unnamed Layer* 2182) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2184) [Shuffle] with Reshape_753\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_762 with (Unnamed Layer* 2212) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2214) [Shuffle] with Reshape_765\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2214) [Shuffle] + Reshape_765 with Reshape_769\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Transpose_781 with Reshape_785\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_789 with (Unnamed Layer* 2287) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2289) [Shuffle] with Reshape_792\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_795 with (Unnamed Layer* 2311) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2313) [Shuffle] with Reshape_798\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing Flatten_802 with (Unnamed Layer* 2336) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2338) [Shuffle] with Reshape_805\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing head_dist.l.bias with (Unnamed Layer* 2370) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstShuffleFusion: Fusing onnx::Div_1428 with (Unnamed Layer* 2374) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] After Myelin optimization: 629 layers\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_52 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_58 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_65 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_77 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_104 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_110 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_117 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_129 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_156 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_162 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_169 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_181 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_208 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_214 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_221 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_233 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_291 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_303 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_315 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_342 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_348 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_355 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_367 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_394 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_400 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_407 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_419 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_446 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_452 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_459 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_471 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_498 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_504 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_511 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_523 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_581 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_593 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_605 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_632 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_638 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_645 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_657 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_684 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_690 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_697 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_709 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_736 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_742 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_749 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_761 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_788 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_794 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of MatMul_801 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of Gemm_809 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: MatMulToConvTransform\n",
      "[05/24/2022-15:21:33] [TRT] [V] Convert layer type of Gemm_811 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_465 + (Unnamed Layer* 69) [Shuffle] with Mul_40\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_467 + (Unnamed Layer* 72) [Shuffle] with Add_42\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_529 + (Unnamed Layer* 219) [Shuffle] with Mul_92\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_531 + (Unnamed Layer* 222) [Shuffle] with Add_94\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_593 + (Unnamed Layer* 369) [Shuffle] with Mul_144\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_595 + (Unnamed Layer* 372) [Shuffle] with Add_146\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_657 + (Unnamed Layer* 519) [Shuffle] with Mul_196\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_659 + (Unnamed Layer* 522) [Shuffle] with Add_198\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_765 + (Unnamed Layer* 764) [Shuffle] with Mul_280\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_767 + (Unnamed Layer* 767) [Shuffle] with Add_282\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_829 + (Unnamed Layer* 917) [Shuffle] with Mul_330\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_831 + (Unnamed Layer* 920) [Shuffle] with Add_332\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_893 + (Unnamed Layer* 1071) [Shuffle] with Mul_382\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_895 + (Unnamed Layer* 1074) [Shuffle] with Add_384\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_957 + (Unnamed Layer* 1225) [Shuffle] with Mul_434\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_959 + (Unnamed Layer* 1228) [Shuffle] with Add_436\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_1021 + (Unnamed Layer* 1379) [Shuffle] with Mul_486\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_1023 + (Unnamed Layer* 1382) [Shuffle] with Add_488\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_1129 + (Unnamed Layer* 1628) [Shuffle] with Mul_570\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_1131 + (Unnamed Layer* 1631) [Shuffle] with Add_572\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_1193 + (Unnamed Layer* 1781) [Shuffle] with Mul_620\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_1195 + (Unnamed Layer* 1784) [Shuffle] with Add_622\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_1257 + (Unnamed Layer* 1935) [Shuffle] with Mul_672\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_1259 + (Unnamed Layer* 1938) [Shuffle] with Add_674\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_1321 + (Unnamed Layer* 2089) [Shuffle] with Mul_724\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_1323 + (Unnamed Layer* 2092) [Shuffle] with Add_726\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Mul_1385 + (Unnamed Layer* 2243) [Shuffle] with Mul_776\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ConstEltFusion: Fusing onnx::Add_1387 + (Unnamed Layer* 2246) [Shuffle] with Add_778\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_52 with Flatten_53 + (Unnamed Layer* 112) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_52 + Flatten_53 + (Unnamed Layer* 112) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_58 with Flatten_59 + (Unnamed Layer* 135) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_58 + Flatten_59 + (Unnamed Layer* 135) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_65 with Flatten_66 + (Unnamed Layer* 159) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_65 + Flatten_66 + (Unnamed Layer* 159) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_77 with Flatten_78 + (Unnamed Layer* 188) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_77 + Flatten_78 + (Unnamed Layer* 188) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_104 with Flatten_105 + (Unnamed Layer* 262) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_104 + Flatten_105 + (Unnamed Layer* 262) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_110 with Flatten_111 + (Unnamed Layer* 285) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_110 + Flatten_111 + (Unnamed Layer* 285) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_117 with Flatten_118 + (Unnamed Layer* 309) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_117 + Flatten_118 + (Unnamed Layer* 309) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_129 with Flatten_130 + (Unnamed Layer* 338) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_129 + Flatten_130 + (Unnamed Layer* 338) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_156 with Flatten_157 + (Unnamed Layer* 412) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_156 + Flatten_157 + (Unnamed Layer* 412) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_162 with Flatten_163 + (Unnamed Layer* 435) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_162 + Flatten_163 + (Unnamed Layer* 435) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_169 with Flatten_170 + (Unnamed Layer* 459) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_169 + Flatten_170 + (Unnamed Layer* 459) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_181 with Flatten_182 + (Unnamed Layer* 488) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_181 + Flatten_182 + (Unnamed Layer* 488) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_208 with Flatten_209 + (Unnamed Layer* 562) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_208 + Flatten_209 + (Unnamed Layer* 562) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_214 with Flatten_215 + (Unnamed Layer* 585) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_214 + Flatten_215 + (Unnamed Layer* 585) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_221 with Flatten_222 + (Unnamed Layer* 609) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_221 + Flatten_222 + (Unnamed Layer* 609) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_233 with Flatten_234 + (Unnamed Layer* 638) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_233 + Flatten_234 + (Unnamed Layer* 638) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_291 with Flatten_292 + (Unnamed Layer* 808) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_291 + Flatten_292 + (Unnamed Layer* 808) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_303 with Flatten_304 + (Unnamed Layer* 856) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_303 + Flatten_304 + (Unnamed Layer* 856) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_315 with Flatten_316 + (Unnamed Layer* 886) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_315 + Flatten_316 + (Unnamed Layer* 886) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_342 with Flatten_343 + (Unnamed Layer* 961) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_342 + Flatten_343 + (Unnamed Layer* 961) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_348 with Flatten_349 + (Unnamed Layer* 985) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_348 + Flatten_349 + (Unnamed Layer* 985) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_355 with Flatten_356 + (Unnamed Layer* 1010) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_355 + Flatten_356 + (Unnamed Layer* 1010) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_367 with Flatten_368 + (Unnamed Layer* 1040) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_367 + Flatten_368 + (Unnamed Layer* 1040) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_394 with Flatten_395 + (Unnamed Layer* 1115) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_394 + Flatten_395 + (Unnamed Layer* 1115) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_400 with Flatten_401 + (Unnamed Layer* 1139) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_400 + Flatten_401 + (Unnamed Layer* 1139) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_407 with Flatten_408 + (Unnamed Layer* 1164) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_407 + Flatten_408 + (Unnamed Layer* 1164) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_419 with Flatten_420 + (Unnamed Layer* 1194) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_419 + Flatten_420 + (Unnamed Layer* 1194) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_446 with Flatten_447 + (Unnamed Layer* 1269) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_446 + Flatten_447 + (Unnamed Layer* 1269) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_452 with Flatten_453 + (Unnamed Layer* 1293) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_452 + Flatten_453 + (Unnamed Layer* 1293) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_459 with Flatten_460 + (Unnamed Layer* 1318) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_459 + Flatten_460 + (Unnamed Layer* 1318) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_471 with Flatten_472 + (Unnamed Layer* 1348) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_471 + Flatten_472 + (Unnamed Layer* 1348) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_498 with Flatten_499 + (Unnamed Layer* 1423) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_498 + Flatten_499 + (Unnamed Layer* 1423) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_504 with Flatten_505 + (Unnamed Layer* 1447) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_504 + Flatten_505 + (Unnamed Layer* 1447) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_511 with Flatten_512 + (Unnamed Layer* 1472) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_511 + Flatten_512 + (Unnamed Layer* 1472) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:33] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_523 with Flatten_524 + (Unnamed Layer* 1502) [Shuffle]\n",
      "[05/24/2022-15:21:33] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:33] [TRT] [V] Removing reshape_after_MatMul_523 + Flatten_524 + (Unnamed Layer* 1502) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_581 with Flatten_582 + (Unnamed Layer* 1672) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_581 + Flatten_582 + (Unnamed Layer* 1672) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_593 with Flatten_594 + (Unnamed Layer* 1720) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_593 + Flatten_594 + (Unnamed Layer* 1720) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_605 with Flatten_606 + (Unnamed Layer* 1750) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_605 + Flatten_606 + (Unnamed Layer* 1750) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_632 with Flatten_633 + (Unnamed Layer* 1825) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_632 + Flatten_633 + (Unnamed Layer* 1825) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_638 with Flatten_639 + (Unnamed Layer* 1849) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_638 + Flatten_639 + (Unnamed Layer* 1849) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_645 with Flatten_646 + (Unnamed Layer* 1874) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_645 + Flatten_646 + (Unnamed Layer* 1874) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_657 with Flatten_658 + (Unnamed Layer* 1904) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_657 + Flatten_658 + (Unnamed Layer* 1904) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_684 with Flatten_685 + (Unnamed Layer* 1979) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_684 + Flatten_685 + (Unnamed Layer* 1979) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_690 with Flatten_691 + (Unnamed Layer* 2003) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_690 + Flatten_691 + (Unnamed Layer* 2003) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_697 with Flatten_698 + (Unnamed Layer* 2028) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_697 + Flatten_698 + (Unnamed Layer* 2028) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_709 with Flatten_710 + (Unnamed Layer* 2058) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_709 + Flatten_710 + (Unnamed Layer* 2058) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_736 with Flatten_737 + (Unnamed Layer* 2133) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_736 + Flatten_737 + (Unnamed Layer* 2133) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_742 with Flatten_743 + (Unnamed Layer* 2157) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_742 + Flatten_743 + (Unnamed Layer* 2157) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_749 with Flatten_750 + (Unnamed Layer* 2182) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_749 + Flatten_750 + (Unnamed Layer* 2182) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_761 with Flatten_762 + (Unnamed Layer* 2212) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_761 + Flatten_762 + (Unnamed Layer* 2212) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_788 with Flatten_789 + (Unnamed Layer* 2287) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_788 + Flatten_789 + (Unnamed Layer* 2287) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_794 with Flatten_795 + (Unnamed Layer* 2311) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_794 + Flatten_795 + (Unnamed Layer* 2311) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing reshape_after_MatMul_801 with Flatten_802 + (Unnamed Layer* 2336) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing reshape_after_MatMul_801 + Flatten_802 + (Unnamed Layer* 2336) [Shuffle]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2351) [Shuffle] with reshape_before_Gemm_809\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing (Unnamed Layer* 2365) [Shuffle] with reshape_before_Gemm_811\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing (Unnamed Layer* 2351) [Shuffle] + reshape_before_Gemm_809\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: SqueezePushDownJoin\n",
      "[05/24/2022-15:21:34] [TRT] [V] -----------SqueezePushDown kSQUEEZE_JOIN case: Gemm_809 --> reshape_after_Gemm_809 --> (Unnamed Layer* 2357) [ElementWise]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: SqueezePushDownJoin\n",
      "[05/24/2022-15:21:34] [TRT] [V] -----------SqueezePushDown kSQUEEZE_JOIN case: (Unnamed Layer* 2357) [ElementWise] --> copied_squeeze_after_(Unnamed Layer* 2357) [ElementWise] --> Add_812\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing (Unnamed Layer* 2365) [Shuffle] + reshape_before_Gemm_811\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: SqueezePushDownJoin\n",
      "[05/24/2022-15:21:34] [TRT] [V] -----------SqueezePushDown kSQUEEZE_JOIN case: Gemm_811 --> reshape_after_Gemm_811 --> (Unnamed Layer* 2371) [ElementWise]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConstShuffleFusion: Fusing head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] with unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConstEltFusion: Fusing head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output with (Unnamed Layer* 2371) [ElementWise]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ShuffleShuffleFusion: Fusing copied_squeeze_after_(Unnamed Layer* 2371) [ElementWise] with unsqueeze_node_after_(Unnamed Layer* 2371) [ElementWise]_onnx::Add_1426\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ShuffleErasure\n",
      "[05/24/2022-15:21:34] [TRT] [V] Removing copied_squeeze_after_(Unnamed Layer* 2371) [ElementWise] + unsqueeze_node_after_(Unnamed Layer* 2371) [ElementWise]_onnx::Add_1426\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConstShuffleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConstShuffleFusion: Fusing head.l.bias + (Unnamed Layer* 2356) [Shuffle] with unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConstEltFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConstEltFusion: Fusing head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output with (Unnamed Layer* 2357) [ElementWise]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_52 with BatchNormalization_54\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_58 with BatchNormalization_60\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_65 with BatchNormalization_67\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_77 with BatchNormalization_79\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_104 with BatchNormalization_106\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_110 with BatchNormalization_112\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_117 with BatchNormalization_119\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_129 with BatchNormalization_131\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_156 with BatchNormalization_158\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_162 with BatchNormalization_164\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_169 with BatchNormalization_171\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_181 with BatchNormalization_183\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_208 with BatchNormalization_210\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_214 with BatchNormalization_216\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_221 with BatchNormalization_223\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_233 with BatchNormalization_235\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_291 with BatchNormalization_293\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_303 with BatchNormalization_305\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_315 with BatchNormalization_317\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_342 with BatchNormalization_344\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_348 with BatchNormalization_350\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_355 with BatchNormalization_357\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_367 with BatchNormalization_369\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_394 with BatchNormalization_396\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_400 with BatchNormalization_402\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_407 with BatchNormalization_409\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_419 with BatchNormalization_421\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_446 with BatchNormalization_448\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_452 with BatchNormalization_454\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_459 with BatchNormalization_461\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_471 with BatchNormalization_473\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_498 with BatchNormalization_500\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_504 with BatchNormalization_506\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_511 with BatchNormalization_513\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_523 with BatchNormalization_525\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_581 with BatchNormalization_583\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_593 with BatchNormalization_595\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_605 with BatchNormalization_607\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_632 with BatchNormalization_634\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_638 with BatchNormalization_640\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_645 with BatchNormalization_647\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_657 with BatchNormalization_659\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_684 with BatchNormalization_686\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_690 with BatchNormalization_692\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_697 with BatchNormalization_699\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_709 with BatchNormalization_711\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_736 with BatchNormalization_738\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_742 with BatchNormalization_744\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_749 with BatchNormalization_751\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_761 with BatchNormalization_763\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_788 with BatchNormalization_790\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_794 with BatchNormalization_796\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing MatMul_801 with BatchNormalization_803\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing Gemm_809 with head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvScaleFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvScaleFusion: Fusing Gemm_811 with head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise]\n",
      "[05/24/2022-15:21:34] [TRT] [V] Applying ScaleNodes fusions.\n",
      "[05/24/2022-15:21:34] [TRT] [V] After scale fusion: 488 layers\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_38 with onnx::Mul_465 + (Unnamed Layer* 69) [Shuffle] + Mul_40\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_90 with onnx::Mul_529 + (Unnamed Layer* 219) [Shuffle] + Mul_92\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_142 with onnx::Mul_593 + (Unnamed Layer* 369) [Shuffle] + Mul_144\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_194 with onnx::Mul_657 + (Unnamed Layer* 519) [Shuffle] + Mul_196\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_278 with onnx::Mul_765 + (Unnamed Layer* 764) [Shuffle] + Mul_280\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_328 with onnx::Mul_829 + (Unnamed Layer* 917) [Shuffle] + Mul_330\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_380 with onnx::Mul_893 + (Unnamed Layer* 1071) [Shuffle] + Mul_382\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_432 with onnx::Mul_957 + (Unnamed Layer* 1225) [Shuffle] + Mul_434\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_484 with onnx::Mul_1021 + (Unnamed Layer* 1379) [Shuffle] + Mul_486\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_568 with onnx::Mul_1129 + (Unnamed Layer* 1628) [Shuffle] + Mul_570\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_618 with onnx::Mul_1193 + (Unnamed Layer* 1781) [Shuffle] + Mul_620\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_670 with onnx::Mul_1257 + (Unnamed Layer* 1935) [Shuffle] + Mul_672\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_722 with onnx::Mul_1321 + (Unnamed Layer* 2089) [Shuffle] + Mul_724\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: GemmScaleToGemmFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] GemmScaleToGemmFusion: Fusing MatMul_774 with onnx::Mul_1385 + (Unnamed Layer* 2243) [Shuffle] + Mul_776\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ConvEltwiseSumFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] ConvEltwiseSumFusion: Fusing Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] with Add_812\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_1 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_4 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_7 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_50 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_63 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_102 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_115 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_154 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_167 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_206 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_219 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_289 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_301 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_340 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_353 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_392 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_405 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_444 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_457 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_496 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_509 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_579 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_591 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_630 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_643 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_682 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_695 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_734 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_747 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_786 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: ActivationToPointwiseConversion\n",
      "[05/24/2022-15:21:34] [TRT] [V] Swap the layer type of HardSigmoid_799 from ACTIVATION to POINTWISE\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_1) with Mul_2\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_4) with Mul_5\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_7) with Mul_8\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_50) with Mul_51\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_63) with Mul_64\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_102) with Mul_103\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_115) with Mul_116\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_154) with Mul_155\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_167) with Mul_168\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_206) with Mul_207\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_219) with Mul_220\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_289) with Mul_290\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_301) with Mul_302\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_340) with Mul_341\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_353) with Mul_354\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_392) with Mul_393\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_405) with Mul_406\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_444) with Mul_445\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_457) with Mul_458\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_496) with Mul_497\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_509) with Mul_510\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_579) with Mul_580\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_591) with Mul_592\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_630) with Mul_631\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_643) with Mul_644\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_682) with Mul_683\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_695) with Mul_696\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_734) with Mul_735\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_747) with Mul_748\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_786) with Mul_787\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing PWN(HardSigmoid_799) with Mul_800\n",
      "[05/24/2022-15:21:34] [TRT] [V] Running: PointWiseFusion\n",
      "[05/24/2022-15:21:34] [TRT] [V] PointWiseFusion: Fusing onnx::Div_1428 + (Unnamed Layer* 2374) [Shuffle] with Div_814\n",
      "[05/24/2022-15:21:34] [TRT] [V] After vertical fusions: 441 layers\n",
      "[05/24/2022-15:21:34] [TRT] [V] Replacing input 0 of BatchNormalization_810 with (Unnamed Layer* 2349) [Shuffle]_output\n",
      "[05/24/2022-15:21:34] [TRT] [V] After dupe layer removal: 441 layers\n",
      "[05/24/2022-15:21:34] [TRT] [V] After final dead-layer removal: 440 layers\n",
      "[05/24/2022-15:21:34] [TRT] [V] After tensor merging: 440 layers\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_34 by retargeting onnx::Transpose_458 from onnx::Transpose_458 to onnx::Split_457\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_34_71 by retargeting onnx::Transpose_459 from onnx::Transpose_459 to onnx::Split_457\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_34_73 by retargeting onnx::Transpose_460 from onnx::Transpose_460 to onnx::Split_457\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_86 by retargeting onnx::Transpose_522 from onnx::Transpose_522 to onnx::Split_521\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_86_111 by retargeting onnx::Transpose_523 from onnx::Transpose_523 to onnx::Split_521\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_86_113 by retargeting onnx::Transpose_524 from onnx::Transpose_524 to onnx::Split_521\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_138 by retargeting onnx::Transpose_586 from onnx::Transpose_586 to onnx::Split_585\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_138_151 by retargeting onnx::Transpose_587 from onnx::Transpose_587 to onnx::Split_585\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_138_153 by retargeting onnx::Transpose_588 from onnx::Transpose_588 to onnx::Split_585\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_190 by retargeting onnx::Transpose_650 from onnx::Transpose_650 to onnx::Split_649\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_190_191 by retargeting onnx::Transpose_651 from onnx::Transpose_651 to onnx::Split_649\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_190_193 by retargeting onnx::Transpose_652 from onnx::Transpose_652 to onnx::Split_649\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_242 by retargeting onnx::Transpose_714 from onnx::Transpose_714 to onnx::Split_713\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_242_231 by retargeting onnx::Transpose_715 from onnx::Transpose_715 to onnx::Split_713\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_324 by retargeting onnx::Transpose_822 from onnx::Transpose_822 to onnx::Split_821\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_324_306 by retargeting onnx::Transpose_823 from onnx::Transpose_823 to onnx::Split_821\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_324_308 by retargeting onnx::Transpose_824 from onnx::Transpose_824 to onnx::Split_821\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_376 by retargeting onnx::Transpose_886 from onnx::Transpose_886 to onnx::Split_885\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_376_346 by retargeting onnx::Transpose_887 from onnx::Transpose_887 to onnx::Split_885\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_376_348 by retargeting onnx::Transpose_888 from onnx::Transpose_888 to onnx::Split_885\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_428 by retargeting onnx::Transpose_950 from onnx::Transpose_950 to onnx::Split_949\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_428_386 by retargeting onnx::Transpose_951 from onnx::Transpose_951 to onnx::Split_949\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_428_388 by retargeting onnx::Transpose_952 from onnx::Transpose_952 to onnx::Split_949\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_480 by retargeting onnx::Transpose_1014 from onnx::Transpose_1014 to onnx::Split_1013\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_480_426 by retargeting onnx::Transpose_1015 from onnx::Transpose_1015 to onnx::Split_1013\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_480_428 by retargeting onnx::Transpose_1016 from onnx::Transpose_1016 to onnx::Split_1013\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_532 by retargeting onnx::Transpose_1078 from onnx::Transpose_1078 to onnx::Split_1077\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_532_466 by retargeting onnx::Transpose_1079 from onnx::Transpose_1079 to onnx::Split_1077\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_614 by retargeting onnx::Transpose_1186 from onnx::Transpose_1186 to onnx::Split_1185\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_614_541 by retargeting onnx::Transpose_1187 from onnx::Transpose_1187 to onnx::Split_1185\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_614_543 by retargeting onnx::Transpose_1188 from onnx::Transpose_1188 to onnx::Split_1185\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_666 by retargeting onnx::Transpose_1250 from onnx::Transpose_1250 to onnx::Split_1249\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_666_581 by retargeting onnx::Transpose_1251 from onnx::Transpose_1251 to onnx::Split_1249\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_666_583 by retargeting onnx::Transpose_1252 from onnx::Transpose_1252 to onnx::Split_1249\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_718 by retargeting onnx::Transpose_1314 from onnx::Transpose_1314 to onnx::Split_1313\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_718_621 by retargeting onnx::Transpose_1315 from onnx::Transpose_1315 to onnx::Split_1313\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_718_623 by retargeting onnx::Transpose_1316 from onnx::Transpose_1316 to onnx::Split_1313\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_770 by retargeting onnx::Transpose_1378 from onnx::Transpose_1378 to onnx::Split_1377\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_770_661 by retargeting onnx::Transpose_1379 from onnx::Transpose_1379 to onnx::Split_1377\n",
      "[05/24/2022-15:21:34] [TRT] [V] Eliminating slice Split_770_663 by retargeting onnx::Transpose_1380 from onnx::Transpose_1380 to onnx::Split_1377\n",
      "[05/24/2022-15:21:34] [TRT] [V] After slice removal: 400 layers\n",
      "[05/24/2022-15:21:34] [TRT] [V] After concat removal: 400 layers\n",
      "[05/24/2022-15:21:34] [TRT] [V] Graph construction and optimization completed in 1.20167 seconds.\n",
      "[05/24/2022-15:21:35] [TRT] [V] Using cublas as a tactic source\n",
      "[05/24/2022-15:21:35] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.8.0 but loaded cuBLAS/cuBLAS LT 11.5.1\n",
      "[05/24/2022-15:21:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +226, GPU +92, now: CPU 3717, GPU 1005 (MiB)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Using cuDNN as a tactic source\n",
      "[05/24/2022-15:21:35] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +112, GPU +48, now: CPU 3829, GPU 1053 (MiB)\n",
      "[05/24/2022-15:21:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/24/2022-15:21:35] [TRT] [V] Constructing optimization profile number 0 [1/1].\n",
      "[05/24/2022-15:21:35] [TRT] [V] Reserving memory for activation tensors. Host: 0 bytes Device: 9697792 bytes\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(150528,50176,224,1) -> Float(150528,1,672,3) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.04192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.029248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.029248\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(150528,50176,224,1) -> Half(150528,50176,224,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.025248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(150528,50176,224,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.050208\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.021664\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.021664\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,12544,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.03888\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.037056\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.037056\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,12544,112,1) -> Float(12544,12544:32,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.10512\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.10992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.10512\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,12544,112,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.031872\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.036736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.031872\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,12544,112,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.051392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.022144\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.022144\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,1,1792,16) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.10512\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.035168\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.035168\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,1,1792,16) -> Float(12544,12544:32,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.103104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.115424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.103104\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,1,1792,16) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.051104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.035584\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.035584\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,1,1792,16) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.054048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.041472\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.041472\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.104928\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.040864\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.040864\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.105184\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.042912\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.042912\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.051424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.041408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.041408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.054304\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0472\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0472\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(200704,12544,112,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.034336\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.025664\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.025664\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(200704,12544,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.051456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.037536\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.037536\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(200704,12544,112,1) -> Float(12544,12544:32,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.044512\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.109952\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.044512\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(200704,12544,112,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.022752\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.021312\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.021312\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544:2,112,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.050976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020576\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.020576\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544:2,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.051456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.043328\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.043328\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544:2,112,1) -> Float(12544,12544:32,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.044544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.110304\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.044544\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544:2,112,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.4 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.134784\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.020096\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,12544,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,12544,112,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,12544,112,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,1,1792,16) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,1,1792,16) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(200704,1,1792,16) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,112,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(200704,12544,112,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(200704,12544,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(200704,12544,112,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544:2,112,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544:2,112,1) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544:2,112,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,3136,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.03248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.020896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,3136,56,1) -> Float(3136,3136:32,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.032288\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.032224\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.032224\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,3136,56,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.020192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.015936\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.015936\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,3136,56,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.023136\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013312\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013312\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,1792,32) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.03296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020288\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.020288\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,1792,32) -> Float(3136,3136:32,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.032416\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.038688\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.032416\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,1792,32) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015904\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.015904\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,1792,32) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.022368\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.023296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.022368\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.033408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.032192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.02368\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.02368\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.023392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.022432\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.026304\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.022432\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,3136,56,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.0216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014848\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014848\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,3136,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015712\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.02112\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.015712\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,3136,56,1) -> Float(3136,3136:32,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.032512\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,3136,56,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013088\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013088\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136:2,56,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.020544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012448\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.012448\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136:2,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015712\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.023936\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.015712\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136:2,56,1) -> Float(3136,3136:32,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015712\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.032288\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.015712\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136:2,56,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.16 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.039264\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012416\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.012416\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,3136,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,3136,56,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,3136,56,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,1792,32) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,1792,32) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,1792,32) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,56,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,3136,56,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,3136,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(100352,3136,56,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136:2,56,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136:2,56,1) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136:2,56,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,784,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01312\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01312\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,784,28,1) -> Float(1568,784:32,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014592\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.018976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.014592\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,784,28,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014624\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.010016\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.010016\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,784,28,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016032\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1792,64) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016064\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.012768\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1792,64) -> Float(1568,784:32,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.013408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.022624\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.013408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1792,64) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.012192\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1792,64) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016064\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014208\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014208\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.013472\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014592\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.013472\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012224\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014368\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.012224\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015616\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.015904\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.015616\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,784,28,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.015904\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,784,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013184\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,784,28,1) -> Float(1568,784:32,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01136\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.019072\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.01136\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,784,28,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012608\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,784:2,28,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01488\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,784:2,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,784:2,28,1) -> Float(1568,784:32,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.019232\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,784:2,28,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.28 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,784,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,784,28,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,784,28,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1792,64) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1792,64) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1792,64) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1568,784:32,28,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,784,28,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,784,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,784,28,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,784:2,28,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,784:2,28,1) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,784:2,28,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,196,14,1) -> Float(25088,1,1792,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,196,14,1) -> Float(784,196:32,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012416\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.012416\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,196,14,1) -> Half(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.086304\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,196,14,1) -> Half(12544,196:2,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1792,128) -> Float(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01712\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1792,128) -> Float(784,196:32,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014464\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.014048\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1792,128) -> Half(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.010464\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1792,128) -> Half(12544,196:2,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(784,196:32,14,1) -> Float(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017088\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(784,196:32,14,1) -> Float(25088,1,1792,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(784,196:32,14,1) -> Half(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01088\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(784,196:32,14,1) -> Half(12544,196:2,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.010432\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.010432\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,196,14,1) -> Float(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.087136\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,196,14,1) -> Float(25088,1,1792,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,196,14,1) -> Float(784,196:32,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,196,14,1) -> Half(12544,196:2,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,196:2,14,1) -> Float(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,196:2,14,1) -> Float(25088,1,1792,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,196:2,14,1) -> Float(784,196:32,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,196:2,14,1) -> Half(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1439 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.056096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.056096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.055936\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.05664\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.05664\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027072\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.057632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.058336\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.010368\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.010016\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027264\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.024032\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.024032\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011712\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.026848\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.028192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.024992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057664\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.024992\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Shape_437) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.069888\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.056288\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027072\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.055968\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.010048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.026944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006688\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006688\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_437 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.069536\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(32768,256,1) -> Half(32768,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 23) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(32768,256,1) -> Float(32768,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 23) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.00784\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.013728\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013056\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013056\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.102656\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.120416\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.102656\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.103456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.103744\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.118784\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.103744\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.049728\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.012672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011072\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014176\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011072\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.1032\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01984\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01984\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.104864\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.015008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.015008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.050528\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.019008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.019008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.013792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.013792\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.013536\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.050272\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013088\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013088\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.044\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.119104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.044\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.048864\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.05104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014592\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014592\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.044352\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.119904\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.044352\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_445 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.132352\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008544\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011328\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013056\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011328\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.146304\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009952\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009952\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.145952\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012448\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012576\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.012448\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.14656\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0128\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0128\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.146784\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.329024\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014048\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.0128\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014368\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.0128\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.146464\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014336\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014336\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.147392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.015808\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.015808\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.147584\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.010336\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013024\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.010336\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.148704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.147808\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008512\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008512\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.010304\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01472\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.010304\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 38) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.148288\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008512\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008512\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 39) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.333824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013952\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013952\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 39) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.33296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013952\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013952\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 39) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.165696\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 39) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.148864\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.015488\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.015488\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013152\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017728\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.017728\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.14592\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.018048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.012768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.012768\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.02544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.017792\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013056\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.012896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016064\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01456\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.013152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014336\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.013152\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016288\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01584\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01584\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.148128\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011648\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011648\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.021216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011392\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01504\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01184\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.014656\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.01184\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.021152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_457) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.019776\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008544\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017376\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.008544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.0088\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007072\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007072\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.008768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007328\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007328\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007328\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007328\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014784\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.010048\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.00944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_458 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.013344\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.015808\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.015808\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011328\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017696\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.017152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.011232\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.011488\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.007456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.007456\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.014848\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009248\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009888\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.013824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_460 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.012416\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.00768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.032096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016576\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.031616\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016352\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00752\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00752\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.00832\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_461 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.039104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.032096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016448\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.032448\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016384\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.00832\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.016576\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_463 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.038752\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.03136\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.029632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.029632\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.02544\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.024064\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.024064\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.039936\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.017728\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.017728\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.303264\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.028448\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.028448\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.13776\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.02848\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.02848\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.022848\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.033056\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.022848\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027264\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.020672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.138848\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.029536\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.029536\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.0216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.017408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.017408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.134336\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.016672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.016672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.141856\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.033824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.033824\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_466 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.39232\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.016384\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.016384\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 83) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.025216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.024224\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.024224\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 83) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.026976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.020512\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.020512\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009216\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.056416\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027136\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.056704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027168\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.010528\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.026912\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_462 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.069568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.056224\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0576\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.056224\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01184\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.056416\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.05776\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.056416\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.058592\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.027616\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.023936\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.023936\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.02896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_470 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.0248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057696\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.0248\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.057408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.057408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011904\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.056352\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057536\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.056352\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.057024\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00976\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00976\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0104\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.02736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009152\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.024032\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.057568\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.024032\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.011712\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.028192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.44 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.024768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0576\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.024768\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.01344\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.075776\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.076192\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.168736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.076704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.0768\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.168096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00944\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00944\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.013056\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.07648\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.076608\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.077248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009152\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.077248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.077056\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 1002 Time: 0.008704\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_52_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.077248\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 113) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.167808\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 113) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.169824\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.009376\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 113) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.086272\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 113) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 1002 Time: 0.07808\n",
      "[05/24/2022-15:21:35] [TRT] [V] Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:35] [TRT] [V] Fastest Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:35] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,12544,196) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,256:32,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,64,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,256:2,64,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,64,4) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,16,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,3136,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,4) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,3136:2,196,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,1,784,4) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,38416:2,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,128,4) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,6272:32,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,6272,32,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,6272:2,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(50176:32,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176:2,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,1,1) -> Float(640,1,640,640) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023104\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.024992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.023104\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,1,1) -> Float(20,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.82784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.027584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.027584\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,1,1) -> Half(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.030848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02032\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.02032\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,1,1) -> Half(320,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.355456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.015264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.015264\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,640,640) -> Float(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.023904\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.023584\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,640,640) -> Float(20,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.830752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.027584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.027584\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,640,640) -> Half(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.029312\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02416\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.02416\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(640,1,640,640) -> Half(320,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.386304\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.030336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.030336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(20,1:32,1,1) -> Float(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.884\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.029696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.029696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(20,1:32,1,1) -> Float(640,1,640,640) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.021824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.021824\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(20,1:32,1,1) -> Half(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.385696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.030176\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.030176\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(20,1:32,1,1) -> Half(320,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.385632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.034176\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.034176\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(640,1,1,1) -> Float(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.034208\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01904\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.01904\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(640,1,1,1) -> Float(640,1,640,640) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032064\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.027328\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.027328\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(640,1,1,1) -> Float(20,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.435424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.030432\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.030432\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(640,1,1,1) -> Half(320,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.388768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.016416\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.016416\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(320,1:2,1,1) -> Float(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.38832\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.015712\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.015712\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(320,1:2,1,1) -> Float(640,1,640,640) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017504\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031136\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.017504\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(320,1:2,1,1) -> Float(20,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.392256\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.034144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.034144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(320,1:2,1,1) -> Half(640,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 639) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.388992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.015616\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.015616\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02896\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.027392\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.027392\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.028352\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.028352\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.033248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.021952\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.021952\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.03024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.016768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.016768\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.03248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.02624\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02864\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.059296\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.02864\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.022304\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.022304\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.030368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.02976\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.03248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.030304\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.030304\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.028704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.028704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.022752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.030304\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.022752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.029664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.034272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.029664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0344\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.019328\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.019328\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.022848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.028\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.022848\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.020992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.046848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.020992\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.019424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.016544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.016544\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.027744\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01568\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.01568\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023328\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.023328\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02128\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.047232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.02128\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_713) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.034848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.015712\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.015712\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1792,128,1) -> Half(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010208\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007936\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007936\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1792,128,1) -> Half(12544,1792:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1792,14) -> Float(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.019552\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008832\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008832\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1792,14) -> Half(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1792,14) -> Half(12544,1792:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,1792:32,128,1) -> Float(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,1792:32,128,1) -> Half(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011936\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1792,1792:32,128,1) -> Half(12544,1792:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,1792,128,1) -> Float(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007072\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,1792,128,1) -> Half(12544,1792:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,1792:2,128,1) -> Float(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,1792:2,128,1) -> Half(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_730 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.027136\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026496\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.013472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.013472\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010176\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0104\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.024768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.016\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.016\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009536\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009536\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0104\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.024992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01152\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010848\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010464\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011744\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009472\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01376\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.011872\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026496\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00928\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00928\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009952\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009952\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.013856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_714 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.021376\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.021376\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.027104\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.036608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.027104\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.020416\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.010656\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,640,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02464\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.023456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.023456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.025888\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02048\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.02048\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026816\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.045408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.026816\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.020736\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.017824\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(125440,1,15680,196) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.023808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.023808\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026048\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.02336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.024128\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.024128\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.023584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.017632\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4480,640:32,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.026656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.023808\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01088\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.020576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.01088\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018016\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02192\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.018016\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.035968\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.016096\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(125440,640,80,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.021664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.021664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017568\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.023264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.017568\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.024096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.018368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01712\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.036256\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.01712\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(62720,640:2,80,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_715 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.018144\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1792,128,1) -> Half(12544,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_735 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007712\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,1792,128,1) -> Half(7168,1792:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_735 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00944\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,1792,128,1) -> Float(12544,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_735 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008384\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,1792,128,1) -> Half(7168,1792:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_735 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005984\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005984\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(7168,1792:2,128,1) -> Float(12544,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_735 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(7168,1792:2,128,1) -> Half(12544,1792,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_735 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.025664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,896,128,1) -> Float(6272,1,896,7) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,896,128,1) -> Float(896,896:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015936\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.013216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.013216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,896,128,1) -> Half(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,896,128,1) -> Half(3584,896:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,896,7) -> Float(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,896,7) -> Float(896,896:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.013376\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.013376\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,896,7) -> Half(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,896,7) -> Half(3584,896:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00944\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(896,896:32,128,1) -> Float(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(896,896:32,128,1) -> Float(6272,1,896,7) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(896,896:32,128,1) -> Half(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(896,896:32,128,1) -> Half(3584,896:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,896,128,1) -> Float(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,896,128,1) -> Float(6272,1,896,7) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00944\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,896,128,1) -> Float(896,896:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.013088\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,896,128,1) -> Half(3584,896:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(3584,896:2,128,1) -> Float(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(3584,896:2,128,1) -> Float(6272,1,896,7) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(3584,896:2,128,1) -> Float(896,896:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.013344\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(3584,896:2,128,1) -> Half(6272,896,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_740 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.014624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272:32,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272:32,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011392\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272:2,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272:2,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_746 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.021536\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16384,128,1) -> Half(16384,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 733) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(16384,128,1) -> Float(16384,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 733) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008512\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,128,1) -> Float(6272:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.018976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,128,1) -> Half(6272:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6272:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.018848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6272:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272:32,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0064\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0064\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272:32,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272:32,128,1) -> Half(6272:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,128,1) -> Float(6272:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.018976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.010752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,128,1) -> Half(6272:2,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272:2,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272:2,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272:2,128,1) -> Float(6272:32,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_748 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.019008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.011168\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272:2,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02304\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.048448\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023296\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.04624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023296\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008512\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.024128\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 748) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02352\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 749) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.045824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 749) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.047776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(128,1,128,128) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 749) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.025408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 749) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.023712\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_762 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.014624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,3136,196,1) -> Half(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00944\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1568,8) -> Float(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.031904\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,1568,8) -> Half(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009024\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Float(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032128\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,196,1) -> Half(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016384\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,3136,196,1) -> Float(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010528\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136:2,196,1) -> Float(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136:2,196,1) -> Half(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_763 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.039872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,9604,196,1) -> Float(76832,1,1568,8) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.034176\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.017312\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.017312\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,9604,196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,9604,196,1) -> Half(38416,9604:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015552\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.011264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.011264\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,1,1568,8) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.081376\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.01664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,1,1568,8) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.039616\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.016928\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.016928\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,1,1568,8) -> Half(38416,9604:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041952\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.019232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.019232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,9604,196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.012448\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.012448\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,9604,196,1) -> Float(76832,1,1568,8) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.039712\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.017472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.017472\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,9604,196,1) -> Half(38416,9604:2,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015328\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(38416,9604:2,196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.039328\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(38416,9604:2,196,1) -> Float(76832,1,1568,8) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.040768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01968\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.01968\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(38416,9604:2,196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_766 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.105504\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010688\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010688\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,9604,196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,1,1568,8) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,1,1568,8) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,9604,196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(38416,9604:2,196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(38416,9604:2,196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 778) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.012704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.012704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 778) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(76832,9604,196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(76832,9604,196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(100352,12544,64,1) -> Half(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01904\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.016192\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.016192\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,512,8) -> Float(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.10272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.02032\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.02032\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(100352,1,512,8) -> Half(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.049888\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.020576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.020576\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,64,1) -> Float(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.10464\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,12544:32,64,1) -> Half(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.050592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.023392\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.023392\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(100352,12544,64,1) -> Float(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.020608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.015008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.015008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,12544:2,64,1) -> Float(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.048736\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.012544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.012544\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(50176,12544:2,64,1) -> Half(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_716 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.13552\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.012512\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.012512\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,3136,64,1) -> Float(25088,1,512,8) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.014688\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,3136,64,1) -> Float(3136,3136:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.031808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.031776\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,3136,64,1) -> Half(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00944\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,3136,64,1) -> Half(12544,3136:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,512,8) -> Float(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032512\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008832\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008832\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,512,8) -> Float(3136,3136:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032352\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.03232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.03232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,512,8) -> Half(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009056\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009056\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,512,8) -> Half(12544,3136:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009728\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,64,1) -> Float(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.033344\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,64,1) -> Float(25088,1,512,8) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032064\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009888\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009888\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,64,1) -> Half(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,64,1) -> Half(12544,3136:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01728\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010528\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010528\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,3136,64,1) -> Float(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,3136,64,1) -> Float(25088,1,512,8) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,3136,64,1) -> Float(3136,3136:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.032032\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.015168\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,3136,64,1) -> Half(12544,3136:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136:2,64,1) -> Float(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136:2,64,1) -> Float(25088,1,512,8) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017056\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136:2,64,1) -> Float(3136,3136:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.032032\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,3136:2,64,1) -> Half(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_770 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.039232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.055296\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.057408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.055296\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.055552\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.057248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.057248\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02736\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0088\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0088\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.056096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.05728\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.027168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010432\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007104\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007104\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.027808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.024224\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.057472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.024224\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006848\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006848\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.026976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.02784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.024832\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.057632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.024832\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.144 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.06976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008352\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.008352\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.076256\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.008576\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.076704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.16704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009888\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009888\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.076672\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.07648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.008544\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.077248\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.077088\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0088\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.0088\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_291_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.077536\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007072\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.088256\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.090176\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041344\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0416\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.088256\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013472\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041568\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041568\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00768\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.042016\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.046144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.04208\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041792\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.042272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 809) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.041792\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032128\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.031808\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032288\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.031872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.03184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.03184\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016352\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032288\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.031872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016384\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00832\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.015072\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.017024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_786) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.038144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032544\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016576\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.03184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016352\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00832\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.038368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(131072,512,1) -> Half(131072,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 815) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010048\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00832\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00832\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(131072,512,1) -> Float(131072,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 815) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011616\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 832) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.168288\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00944\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00944\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 832) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.17008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 832) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.086144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 832) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.078176\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031808\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.031808\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.031648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.03184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.031648\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007264\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.031776\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.01488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_786 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015328\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.032032\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.015328\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_801 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_801 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.032288\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_801 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0168\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_801 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016256\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009216\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008992\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012896\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009056\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009056\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01392\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.01632\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.01392\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010528\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00912\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013312\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016064\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009696\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016288\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00976\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012224\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010528\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010528\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010112\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01312\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010048\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.014528\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.010048\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012416\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.013312\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.014912\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.009856\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_821) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.014656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006784\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007872\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007872\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008512\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008416\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008416\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.014784\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.0064\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.0064\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00752\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00752\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012864\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_822 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007264\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007264\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0152\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010304\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.010304\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.014336\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.011072\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.011072\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010624\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.016064\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.015008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.008768\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.007424\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.010464\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.00704\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.012928\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:36] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:36] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:36] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.010528\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_824 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012224\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015872\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015872\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006656\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007872\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_827 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014624\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.013312\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.026976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007872\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007872\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015264\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015904\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008512\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008512\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015264\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008096\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01504\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_830 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.03056\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 931) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 931) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01136\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_826 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.019008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.01824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018176\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011584\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010688\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.010688\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009088\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_834 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011136\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.011136\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,1,3136,49) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,512:32,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,64,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12800,512:2,64,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,128,8) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,16,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,784,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6272,1,392,8) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3136,784:2,49,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,1,392,8) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(9604,2401:2,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,256,8) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1568,1568:32,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1568,32,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,1568:2,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(25088:32,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088:2,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(512,1,512,512) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544:32,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544:2,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(1280,1,1280,1280) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012896\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.015008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.012896\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(40,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.417984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1,1) -> Half(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.011456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.011456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1,1) -> Half(640,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.180512\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014336\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.014208\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(40,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.414112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Half(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Half(640,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.182048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.410784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016256\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1280,1280) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016928\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.014976\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Half(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.182112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Half(640,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.18208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(1280,1,1,1) -> Float(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.011008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.011008\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(1280,1,1,1) -> Float(1280,1,1280,1280) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.015136\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.014752\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(1280,1,1,1) -> Float(40,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.20512\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016448\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016448\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(1280,1,1,1) -> Half(640,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.183584\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.010016\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.010016\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(640,1:2,1,1) -> Float(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.183392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(640,1:2,1,1) -> Float(1280,1,1280,1280) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016928\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(640,1:2,1,1) -> Float(40,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.184896\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018368\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.018368\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(640,1:2,1,1) -> Half(1280,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1503) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.183776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.019776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01504\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01504\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016224\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.027232\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.016224\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.011456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.011456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.020416\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01008\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.019136\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.031904\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.015456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015296\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014816\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014816\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.02048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016672\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016672\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01952\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016384\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016384\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.019712\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01696\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01696\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01664\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.019744\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015936\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01104\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01104\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021056\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.015136\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.015136\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014176\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.027392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.014176\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.009504\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.009504\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021056\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.016896\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.016896\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.027488\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.014144\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1077) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1792,256,1) -> Half(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1792,256,1) -> Half(7168,1792:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,1792,7) -> Float(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,1792,7) -> Half(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,1792,7) -> Half(7168,1792:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1792,1792:32,256,1) -> Float(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018176\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1792,1792:32,256,1) -> Half(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1792,1792:32,256,1) -> Half(7168,1792:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012192\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1792,256,1) -> Float(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,1792,256,1) -> Half(7168,1792:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009088\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(7168,1792:2,256,1) -> Float(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(7168,1792:2,256,1) -> Half(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1094 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.025472\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017248\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011328\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016032\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010816\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008352\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008352\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007712\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007712\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0104\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007776\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008928\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011328\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007136\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007136\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010432\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010464\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1078 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012128\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.013216\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.013216\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014464\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.014464\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012672\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1280,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016384\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.012768\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.026656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.015616\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012864\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(62720,1,3920,49) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016896\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01424\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.019488\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01328\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014368\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.01328\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(2560,1280:32,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01584\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01584\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012672\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01312\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01312\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.023168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.012\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(62720,1280,80,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.013344\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.013344\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01872\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014656\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.023264\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(32000,1280:2,80,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1079 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016544\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01328\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01328\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(7168,1792,256,1) -> Half(7168,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1099 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(7168,1792,256,1) -> Half(3584,1792:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1099 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00544\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(7168,1792,256,1) -> Float(7168,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1099 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(7168,1792,256,1) -> Half(3584,1792:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1099 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011936\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3584,1792:2,256,1) -> Float(7168,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1099 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(3584,1792:2,256,1) -> Half(7168,1792,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Slice_1099 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.025344\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1024,256,1) -> Float(4096,1,1024,4) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1024,256,1) -> Float(1024,1024:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017536\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1024,256,1) -> Half(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1024,256,1) -> Half(2048,1024:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1,1024,4) -> Float(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017504\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1,1024,4) -> Float(1024,1024:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.013984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.013984\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1,1024,4) -> Half(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1,1024,4) -> Half(2048,1024:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,256,1) -> Float(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0176\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,256,1) -> Float(4096,1,1024,4) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017728\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,256,1) -> Half(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,256,1) -> Half(2048,1024:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,1024,256,1) -> Float(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,1024,256,1) -> Float(4096,1,1024,4) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,1024,256,1) -> Float(1024,1024:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,1024,256,1) -> Half(2048,1024:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012128\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(2048,1024:2,256,1) -> Float(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(2048,1024:2,256,1) -> Float(4096,1,1024,4) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010464\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(2048,1024:2,256,1) -> Float(1024,1024:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.009984\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(2048,1024:2,256,1) -> Half(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Reshape_1104 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016736\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0176\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096:32,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017536\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096:32,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096:2,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096:2,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1110 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016512\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(65536,256,1) -> Half(65536,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1597) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(65536,256,1) -> Float(65536,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1597) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,256,1) -> Float(4096:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,256,1) -> Half(4096:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4096:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017728\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(4096:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096:32,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017728\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096:32,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096:32,256,1) -> Half(4096:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,256,1) -> Float(4096:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.013888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,256,1) -> Half(4096:2,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012128\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096:2,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096:2,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010432\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096:2,256,1) -> Float(4096:32,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1112 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010016\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.010016\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096:2,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0344\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018016\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008448\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1612) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018432\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1613) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.03392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1613) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.033952\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,1,256,256) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1613) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01952\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(256,1,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1613) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,256,16,1) -> Half(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1,256,16) -> Float(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(4096,1,256,16) -> Half(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009312\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(4096,256,16,1) -> Float(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(2048,256:2,16,1) -> Float(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(2048,256:2,16,1) -> Half(4096,256,16,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1126 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011904\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,784,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,16) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,16) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(784,784:32,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007488\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,784,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784:2,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784:2,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1127 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,784,49,1) -> Float(12544,1,784,16) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1130 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,784,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,784,49,1) -> Half(6272,784:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1130 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,16) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,16) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,16) -> Half(6272,784:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1130 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,784,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,784,49,1) -> Float(12544,1,784,16) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1130 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,784,49,1) -> Half(6272,784:2,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1130 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011712\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784:2,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784:2,49,1) -> Float(12544,1,784,16) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1130 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784:2,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,784,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,16) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,1,784,16) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,784,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784:2,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6272,784:2,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1642) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1642) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12544,784,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12544,784,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(50176,3136,64,1) -> Half(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012672\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00976\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00976\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1024,16) -> Float(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.032032\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012704\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.012704\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(50176,1,1024,16) -> Half(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012896\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.012896\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,64,1) -> Float(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.032448\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.01408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.01408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(3136,3136:32,64,1) -> Half(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014144\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(50176,3136,64,1) -> Float(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014528\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0096\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,3136:2,64,1) -> Float(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01744\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(25088,3136:2,64,1) -> Half(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1080 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.038944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,64,1) -> Float(16384,1,1024,16) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,64,1) -> Float(1024,1024:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017536\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0144\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,64,1) -> Half(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,64,1) -> Half(8192,1024:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010528\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1,1024,16) -> Float(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1,1024,16) -> Float(1024,1024:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017728\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.014784\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1,1024,16) -> Half(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010464\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00768\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1,1024,16) -> Half(8192,1024:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,64,1) -> Float(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018016\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008192\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008192\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,64,1) -> Float(16384,1,1024,16) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,64,1) -> Half(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01088\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008128\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1024:32,64,1) -> Half(8192,1024:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,64,1) -> Float(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,64,1) -> Float(16384,1,1024,16) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010464\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007808\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007808\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,64,1) -> Float(1024,1024:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014592\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,64,1) -> Half(8192,1024:2,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(8192,1024:2,64,1) -> Float(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011104\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(8192,1024:2,64,1) -> Float(16384,1,1024,16) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(8192,1024:2,64,1) -> Float(1024,1024:32,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(8192,1024:2,64,1) -> Half(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1134 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016736\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008928\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.039328\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.039552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.039328\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01024\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.040416\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.040416\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.039616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.039616\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021056\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.03888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008224\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008224\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.038944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021056\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021248\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.039744\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.018752\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011712\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.020832\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021728\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.019328\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.039584\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.019328\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.268 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.04816\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384,1024,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(16384:32,1024,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384,1024,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(16384:2,1024,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1,1,1) -> Float(1024,1,1024,1024) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1,1,1) -> Half(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1,1,1) -> Half(512,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.052032\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1,1024,1024) -> Float(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1,1024,1024) -> Half(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007648\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1024,1,1024,1024) -> Half(512,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.052224\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Float(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.112288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008032\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008032\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Float(1024,1,1024,1024) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Half(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.052544\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008032\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008032\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Half(512,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.052256\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(1024,1,1,1) -> Float(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(1024,1,1,1) -> Float(1024,1,1024,1024) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.00784\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(1024,1,1,1) -> Half(512,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.052672\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1:2,1,1) -> Float(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.052512\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1:2,1,1) -> Float(1024,1,1024,1024) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(512,1:2,1,1) -> Half(1024,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_581_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.052672\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.045952\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023232\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023232\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.045984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0232\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.04576\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012768\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0232\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.025504\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1673) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.023424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.010656\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011936\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011744\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.010912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.018784\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.010912\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::MatMul_1150) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021888\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.018176\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01152\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.017984\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007616\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011552\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.021504\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(294912,768,1) -> Half(294912,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1679) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015488\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.012832\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(294912,768,1) -> Float(294912,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1679) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.0168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.012192\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.012192\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008704\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.031584\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.031264\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.031264\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.031584\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.031808\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.03136\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.03136\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008928\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.031776\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.03184\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007712\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007712\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016736\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.014816\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.031328\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.014816\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.011936\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.016512\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.01696\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.015456\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.031296\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 1002 Time: 0.015456\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Flatten_1152 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.038304\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:37] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.04064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008032\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.008064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.04064\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.08496\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:37] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:37] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:37] [TRT] [V] Tactic: 1002 Time: 0.012768\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.04064\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.040832\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00784\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.041152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.040896\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.0056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.0056\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1695) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.040928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1696) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.085408\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1696) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.086496\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1696) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.045568\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1696) [Scale]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.041696\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.018464\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.01856\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.018208\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.010912\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.018528\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.010912\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011936\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1150 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.010912\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.018752\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.010912\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1165 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1165 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01824\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1165 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Shape_1165 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011744\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008704\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.01216\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.01216\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008256\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015584\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.01248\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.01248\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015808\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015584\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009568\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.012416\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.008928\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011712\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.0056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.0056\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.010048\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.012448\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Split_1185) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01456\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008256\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015424\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00848\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008256\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01472\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009312\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006208\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006208\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.014944\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00624\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00624\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00624\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00624\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008896\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009536\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00912\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011296\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009536\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009344\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1186 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011488\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008288\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015584\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007232\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015584\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.014976\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015616\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015168\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007424\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00896\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011328\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1188 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.0144\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01584\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01584\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.014592\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1189 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011968\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1194 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1194 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005056\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1194 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1194 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009632\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1194 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011744\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005056\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Add_1194 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009824\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005952\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1795) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007264\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1795) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007264\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007232\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01584\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006624\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00768\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::MatMul_1190 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.013088\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006368\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015744\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009184\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.010272\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009408\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00656\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.015616\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.0064\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.0064\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009376\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.010112\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.008736\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.011744\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005248\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.0096\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Transpose_1198 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 1002 Time: 0.00896\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,1,1024,16) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,768:32,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,64,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,768:2,64,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(256,256:32,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,1,192,12) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1536,256:2,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,1,384,12) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(512,512:32,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,512,32,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(3072,512:2,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12288:32,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(12288:2,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(768,1,768,768) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(768,1,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(12,1:32,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(6144:32,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(6144:2,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1) -> Half(384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.384 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1) -> Float(384,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(input.384 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007808\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 2349) [Shuffle]_output) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 2349) [Shuffle]_output) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 2349) [Shuffle]_output) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 2349) [Shuffle]_output) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009312\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 2349) [Shuffle]_output) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009152\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 2349) [Shuffle]_output) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.0072\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009312\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.0072\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009088\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005504\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005504\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009248\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005984\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005984\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2349) [Shuffle]_output -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.00928\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(384,1,384,384) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(384,1,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1,1) -> Float(1000,1,1000,1000) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1,1) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1,1) -> Half(500,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009792\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1000,1000) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007168\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1000,1000) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007392\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1000,1000) -> Half(500,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.010016\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1000,1,1,1) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007872\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1000,1,1,1) -> Float(1000,1,1000,1000) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.00576\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1000,1,1,1) -> Half(500,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.01008\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(500,1:2,1,1) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.010016\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(500,1:2,1,1) -> Float(1000,1,1000,1000) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.009056\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005984\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005984\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(500,1:2,1,1) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 2371) [ElementWise]_out_tensor -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.010016\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005024\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1,1) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1000,1000) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1,1000,1000) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1000,1,1,1) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(500,1:2,1,1) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(500,1:2,1,1) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Float(1000,1) -> Half(1000,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Div_1427 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.006176\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1000,1) -> Float(1000,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(onnx::Div_1427 -> <out>) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing reformatting costs\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning Reformat: Half(1000,1) -> Float(1000,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> output) (Reformat)\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 1002 Time: 0.007648\n",
      "[05/24/2022-15:21:38] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Float(32768,256,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Half(32768,256,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Float(16384,128,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Half(16384,128,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Float(131072,512,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Half(131072,512,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Float(65536,256,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Half(65536,256,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Float(294912,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination:  -> Half(294912,768,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:38] [TRT] [V] *************** Autotuning format combination: Float(150528,50176,224,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Conv_0 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:21:38] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Conv_0 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:38] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:38] [TRT] [V] --------------- Timing Runner: Conv_0 (CudnnConvolution)\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 0 Time: 0.080608\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 1 Time: 0.072384\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 2 Time: 0.094816\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 5 Time: 1.62035\n",
      "[05/24/2022-15:21:39] [TRT] [V] Fastest Tactic: 1 Time: 0.072384\n",
      "[05/24/2022-15:21:39] [TRT] [V] --------------- Timing Runner: Conv_0 (CaskConvolution)\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 1062367460111450758 Time: 0.042944\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 1754984623894446479 Time: 0.04128\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 3611739942397549984 Time: 0.10912\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 4337000649858996379 Time: 0.058432\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 4501471010995462441 Time: 0.103872\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 5137655947464784826 Time: 0.057216\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 5288347012147084929 Time: 0.107616\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 6645123197870846056 Time: 0.057824\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 7144526460361122478 Time: 0.038944\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -9137461792520977713 Time: 0.104256\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -8262349710178828730 Time: 0.108032\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -8133971918129952780 Time: 0.055936\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -6092040395344634144 Time: 0.043328\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -4787320710726427159 Time: 0.040352\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -3456450830548107839 Time: 0.04144\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -1218658103698133241 Time: 0.056576\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -836875257600482091 Time: 0.055392\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -410470605513481746 Time: 0.101856\n",
      "[05/24/2022-15:21:39] [TRT] [V] Fastest Tactic: 7144526460361122478 Time: 0.038944\n",
      "[05/24/2022-15:21:39] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7144526460361122478\n",
      "[05/24/2022-15:21:39] [TRT] [V] *************** Autotuning format combination: Float(150528,1,672,3) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:39] [TRT] [V] --------------- Timing Runner: Conv_0 (CaskConvolution)\n",
      "[05/24/2022-15:21:39] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:39] [TRT] [V] *************** Autotuning format combination: Half(150528,50176,224,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:39] [TRT] [V] --------------- Timing Runner: Conv_0 (CudnnConvolution)\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 0 Time: 0.079808\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 1 Time: 0.064544\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 2 Time: 0.092832\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 5 Time: 1.59693\n",
      "[05/24/2022-15:21:39] [TRT] [V] Fastest Tactic: 1 Time: 0.064544\n",
      "[05/24/2022-15:21:39] [TRT] [V] --------------- Timing Runner: Conv_0 (CaskConvolution)\n",
      "[05/24/2022-15:21:39] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:39] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[05/24/2022-15:21:39] [TRT] [V] *************** Autotuning format combination: Half(100352,50176:2,224,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:39] [TRT] [V] --------------- Timing Runner: Conv_0 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:39] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:39] [TRT] [V] --------------- Timing Runner: Conv_0 (CaskConvolution)\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 3564772625446233998 Time: 0.031808\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 3650389455493082349 Time: 0.031968\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 5319956359050645452 Time: 0.030912\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 7205456024582378848 Time: 0.04784\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -6490690591794140522 Time: 0.044288\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -4686027666808657977 Time: 0.07712\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -4212163711445252890 Time: 0.075168\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -3898373634979201110 Time: 0.076224\n",
      "[05/24/2022-15:21:39] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: -2409163523992614473 Time: 0.047232\n",
      "[05/24/2022-15:21:39] [TRT] [V] Fastest Tactic: 5319956359050645452 Time: 0.030912\n",
      "[05/24/2022-15:21:39] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:39] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:39] [TRT] [V] *************** Autotuning format combination: Float(200704,12544,112,1) -> Float(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:39] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWiseV2)\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 0 Time: 0.025376\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 1 Time: 0.018496\n",
      "[05/24/2022-15:21:39] [TRT] [V] Tactic: 2 Time: 0.017376\n",
      "[05/24/2022-15:21:40] [TRT] [V] Tactic: 3 Time: 0.01808\n",
      "[05/24/2022-15:21:40] [TRT] [V] Tactic: 4 Time: 0.016768\n",
      "[05/24/2022-15:21:40] [TRT] [V] Tactic: 5 Time: 0.015872\n",
      "[05/24/2022-15:21:40] [TRT] [V] Tactic: 6 Time: 0.018016\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 7 Time: 0.016384\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 8 Time: 0.015968\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 9 Time: 0.014624\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 28 Time: 0.0224\n",
      "[05/24/2022-15:21:41] [TRT] [V] Fastest Tactic: 9 Time: 0.014624\n",
      "[05/24/2022-15:21:41] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWise)\n",
      "[05/24/2022-15:21:41] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:41] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9\n",
      "[05/24/2022-15:21:41] [TRT] [V] *************** Autotuning format combination: Float(200704,1,1792,16) -> Float(200704,1,1792,16) ***************\n",
      "[05/24/2022-15:21:41] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWiseV2)\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 0 Time: 0.023456\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 1 Time: 0.018304\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 2 Time: 0.017184\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 3 Time: 0.017728\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 4 Time: 0.016288\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 5 Time: 0.015744\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 6 Time: 0.017632\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 7 Time: 0.016608\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 8 Time: 0.015584\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 9 Time: 0.015552\n",
      "[05/24/2022-15:21:41] [TRT] [V] Tactic: 28 Time: 0.022176\n",
      "[05/24/2022-15:21:41] [TRT] [V] Fastest Tactic: 9 Time: 0.015552\n",
      "[05/24/2022-15:21:41] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWise)\n",
      "[05/24/2022-15:21:41] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:41] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9\n",
      "[05/24/2022-15:21:41] [TRT] [V] *************** Autotuning format combination: Float(12544,12544:32,112,1) -> Float(12544,12544:32,112,1) ***************\n",
      "[05/24/2022-15:21:41] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWiseV2)\n",
      "[05/24/2022-15:21:42] [TRT] [V] Tactic: 24 Time: 0.029632\n",
      "[05/24/2022-15:21:42] [TRT] [V] Tactic: 25 Time: 0.029696\n",
      "[05/24/2022-15:21:42] [TRT] [V] Tactic: 26 Time: 0.03024\n",
      "[05/24/2022-15:21:42] [TRT] [V] Tactic: 27 Time: 0.030528\n",
      "[05/24/2022-15:21:43] [TRT] [V] Tactic: 31 Time: 0.029376\n",
      "[05/24/2022-15:21:43] [TRT] [V] Fastest Tactic: 31 Time: 0.029376\n",
      "[05/24/2022-15:21:43] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWise)\n",
      "[05/24/2022-15:21:43] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:43] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31\n",
      "[05/24/2022-15:21:43] [TRT] [V] *************** Autotuning format combination: Half(200704,12544,112,1) -> Half(200704,12544,112,1) ***************\n",
      "[05/24/2022-15:21:43] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWiseV2)\n",
      "[05/24/2022-15:21:43] [TRT] [V] Tactic: 0 Time: 0.024704\n",
      "[05/24/2022-15:21:43] [TRT] [V] Tactic: 1 Time: 0.017568\n",
      "[05/24/2022-15:21:43] [TRT] [V] Tactic: 2 Time: 0.016704\n",
      "[05/24/2022-15:21:44] [TRT] [V] Tactic: 3 Time: 0.013888\n",
      "[05/24/2022-15:21:44] [TRT] [V] Tactic: 4 Time: 0.01344\n",
      "[05/24/2022-15:21:44] [TRT] [V] Tactic: 5 Time: 0.012832\n",
      "[05/24/2022-15:21:44] [TRT] [V] Tactic: 6 Time: 0.012192\n",
      "[05/24/2022-15:21:45] [TRT] [V] Tactic: 7 Time: 0.010592\n",
      "[05/24/2022-15:21:45] [TRT] [V] Tactic: 8 Time: 0.01056\n",
      "[05/24/2022-15:21:45] [TRT] [V] Tactic: 9 Time: 0.01104\n",
      "[05/24/2022-15:21:45] [TRT] [V] Tactic: 28 Time: 0.021888\n",
      "[05/24/2022-15:21:45] [TRT] [V] Fastest Tactic: 8 Time: 0.01056\n",
      "[05/24/2022-15:21:45] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWise)\n",
      "[05/24/2022-15:21:45] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:45] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:45] [TRT] [V] *************** Autotuning format combination: Half(100352,12544:2,112,1) -> Half(100352,12544:2,112,1) ***************\n",
      "[05/24/2022-15:21:45] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWiseV2)\n",
      "[05/24/2022-15:21:46] [TRT] [V] Tactic: 0 Time: 0.015584\n",
      "[05/24/2022-15:21:46] [TRT] [V] Tactic: 1 Time: 0.011936\n",
      "[05/24/2022-15:21:46] [TRT] [V] Tactic: 2 Time: 0.012192\n",
      "[05/24/2022-15:21:46] [TRT] [V] Tactic: 3 Time: 0.010016\n",
      "[05/24/2022-15:21:47] [TRT] [V] Tactic: 4 Time: 0.010656\n",
      "[05/24/2022-15:21:47] [TRT] [V] Tactic: 5 Time: 0.010272\n",
      "[05/24/2022-15:21:47] [TRT] [V] Tactic: 6 Time: 0.009408\n",
      "[05/24/2022-15:21:47] [TRT] [V] Tactic: 7 Time: 0.009984\n",
      "[05/24/2022-15:21:48] [TRT] [V] Tactic: 8 Time: 0.009344\n",
      "[05/24/2022-15:21:48] [TRT] [V] Tactic: 9 Time: 0.00944\n",
      "[05/24/2022-15:21:48] [TRT] [V] Tactic: 10 Time: 0.024864\n",
      "[05/24/2022-15:21:48] [TRT] [V] Tactic: 11 Time: 0.017952\n",
      "[05/24/2022-15:21:49] [TRT] [V] Tactic: 12 Time: 0.017088\n",
      "[05/24/2022-15:21:49] [TRT] [V] Tactic: 13 Time: 0.013952\n",
      "[05/24/2022-15:21:49] [TRT] [V] Tactic: 14 Time: 0.013024\n",
      "[05/24/2022-15:21:49] [TRT] [V] Tactic: 15 Time: 0.013056\n",
      "[05/24/2022-15:21:50] [TRT] [V] Tactic: 16 Time: 0.011936\n",
      "[05/24/2022-15:21:50] [TRT] [V] Tactic: 17 Time: 0.011744\n",
      "[05/24/2022-15:21:50] [TRT] [V] Tactic: 18 Time: 0.010176\n",
      "[05/24/2022-15:21:50] [TRT] [V] Tactic: 19 Time: 0.011072\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 28 Time: 0.014976\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 29 Time: 0.024384\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: 8 Time: 0.009344\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_1), Mul_2) (PointWise)\n",
      "[05/24/2022-15:21:51] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:51] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:51] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:51] [TRT] [V] *************** Autotuning format combination: Float(200704,12544,112,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (CudnnConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 0 Time: 0.06704\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 1 Time: 0.059968\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 2 Time: 0.116832\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 5 Time: 0.507872\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: 1 Time: 0.059968\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (CaskConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 1062367460111450758 Time: 0.042784\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 1754984623894446479 Time: 0.044416\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 3611739942397549984 Time: 0.089504\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 4337000649858996379 Time: 0.054048\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 4501471010995462441 Time: 0.086592\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 5137655947464784826 Time: 0.051744\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 5288347012147084929 Time: 0.08688\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 6645123197870846056 Time: 0.053024\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 7144526460361122478 Time: 0.043072\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -9137461792520977713 Time: 0.087936\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -8262349710178828730 Time: 0.087872\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -8133971918129952780 Time: 0.058976\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -6092040395344634144 Time: 0.045088\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -4787320710726427159 Time: 0.043904\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -3456450830548107839 Time: 0.038112\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -1218658103698133241 Time: 0.057952\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -836875257600482091 Time: 0.05728\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -410470605513481746 Time: 0.086016\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: -3456450830548107839 Time: 0.038112\n",
      "[05/24/2022-15:21:51] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3456450830548107839\n",
      "[05/24/2022-15:21:51] [TRT] [V] *************** Autotuning format combination: Float(200704,1,1792,16) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (CaskConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -9153228964338181824 Time: 0.053664\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -7394439838318485025 Time: 0.047744\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: -7394439838318485025 Time: 0.047744\n",
      "[05/24/2022-15:21:51] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[05/24/2022-15:21:51] [TRT] [V] *************** Autotuning format combination: Half(200704,12544,112,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (CudnnConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 0 Time: 0.068512\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 1 Time: 0.052224\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 2 Time: 0.105792\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 5 Time: 0.489152\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: 1 Time: 0.052224\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (CaskConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:51] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[05/24/2022-15:21:51] [TRT] [V] *************** Autotuning format combination: Half(100352,12544:2,112,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: Conv_3 (CaskConvolution)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 3564772625446233998 Time: 0.023584\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 3650389455493082349 Time: 0.024384\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 5319956359050645452 Time: 0.0224\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 7205456024582378848 Time: 0.031296\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -6490690591794140522 Time: 0.031968\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -4686027666808657977 Time: 0.049376\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -4212163711445252890 Time: 0.048\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -3898373634979201110 Time: 0.04848\n",
      "[05/24/2022-15:21:51] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: -2409163523992614473 Time: 0.03056\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: 5319956359050645452 Time: 0.0224\n",
      "[05/24/2022-15:21:51] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:51] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:51] [TRT] [V] *************** Autotuning format combination: Float(100352,3136,56,1) -> Float(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWiseV2)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 0 Time: 0.013824\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 1 Time: 0.011104\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 2 Time: 0.010624\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 3 Time: 0.009376\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 4 Time: 0.008576\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 5 Time: 0.008704\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 6 Time: 0.00848\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 7 Time: 0.007808\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 8 Time: 0.007456\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 9 Time: 0.007872\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 28 Time: 0.013248\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: 8 Time: 0.007456\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWise)\n",
      "[05/24/2022-15:21:51] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:51] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:51] [TRT] [V] *************** Autotuning format combination: Float(100352,1,1792,32) -> Float(100352,1,1792,32) ***************\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWiseV2)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 0 Time: 0.01392\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 1 Time: 0.011072\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 2 Time: 0.01088\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 3 Time: 0.009312\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 4 Time: 0.00864\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 5 Time: 0.008864\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 6 Time: 0.00848\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 7 Time: 0.007872\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 8 Time: 0.007584\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 9 Time: 0.00784\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 28 Time: 0.013248\n",
      "[05/24/2022-15:21:51] [TRT] [V] Fastest Tactic: 8 Time: 0.007584\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWise)\n",
      "[05/24/2022-15:21:51] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:51] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:51] [TRT] [V] *************** Autotuning format combination: Float(3136,3136:32,56,1) -> Float(3136,3136:32,56,1) ***************\n",
      "[05/24/2022-15:21:51] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWiseV2)\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 24 Time: 0.007808\n",
      "[05/24/2022-15:21:51] [TRT] [V] Tactic: 25 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 26 Time: 0.00752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 27 Time: 0.007872\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 31 Time: 0.007648\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 25 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(100352,3136,56,1) -> Half(100352,3136,56,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWiseV2)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.013856\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.011232\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.010784\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3 Time: 0.009536\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4 Time: 0.00864\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.008576\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6 Time: 0.008736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7 Time: 0.00784\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 8 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 9 Time: 0.007968\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 28 Time: 0.01328\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 8 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,3136:2,56,1) -> Half(50176,3136:2,56,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWiseV2)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.008448\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.008416\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3 Time: 0.007616\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4 Time: 0.007776\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.007584\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6 Time: 0.007584\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7 Time: 0.007584\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 8 Time: 0.007168\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 9 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 10 Time: 0.014752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 11 Time: 0.011488\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 12 Time: 0.01104\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 13 Time: 0.009536\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 14 Time: 0.008832\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 15 Time: 0.008992\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 16 Time: 0.008448\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 17 Time: 0.008032\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 18 Time: 0.007552\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 19 Time: 0.008064\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 28 Time: 0.009952\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 29 Time: 0.014336\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 8 Time: 0.007168\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_4), Mul_5) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(100352,3136,56,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (CudnnConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.06768\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.054624\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.147264\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.306144\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 1 Time: 0.054624\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1062367460111450758 Time: 0.053312\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1754984623894446479 Time: 0.050368\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3611739942397549984 Time: 0.083296\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4337000649858996379 Time: 0.0576\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4501471010995462441 Time: 0.083872\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5137655947464784826 Time: 0.051808\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5288347012147084929 Time: 0.08256\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6645123197870846056 Time: 0.05632\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7144526460361122478 Time: 0.048544\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -9137461792520977713 Time: 0.086112\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -8262349710178828730 Time: 0.083264\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -8133971918129952780 Time: 0.067776\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -6092040395344634144 Time: 0.058944\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -4787320710726427159 Time: 0.049728\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -3456450830548107839 Time: 0.04256\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -1218658103698133241 Time: 0.066688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -836875257600482091 Time: 0.064192\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -410470605513481746 Time: 0.082624\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: -3456450830548107839 Time: 0.04256\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3456450830548107839\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(100352,1,1792,32) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -9153228964338181824 Time: 0.02896\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -7394439838318485025 Time: 0.046208\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: -9153228964338181824 Time: 0.02896\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(100352,3136,56,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (CudnnConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.07264\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.060096\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.12016\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.302496\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 1 Time: 0.060096\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,3136:2,56,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_6 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3564772625446233998 Time: 0.031808\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3650389455493082349 Time: 0.034432\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5319956359050645452 Time: 0.026432\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7205456024582378848 Time: 0.031808\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -6490690591794140522 Time: 0.03232\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -4686027666808657977 Time: 0.047488\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -4212163711445252890 Time: 0.045312\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -3898373634979201110 Time: 0.046048\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -2409163523992614473 Time: 0.029984\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 5319956359050645452 Time: 0.026432\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,784,28,1) -> Float(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWiseV2)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.008032\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.007744\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3 Time: 0.0072\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4 Time: 0.006752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.006688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6 Time: 0.007296\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7 Time: 0.00672\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 8 Time: 0.006272\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 9 Time: 0.006496\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 28 Time: 0.00912\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 8 Time: 0.006272\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,1,1792,64) -> Float(50176,1,1792,64) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWiseV2)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009344\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.008032\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.007616\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3 Time: 0.007136\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4 Time: 0.006752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.00672\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7 Time: 0.006656\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 8 Time: 0.006208\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 9 Time: 0.006528\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 28 Time: 0.00912\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 8 Time: 0.006208\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(1568,784:32,28,1) -> Float(1568,784:32,28,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWiseV2)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 24 Time: 0.006464\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 25 Time: 0.006208\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 26 Time: 0.006496\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 27 Time: 0.00752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 31 Time: 0.006304\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 25 Time: 0.006208\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,784,28,1) -> Half(50176,784,28,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWiseV2)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009248\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.008032\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.007808\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4 Time: 0.006688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.006688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6 Time: 0.007328\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7 Time: 0.006496\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 8 Time: 0.006048\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 9 Time: 0.00624\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 28 Time: 0.009088\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 8 Time: 0.006048\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(25088,784:2,28,1) -> Half(25088,784:2,28,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWiseV2)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.006688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.006688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3 Time: 0.006464\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4 Time: 0.006272\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.006272\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6 Time: 0.007136\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7 Time: 0.006912\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 8 Time: 0.006464\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 9 Time: 0.006464\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 10 Time: 0.00976\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 11 Time: 0.008256\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 12 Time: 0.007808\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 13 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 14 Time: 0.006912\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 15 Time: 0.00688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 16 Time: 0.00736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 17 Time: 0.00672\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 18 Time: 0.006272\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 19 Time: 0.006496\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 28 Time: 0.007136\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 29 Time: 0.009728\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 4 Time: 0.006272\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_7), Mul_8) (PointWise)\n",
      "[05/24/2022-15:21:52] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,784,28,1) -> Float(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (CudnnConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.074272\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.074848\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.134528\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.307392\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.074272\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1062367460111450758 Time: 0.096544\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1754984623894446479 Time: 0.092576\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3611739942397549984 Time: 0.153632\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4337000649858996379 Time: 0.102656\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 4501471010995462441 Time: 0.15552\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5137655947464784826 Time: 0.091168\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5288347012147084929 Time: 0.152032\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 6645123197870846056 Time: 0.100288\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7144526460361122478 Time: 0.090336\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -9137461792520977713 Time: 0.159712\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -8262349710178828730 Time: 0.155136\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -8133971918129952780 Time: 0.124384\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -6092040395344634144 Time: 0.10688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -4787320710726427159 Time: 0.09104\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -3456450830548107839 Time: 0.073024\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -1218658103698133241 Time: 0.122752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -836875257600482091 Time: 0.117152\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -410470605513481746 Time: 0.152512\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: -3456450830548107839 Time: 0.073024\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3456450830548107839\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,1,1792,64) -> Float(25088,1,1792,128) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -9153228964338181824 Time: 0.045952\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -7394439838318485025 Time: 0.080736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: -9153228964338181824 Time: 0.045952\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,784,28,1) -> Half(25088,196,14,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (CudnnConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.093312\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 1 Time: 0.100544\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 2 Time: 0.124128\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5 Time: 0.30368\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.093312\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(25088,784:2,28,1) -> Half(12544,196:2,14,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (FusedConvActConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Conv_9 (CaskConvolution)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3564772625446233998 Time: 0.054176\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 3650389455493082349 Time: 0.058752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 5319956359050645452 Time: 0.041696\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 7205456024582378848 Time: 0.052672\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -6490690591794140522 Time: 0.053792\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -4686027666808657977 Time: 0.084352\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -4212163711445252890 Time: 0.080384\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -3898373634979201110 Time: 0.082176\n",
      "[05/24/2022-15:21:52] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: -2409163523992614473 Time: 0.048736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 5319956359050645452 Time: 0.041696\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(25088,196,14,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Reshape_17 + Transpose_18 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(25088,1,1792,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Reshape_17 + Transpose_18 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(784,196:32,14,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Reshape_17 + Transpose_18 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.066304\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.066304\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(25088,196,14,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Reshape_17 + Transpose_18 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009088\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.009088\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(12544,196:2,14,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Reshape_17 + Transpose_18 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.012448\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.012448\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(32768,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: MatMul_25 (MatrixMultiply)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.017824\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.017824\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(32768,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: MatMul_25 (MatrixMultiply)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.02352\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.02352\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Flatten_26 + (Unnamed Layer* 38) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Flatten_26 + (Unnamed Layer* 38) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.013024\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.013024\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Flatten_26 + (Unnamed Layer* 38) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.020416\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.020416\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Flatten_26 + (Unnamed Layer* 38) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Flatten_26 + (Unnamed Layer* 38) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.014848\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.014848\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: BatchNormalization_27 (Scale)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.009184\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: BatchNormalization_27 (Scale)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: BatchNormalization_27 (Scale)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.00784\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: BatchNormalization_27 (Scale)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.017088\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.017088\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.02112\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.02112\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.014752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.014752\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_35 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,64,4) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_35 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.008864\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,16,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_35 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.031936\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.031936\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_35 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,16,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_35 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_37 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.007328\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.007328\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,784,4) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_37 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009536\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.009536\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,196,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_37 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.031712\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.031712\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_37 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,196,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_37 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_36 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_36 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.012256\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.012256\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_36 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.057792\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.057792\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_36 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.008256\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: Transpose_36 (Shuffle)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.009856\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(12544,3136,16,1), Float(12544,3136,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: MatMul_38 (MatrixMultiply)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.01904\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.01904\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Half(12544,3136,16,1), Half(12544,3136,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: MatMul_38 (MatrixMultiply)\n",
      "[05/24/2022-15:21:52] [TRT] [V] Tactic: 0 Time: 0.014688\n",
      "[05/24/2022-15:21:52] [TRT] [V] Fastest Tactic: 0 Time: 0.014688\n",
      "[05/24/2022-15:21:52] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:21:52] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:52] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:52] [TRT] [V] --------------- Timing Runner: onnx::Add_467 + (Unnamed Layer* 72) [Shuffle] + Add_42 (Scale)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.01936\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.01936\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(153664,1,784,4) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: onnx::Add_467 + (Unnamed Layer* 72) [Shuffle] + Add_42 (Scale)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: onnx::Add_467 + (Unnamed Layer* 72) [Shuffle] + Add_42 (Scale)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.013984\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.013984\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(76832,38416:2,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: onnx::Add_467 + (Unnamed Layer* 72) [Shuffle] + Add_42 (Scale)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.018112\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.018112\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 83) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.01584\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.01584\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 83) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.008192\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.008192\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Softmax_43 (CudaSoftMax)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 1002 Time: 0.0968\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 1001 Time: 0.041856\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 1001 Time: 0.041856\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Softmax_43 (CudaSoftMax)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 1002 Time: 0.097632\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 1001 Time: 0.042336\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 1001 Time: 0.042336\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Softmax_43 (CaskSoftMax)\n",
      "[05/24/2022-15:21:53] [TRT] [V] CaskSoftMax has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:21:53] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 85) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.015776\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.015776\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 85) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.00832\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.00832\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1), Float(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: MatMul_44 (MatrixMultiply)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.05888\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.05888\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1), Half(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: MatMul_44 (MatrixMultiply)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.040352\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.040352\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(25088,6272,32,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Transpose_45 + Reshape_49 (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.008736\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(25088,1,128,4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Transpose_45 + Reshape_49 (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.014496\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.014496\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(6272,6272:32,32,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Transpose_45 + Reshape_49 (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.067488\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.067488\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(25088,6272,32,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Transpose_45 + Reshape_49 (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.008416\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.008416\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Half(12544,6272:2,32,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: Transpose_45 + Reshape_49 (Shuffle)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.01408\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 0 Time: 0.01408\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:21:53] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWiseV2)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 1 Time: 0.006496\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 2 Time: 0.006336\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 3 Time: 0.006304\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 4 Time: 0.005888\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 5 Time: 0.005664\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 6 Time: 0.007008\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 7 Time: 0.006304\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 8 Time: 0.005888\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 9 Time: 0.005856\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 28 Time: 0.006976\n",
      "[05/24/2022-15:21:53] [TRT] [V] Fastest Tactic: 5 Time: 0.005664\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWise)\n",
      "[05/24/2022-15:21:53] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:53] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWiseV2)\n",
      "[05/24/2022-15:21:53] [TRT] [V] PointWiseV2 has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWise)\n",
      "[05/24/2022-15:21:53] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:53] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:21:53] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWiseV2)\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 24 Time: 0.01616\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 25 Time: 0.015616\n",
      "[05/24/2022-15:21:53] [TRT] [V] Tactic: 26 Time: 0.017344\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 27 Time: 0.01792\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 31 Time: 0.015168\n",
      "[05/24/2022-15:21:54] [TRT] [V] Fastest Tactic: 31 Time: 0.015168\n",
      "[05/24/2022-15:21:54] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWise)\n",
      "[05/24/2022-15:21:54] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:54] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31\n",
      "[05/24/2022-15:21:54] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:21:54] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWiseV2)\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 0 Time: 0.007168\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 1 Time: 0.00656\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 2 Time: 0.006304\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 3 Time: 0.006304\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 4 Time: 0.005856\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 5 Time: 0.005664\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 6 Time: 0.006976\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 7 Time: 0.006304\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 8 Time: 0.005632\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 9 Time: 0.005888\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 28 Time: 0.006944\n",
      "[05/24/2022-15:21:54] [TRT] [V] Fastest Tactic: 8 Time: 0.005632\n",
      "[05/24/2022-15:21:54] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWise)\n",
      "[05/24/2022-15:21:54] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:21:54] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:21:54] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:21:54] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWiseV2)\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:21:54] [TRT] [V] Tactic: 1 Time: 0.006048\n",
      "[05/24/2022-15:21:55] [TRT] [V] Tactic: 2 Time: 0.006048\n",
      "[05/24/2022-15:21:55] [TRT] [V] Tactic: 3 Time: 0.006304\n",
      "[05/24/2022-15:21:55] [TRT] [V] Tactic: 4 Time: 0.006016\n",
      "[05/24/2022-15:21:55] [TRT] [V] Tactic: 5 Time: 0.005824\n",
      "[05/24/2022-15:21:56] [TRT] [V] Tactic: 6 Time: 0.00736\n",
      "[05/24/2022-15:21:56] [TRT] [V] Tactic: 7 Time: 0.006976\n",
      "[05/24/2022-15:21:56] [TRT] [V] Tactic: 8 Time: 0.006272\n",
      "[05/24/2022-15:21:57] [TRT] [V] Tactic: 9 Time: 0.006464\n",
      "[05/24/2022-15:21:57] [TRT] [V] Tactic: 10 Time: 0.008864\n",
      "[05/24/2022-15:21:57] [TRT] [V] Tactic: 11 Time: 0.00736\n",
      "[05/24/2022-15:21:57] [TRT] [V] Tactic: 12 Time: 0.006912\n",
      "[05/24/2022-15:21:58] [TRT] [V] Tactic: 13 Time: 0.006944\n",
      "[05/24/2022-15:21:58] [TRT] [V] Tactic: 14 Time: 0.006912\n",
      "[05/24/2022-15:21:58] [TRT] [V] Tactic: 15 Time: 0.00608\n",
      "[05/24/2022-15:21:58] [TRT] [V] Tactic: 16 Time: 0.007328\n",
      "[05/24/2022-15:21:59] [TRT] [V] Tactic: 17 Time: 0.006464\n",
      "[05/24/2022-15:21:59] [TRT] [V] Tactic: 18 Time: 0.005888\n",
      "[05/24/2022-15:21:59] [TRT] [V] Tactic: 19 Time: 0.006048\n",
      "[05/24/2022-15:21:59] [TRT] [V] Tactic: 28 Time: 0.006496\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 29 Time: 0.008256\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 5 Time: 0.005824\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_50), Mul_51) (PointWise)\n",
      "[05/24/2022-15:22:00] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5\n",
      "[05/24/2022-15:22:00] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_52 (Shuffle)\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_52 (Shuffle)\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_52 (Shuffle)\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 0 Time: 0.010336\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 0 Time: 0.010336\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_52 (Shuffle)\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 0 Time: 0.004928\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 0 Time: 0.004928\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_52 (Shuffle)\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:00] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:00] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:00] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CudnnConvolution)\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 0 Time: 0.057856\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 1 Time: 0.039712\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 2 Time: 0.09504\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 4 Time: 2.34704\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 5 Time: 0.343168\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 1 Time: 0.039712\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CublasConvolution)\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 1 Time: 0.016288\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: 0 Time: 0.016288\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CaskConvolution)\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 1062367460111450758 Time: 0.038688\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 1698681053543049347 Time: 0.040128\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 4501471010995462441 Time: 0.067552\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 5137655947464784826 Time: 0.04576\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 5288347012147084929 Time: 0.06704\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 5326823351883942011 Time: 0.0664\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 5500448035057547314 Time: 0.0552\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 6645123197870846056 Time: 0.04624\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 7144526460361122478 Time: 0.041632\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -8262349710178828730 Time: 0.067776\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -6576203419454146580 Time: 0.037536\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -4787320710726427159 Time: 0.041088\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -3456450830548107839 Time: 0.037216\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -1218658103698133241 Time: 0.056512\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -836875257600482091 Time: 0.05584\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -410470605513481746 Time: 0.067264\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -377491875521947884 Time: 0.066368\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -37215280111360163 Time: 0.046336\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: -3456450830548107839 Time: 0.037216\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CublasConvolution)\n",
      "[05/24/2022-15:22:00] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:00] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CaskConvolution)\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 3886731678879822788 Time: 0.026112\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: 6629944304117643200 Time: 0.01904\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -9153228964338181824 Time: 0.019008\n",
      "[05/24/2022-15:22:00] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:00] [TRT] [V] Tactic: -7394439838318485025 Time: 0.026592\n",
      "[05/24/2022-15:22:00] [TRT] [V] Fastest Tactic: -9153228964338181824 Time: 0.019008\n",
      "[05/24/2022-15:22:00] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:00] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CudnnConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 0 Time: 0.032704\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 1 Time: 0.029344\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 2 Time: 0.091424\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 4 Time: 2.34563\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 5 Time: 0.339488\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 1 Time: 0.029344\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CublasConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 0 Time: 0.023296\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 1 Time: 0.023712\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 4 Time: 0.03056\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 5 Time: 0.028\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 0 Time: 0.023296\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CaskConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CaskConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CublasConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_52 + BatchNormalization_54 (CaskConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 3066127711859985668 Time: 0.023552\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 3564772625446233998 Time: 0.024288\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 5319956359050645452 Time: 0.02336\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 7205456024582378848 Time: 0.027968\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 8163473458334948789 Time: 0.027616\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: -4212163711445252890 Time: 0.038208\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: -3898373634979201110 Time: 0.038496\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: -2409163523992614473 Time: 0.027648\n",
      "[05/24/2022-15:22:01] [TRT] [V] MatMul_52 + BatchNormalization_54 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: -1716393687483585322 Time: 0.037888\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 5319956359050645452 Time: 0.02336\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:01] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 114) [Shuffle] + Reshape_56 (Shuffle)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 114) [Shuffle] + Reshape_56 (Shuffle)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 0 Time: 0.014528\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 0 Time: 0.014528\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 114) [Shuffle] + Reshape_56 (Shuffle)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 0 Time: 0.066912\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 0 Time: 0.066912\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 114) [Shuffle] + Reshape_56 (Shuffle)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 114) [Shuffle] + Reshape_56 (Shuffle)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 0 Time: 0.014048\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 0 Time: 0.014048\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:01] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: Add_57 (ElementWise)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 1 Time: 0.006528\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 1 Time: 0.006528\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: Add_57 (ElementWise)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 1 Time: 0.025056\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 1 Time: 0.025056\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: Add_57 (ElementWise)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 1 Time: 0.0056\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 1 Time: 0.0056\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: Add_57 (ElementWise)\n",
      "[05/24/2022-15:22:01] [TRT] [V] Tactic: 1 Time: 0.005856\n",
      "[05/24/2022-15:22:01] [TRT] [V] Fastest Tactic: 1 Time: 0.005856\n",
      "[05/24/2022-15:22:01] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:01] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:01] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:01] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:01] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:02] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CudnnConvolution)\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 0 Time: 0.066432\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 1 Time: 0.041472\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 2 Time: 0.102368\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 4 Time: 4.37117\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 5 Time: 0.577664\n",
      "[05/24/2022-15:22:02] [TRT] [V] Fastest Tactic: 1 Time: 0.041472\n",
      "[05/24/2022-15:22:02] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CublasConvolution)\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 0 Time: 0.024448\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 1 Time: 0.024192\n",
      "[05/24/2022-15:22:02] [TRT] [V] Fastest Tactic: 1 Time: 0.024192\n",
      "[05/24/2022-15:22:02] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CaskConvolution)\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 1062367460111450758 Time: 0.04528\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 1698681053543049347 Time: 0.047232\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 4501471010995462441 Time: 0.06736\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 5137655947464784826 Time: 0.045824\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 5288347012147084929 Time: 0.066912\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 5326823351883942011 Time: 0.066528\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 5500448035057547314 Time: 0.05344\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 6645123197870846056 Time: 0.046496\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 7144526460361122478 Time: 0.048192\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -8262349710178828730 Time: 0.067712\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -6576203419454146580 Time: 0.044032\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -4787320710726427159 Time: 0.048\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -3456450830548107839 Time: 0.043904\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -1218658103698133241 Time: 0.054688\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -836875257600482091 Time: 0.054176\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -410470605513481746 Time: 0.0672\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -377491875521947884 Time: 0.066368\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -37215280111360163 Time: 0.046432\n",
      "[05/24/2022-15:22:02] [TRT] [V] Fastest Tactic: -3456450830548107839 Time: 0.043904\n",
      "[05/24/2022-15:22:02] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:02] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:02] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CublasConvolution)\n",
      "[05/24/2022-15:22:02] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:02] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CaskConvolution)\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 3886731678879822788 Time: 0.026176\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: 6629944304117643200 Time: 0.019264\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -9153228964338181824 Time: 0.0192\n",
      "[05/24/2022-15:22:02] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:02] [TRT] [V] Tactic: -7394439838318485025 Time: 0.026592\n",
      "[05/24/2022-15:22:02] [TRT] [V] Fastest Tactic: -9153228964338181824 Time: 0.0192\n",
      "[05/24/2022-15:22:02] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:02] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CudnnConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.046336\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 1 Time: 0.040736\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 2 Time: 0.10032\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 4 Time: 4.36381\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 5 Time: 0.572992\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 1 Time: 0.040736\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CublasConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.033248\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 1 Time: 0.032704\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 4 Time: 0.032544\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 5 Time: 0.029984\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 5 Time: 0.029984\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CaskConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 5\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CaskConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CublasConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_58 + BatchNormalization_60 (CaskConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 3066127711859985668 Time: 0.026592\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 3564772625446233998 Time: 0.02736\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 5319956359050645452 Time: 0.026656\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 7205456024582378848 Time: 0.027968\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 8163473458334948789 Time: 0.02768\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: -4212163711445252890 Time: 0.038016\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: -3898373634979201110 Time: 0.038304\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: -2409163523992614473 Time: 0.027712\n",
      "[05/24/2022-15:22:03] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: -1716393687483585322 Time: 0.037568\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.026592\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:03] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 137) [Shuffle] + Reshape_62 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 137) [Shuffle] + Reshape_62 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.023392\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.023392\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 137) [Shuffle] + Reshape_62 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.117024\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.117024\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 137) [Shuffle] + Reshape_62 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 137) [Shuffle] + Reshape_62 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.022112\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.022112\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWiseV2)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.009248\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 1 Time: 0.008032\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 2 Time: 0.007584\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 3 Time: 0.007168\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 4 Time: 0.006656\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 5 Time: 0.00672\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 6 Time: 0.00736\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 7 Time: 0.006624\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 8 Time: 0.006496\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 9 Time: 0.006528\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 28 Time: 0.00912\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 8 Time: 0.006496\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWise)\n",
      "[05/24/2022-15:22:03] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWiseV2)\n",
      "[05/24/2022-15:22:03] [TRT] [V] PointWiseV2 has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWise)\n",
      "[05/24/2022-15:22:03] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWiseV2)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 24 Time: 0.028384\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 25 Time: 0.028768\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 26 Time: 0.030624\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 27 Time: 0.029856\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 31 Time: 0.028768\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 24 Time: 0.028384\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWise)\n",
      "[05/24/2022-15:22:03] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWiseV2)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.009248\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 1 Time: 0.008\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 2 Time: 0.007776\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 3 Time: 0.007392\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 4 Time: 0.006688\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 5 Time: 0.00672\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 6 Time: 0.00736\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 7 Time: 0.006496\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 8 Time: 0.006048\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 9 Time: 0.006304\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 28 Time: 0.009088\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 8 Time: 0.006048\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWise)\n",
      "[05/24/2022-15:22:03] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWiseV2)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.00848\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 1 Time: 0.00736\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 2 Time: 0.007136\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 3 Time: 0.00672\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 4 Time: 0.006688\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 5 Time: 0.006496\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 6 Time: 0.007328\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 7 Time: 0.007104\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 8 Time: 0.006688\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 9 Time: 0.006688\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 10 Time: 0.011712\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 11 Time: 0.00976\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 12 Time: 0.008928\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 13 Time: 0.008448\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 14 Time: 0.007584\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 15 Time: 0.007392\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 16 Time: 0.008032\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 17 Time: 0.007136\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 18 Time: 0.006688\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 19 Time: 0.006752\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 28 Time: 0.00848\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 29 Time: 0.011712\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 5 Time: 0.006496\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_63), Mul_64) (PointWise)\n",
      "[05/24/2022-15:22:03] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5\n",
      "[05/24/2022-15:22:03] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_65 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_65 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.013056\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.013056\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_65 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.02032\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.02032\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_65 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.005344\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.005344\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_65 (Shuffle)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.014912\n",
      "[05/24/2022-15:22:03] [TRT] [V] Fastest Tactic: 0 Time: 0.014912\n",
      "[05/24/2022-15:22:03] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:03] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:03] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:03] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CudnnConvolution)\n",
      "[05/24/2022-15:22:03] [TRT] [V] Tactic: 0 Time: 0.097056\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 1 Time: 0.0584\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 2 Time: 0.183776\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 4 Time: 4.22294\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 5 Time: 0.593504\n",
      "[05/24/2022-15:22:04] [TRT] [V] Fastest Tactic: 1 Time: 0.0584\n",
      "[05/24/2022-15:22:04] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CublasConvolution)\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 0 Time: 0.021536\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 1 Time: 0.02144\n",
      "[05/24/2022-15:22:04] [TRT] [V] Fastest Tactic: 1 Time: 0.02144\n",
      "[05/24/2022-15:22:04] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CaskConvolution)\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 1062367460111450758 Time: 0.060704\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 1698681053543049347 Time: 0.065504\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 4501471010995462441 Time: 0.09856\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 5137655947464784826 Time: 0.068768\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 5288347012147084929 Time: 0.097408\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 5326823351883942011 Time: 0.097088\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 5500448035057547314 Time: 0.089216\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 6645123197870846056 Time: 0.069888\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 7144526460361122478 Time: 0.0688\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -8262349710178828730 Time: 0.098592\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -6576203419454146580 Time: 0.058432\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -4787320710726427159 Time: 0.067488\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -3456450830548107839 Time: 0.058688\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -1218658103698133241 Time: 0.091616\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -836875257600482091 Time: 0.090496\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -410470605513481746 Time: 0.098944\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -377491875521947884 Time: 0.09648\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -37215280111360163 Time: 0.07024\n",
      "[05/24/2022-15:22:04] [TRT] [V] Fastest Tactic: -6576203419454146580 Time: 0.058432\n",
      "[05/24/2022-15:22:04] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:04] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:04] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CublasConvolution)\n",
      "[05/24/2022-15:22:04] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:04] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CaskConvolution)\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 3886731678879822788 Time: 0.041184\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 6629944304117643200 Time: 0.02656\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -9153228964338181824 Time: 0.026624\n",
      "[05/24/2022-15:22:04] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: -7394439838318485025 Time: 0.041888\n",
      "[05/24/2022-15:22:04] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.02656\n",
      "[05/24/2022-15:22:04] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:04] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:04] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CudnnConvolution)\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 0 Time: 0.050656\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 1 Time: 0.042304\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 2 Time: 0.164992\n",
      "[05/24/2022-15:22:04] [TRT] [V] Tactic: 4 Time: 4.16618\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5 Time: 0.625888\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.042304\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CublasConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 0 Time: 0.03104\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.031264\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 4 Time: 0.04784\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5 Time: 0.041792\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 0 Time: 0.03104\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CaskConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CaskConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CublasConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_65 + BatchNormalization_67 (CaskConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 3066127711859985668 Time: 0.036544\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 3564772625446233998 Time: 0.038016\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5319956359050645452 Time: 0.036576\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 7205456024582378848 Time: 0.043104\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 8163473458334948789 Time: 0.042592\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -4212163711445252890 Time: 0.057408\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -3898373634979201110 Time: 0.058112\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -2409163523992614473 Time: 0.042816\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_65 + BatchNormalization_67 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -1716393687483585322 Time: 0.05664\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.036544\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_70 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.00688\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.00688\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_70 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.026688\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.026688\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_70 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_70 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006272\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006272\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,64,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,784,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(12544,3136,16,1), Float(12544,3136,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(12544,3136,16,1), Half(12544,3136,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,1,784,4) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(76832,38416:2,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1), Float(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1), Half(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,6272,32,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,1,128,4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(6272,6272:32,32,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,6272,32,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(12544,6272:2,32,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_109 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006912\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006912\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_109 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.026848\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.026848\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_109 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_109 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006336\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006336\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_122 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006912\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006912\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_122 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.026752\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.026752\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_122 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.005984\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.005984\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_122 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006272\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006272\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,64,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,784,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(12544,3136,16,1), Float(12544,3136,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(12544,3136,16,1), Half(12544,3136,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,1,784,4) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(76832,38416:2,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1), Float(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1), Half(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,6272,32,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,1,128,4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(6272,6272:32,32,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,6272,32,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(12544,6272:2,32,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_161 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006912\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006912\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_161 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.02688\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.02688\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_161 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_161 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006304\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006304\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_174 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006944\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006944\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_174 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.026816\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.026816\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_174 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006016\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_174 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006496\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006496\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(50176,1,12544,196) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(1792,256:32,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(25088,256:2,64,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,64,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,16,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(12544,1,784,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(3136,3136:32,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(12544,3136,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(6272,3136:2,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,64,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,1,12544,196) -> Float(25088,1,128,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1792,256:32,64,1) -> Float(6272,6272:32,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,64,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,256:2,64,1) -> Half(12544,6272:2,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(12544,3136,16,1), Float(12544,3136,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(12544,3136,16,1), Half(12544,3136,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,1,784,4) -> Float(153664,1,784,4) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(76832,38416:2,196,1) -> Half(76832,38416:2,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(153664,38416,196,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(153664,38416,196,1), Float(25088,6272,32,1) -> Float(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(153664,38416,196,1), Half(25088,6272,32,1) -> Half(25088,6272,32,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,6272,32,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,1,128,4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(6272,6272:32,32,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,6272,32,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(12544,6272:2,32,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_213 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006528\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006528\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_213 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.025248\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.025248\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_213 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.005728\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.005728\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_213 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.005952\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.005952\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(50176:32,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(50176,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(50176:2,256,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(50176:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(50176:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1), Float(25088,128,1) -> Float(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_226 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.006528\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.006528\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1), Float(25088:32,128,1) -> Float(25088:32,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_226 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.02512\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.02512\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1), Half(25088,128,1) -> Half(25088,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_226 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.005696\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.005696\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1), Half(25088:2,128,1) -> Half(25088:2,128,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: Add_226 (ElementWise)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.00592\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.00592\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(640,1,1,1) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CudnnConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 0 Time: 0.080032\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.073888\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 2 Time: 0.127296\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 4 skipped. Scratch requested: 4624547840, available: 4294967296\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5 Time: 1.2929\n",
      "[05/24/2022-15:22:05] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.073888\n",
      "[05/24/2022-15:22:05] [TRT] [V] Setting workspace to 4624547840enables more tactics for profiling\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CublasConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 0 Time: 0.055616\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1 Time: 0.054304\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1 Time: 0.054304\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CaskConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1062367460111450758 Time: 0.075744\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 1698681053543049347 Time: 0.07328\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 4501471010995462441 Time: 0.095904\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5137655947464784826 Time: 0.07472\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5288347012147084929 Time: 0.095648\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5326823351883942011 Time: 0.095104\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 5500448035057547314 Time: 0.082944\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 6645123197870846056 Time: 0.075296\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 7144526460361122478 Time: 0.07376\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -8262349710178828730 Time: 0.096064\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -6576203419454146580 Time: 0.07472\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -4787320710726427159 Time: 0.074048\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -3456450830548107839 Time: 0.075104\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -1218658103698133241 Time: 0.084544\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -836875257600482091 Time: 0.083328\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -410470605513481746 Time: 0.095232\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -377491875521947884 Time: 0.095168\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -37215280111360163 Time: 0.074944\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 1698681053543049347 Time: 0.07328\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(640,1,640,640) ***************\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CublasConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:05] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CaskConvolution)\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 3886731678879822788 Time: 0.04352\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: 6629944304117643200 Time: 0.047552\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -9153228964338181824 Time: 0.047744\n",
      "[05/24/2022-15:22:05] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:05] [TRT] [V] Tactic: -7394439838318485025 Time: 0.043648\n",
      "[05/24/2022-15:22:05] [TRT] [V] Fastest Tactic: 3886731678879822788 Time: 0.04352\n",
      "[05/24/2022-15:22:05] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:05] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(640,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CudnnConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.077888\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1 Time: 0.076416\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 2 Time: 0.124384\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 4 skipped. Scratch requested: 4624547840, available: 4294967296\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5 Time: 1.28432\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 1 Time: 0.076416\n",
      "[05/24/2022-15:22:06] [TRT] [V] Setting workspace to 4624547840enables more tactics for profiling\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CublasConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.069856\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1 Time: 0.069568\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 4 Time: 0.046272\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5 Time: 0.044032\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 5 Time: 0.044032\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CaskConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 5\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(640,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CaskConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(320,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CublasConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_233 + BatchNormalization_235 (CaskConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 3066127711859985668 Time: 0.04432\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 3564772625446233998 Time: 0.044896\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5319956359050645452 Time: 0.044544\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 7205456024582378848 Time: 0.042496\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 8163473458334948789 Time: 0.041984\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -4212163711445252890 Time: 0.05216\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -3898373634979201110 Time: 0.052544\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -2409163523992614473 Time: 0.042272\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -1716393687483585322 Time: 0.051776\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 8163473458334948789 Time: 0.041984\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088,128,1) -> Float(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_253 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(25088,1,1792,14) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_253 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.015072\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.015072\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088:32,128,1) -> Float(1792,1792:32,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_253 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.02256\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.02256\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088,128,1) -> Half(25088,1792,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_253 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088:2,128,1) -> Half(12544,1792:2,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_253 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(640,1,1,1) -> Float(125440,640,80,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.007808\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.007808\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(640,1,640,640) -> Float(125440,1,15680,196) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.032448\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.032448\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(20,1:32,1,1) -> Float(4480,640:32,80,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.043552\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.043552\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(640,1,1,1) -> Half(125440,640,80,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006592\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(320,1:2,1,1) -> Half(62720,640:2,80,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.029664\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.029664\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088,1792,128,1) -> Float(12544,1792,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_258 (Slice)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_258 (Padding)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088,1792,128,1) -> Half(12544,1792,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_258 (Slice)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006112\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_258 (Padding)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(12544,1792:2,128,1) -> Half(7168,1792:2,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_258 (Padding)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(125440,640,80,1) -> Float(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_277 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.008992\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(125440,1,15680,196) -> Float(25088,1,1568,8) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_277 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.014688\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.014688\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(4480,640:32,80,1) -> Float(3136,3136:32,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_277 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.031936\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.031936\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(125440,640,80,1) -> Half(25088,3136,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_277 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.009024\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.009024\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(62720,640:2,80,1) -> Half(12544,3136:2,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_277 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.009984\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(125440,640,80,1) -> Float(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_243 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.019968\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.019968\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(125440,1,15680,196) -> Float(100352,1,512,8) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_243 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.033088\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.033088\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(4480,640:32,80,1) -> Float(12544,12544:32,64,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_243 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.114176\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.114176\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(125440,640,80,1) -> Half(100352,12544,64,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_243 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.018656\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.018656\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(62720,640:2,80,1) -> Half(50176,12544:2,64,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_243 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.024704\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.024704\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(12544,1792,128,1) -> Float(6272,896,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_263 (Slice)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_263 (Padding)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(12544,1792,128,1) -> Half(6272,896,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_263 (Slice)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_263 (Padding)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(7168,1792:2,128,1) -> Half(3584,896:2,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Slice_263 (Padding)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(6272,896,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_267 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(6272,1,896,7) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_267 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(896,896:32,128,1) -> Float(6272:32,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_267 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.022592\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.022592\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(6272,896,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_267 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.004704\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.004704\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(3584,896:2,128,1) -> Half(6272:2,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Reshape_267 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(6272,128,1), Float(16384,128,1) -> Float(6272,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_268 (MatrixMultiply)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.009536\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.009536\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(6272,128,1), Half(16384,128,1) -> Half(6272,128,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_268 (MatrixMultiply)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.023328\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.023328\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(6272,128,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Flatten_269 + (Unnamed Layer* 748) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Flatten_269 + (Unnamed Layer* 748) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(6272:32,128,1) -> Float(4,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Flatten_269 + (Unnamed Layer* 748) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(6272,128,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Flatten_269 + (Unnamed Layer* 748) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(6272:2,128,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Flatten_269 + (Unnamed Layer* 748) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: BatchNormalization_270 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(128,1,128,128) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: BatchNormalization_270 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(128,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: BatchNormalization_270 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(64,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: BatchNormalization_270 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(128,1,1,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 + Transpose_276 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(128,1,128,128) -> Float(6272,1,128,8) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 + Transpose_276 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(784,784:32,16,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 + Transpose_276 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.01216\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.01216\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(128,1,1,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 + Transpose_276 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(64,1:2,1,1) -> Half(3136,784:2,16,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 + Transpose_276 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.006496\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(6272,784,16,1), Float(25088,3136,196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_278 (MatrixMultiply)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(6272,784,16,1), Half(25088,3136,196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_278 (MatrixMultiply)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.013824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.013824\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(76832,9604,196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: onnx::Add_767 + (Unnamed Layer* 767) [Shuffle] + Add_282 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(76832,1,1568,8) -> Float(76832,1,1568,8) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: onnx::Add_767 + (Unnamed Layer* 767) [Shuffle] + Add_282 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(76832,9604,196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: onnx::Add_767 + (Unnamed Layer* 767) [Shuffle] + Add_282 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.009568\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(38416,9604:2,196,1) -> Half(38416,9604:2,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: onnx::Add_767 + (Unnamed Layer* 767) [Shuffle] + Add_282 (Scale)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.011488\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.011488\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(76832,9604,196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 778) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.008192\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.008192\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(76832,9604,196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 778) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Softmax_283 (CudaSoftMax)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1002 Time: 0.050688\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1001 Time: 0.0232\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 1001 Time: 0.0232\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Softmax_283 (CudaSoftMax)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1002 Time: 0.051552\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1001 Time: 0.023744\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 1001 Time: 0.023744\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Softmax_283 (CaskSoftMax)\n",
      "[05/24/2022-15:22:06] [TRT] [V] CaskSoftMax has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(196,1) -> Float(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 780) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.00816\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.00816\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(196,1) -> Half(76832,9604,196,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 780) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(76832,9604,196,1), Float(100352,12544,64,1) -> Float(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_284 (MatrixMultiply)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.034944\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.034944\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(76832,9604,196,1), Half(100352,12544,64,1) -> Half(25088,3136,64,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_284 (MatrixMultiply)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.029984\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.029984\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088,3136,64,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_285 + Reshape_288 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.008704\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088,1,512,8) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_285 + Reshape_288 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.018272\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.018272\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(3136,3136:32,64,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_285 + Reshape_288 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.061344\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.061344\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088,3136,64,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_285 + Reshape_288 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.008288\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.008288\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(12544,3136:2,64,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: Transpose_285 + Reshape_288 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.018368\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.018368\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWiseV2)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.007136\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1 Time: 0.006496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 2 Time: 0.006272\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 3 Time: 0.006272\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 4 Time: 0.005856\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5 Time: 0.0056\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 6 Time: 0.006912\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 7 Time: 0.00624\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 8 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 9 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 28 Time: 0.00704\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 5 Time: 0.0056\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWise)\n",
      "[05/24/2022-15:22:06] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWiseV2)\n",
      "[05/24/2022-15:22:06] [TRT] [V] PointWiseV2 has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWise)\n",
      "[05/24/2022-15:22:06] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWiseV2)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 24 Time: 0.015456\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 25 Time: 0.015808\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 26 Time: 0.017248\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 27 Time: 0.018208\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 31 Time: 0.015776\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 24 Time: 0.015456\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWise)\n",
      "[05/24/2022-15:22:06] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWiseV2)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.006912\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1 Time: 0.006496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 2 Time: 0.006304\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 3 Time: 0.00624\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 4 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5 Time: 0.005632\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 6 Time: 0.00688\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 7 Time: 0.00624\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 8 Time: 0.005632\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 9 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 28 Time: 0.006912\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 5 Time: 0.005632\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWise)\n",
      "[05/24/2022-15:22:06] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWiseV2)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 2 Time: 0.006048\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 3 Time: 0.00624\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 4 Time: 0.006048\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 6 Time: 0.007328\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 7 Time: 0.00688\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 8 Time: 0.006272\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 9 Time: 0.006464\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 10 Time: 0.008256\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 11 Time: 0.00736\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 12 Time: 0.00672\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 13 Time: 0.006912\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 14 Time: 0.006272\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 15 Time: 0.00608\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 16 Time: 0.00736\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 17 Time: 0.006496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 18 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 19 Time: 0.006048\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 28 Time: 0.006624\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 29 Time: 0.008288\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 5 Time: 0.005824\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_289), Mul_290) (PointWise)\n",
      "[05/24/2022-15:22:06] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_291 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.005376\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_291 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_291 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.010304\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.010304\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_291 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_291 (Shuffle)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.009792\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CudnnConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.059296\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1 Time: 0.060512\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 2 Time: 0.162912\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 4 Time: 4.83731\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5 Time: 0.657152\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.059296\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CublasConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 0 Time: 0.023744\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1 Time: 0.023936\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: 0 Time: 0.023744\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CaskConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1062367460111450758 Time: 0.105216\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 1698681053543049347 Time: 0.116512\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 4501471010995462441 Time: 0.160576\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5137655947464784826 Time: 0.115296\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5288347012147084929 Time: 0.158336\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5326823351883942011 Time: 0.15728\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 5500448035057547314 Time: 0.156768\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 6645123197870846056 Time: 0.117248\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: 7144526460361122478 Time: 0.122528\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -8262349710178828730 Time: 0.16032\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -6576203419454146580 Time: 0.100608\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -4787320710726427159 Time: 0.1192\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -3456450830548107839 Time: 0.100864\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -1218658103698133241 Time: 0.161216\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -836875257600482091 Time: 0.158976\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -410470605513481746 Time: 0.1616\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -377491875521947884 Time: 0.156352\n",
      "[05/24/2022-15:22:06] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:06] [TRT] [V] Tactic: -37215280111360163 Time: 0.118496\n",
      "[05/24/2022-15:22:06] [TRT] [V] Fastest Tactic: -6576203419454146580 Time: 0.100608\n",
      "[05/24/2022-15:22:06] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:06] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CublasConvolution)\n",
      "[05/24/2022-15:22:06] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:06] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3886731678879822788 Time: 0.07072\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 6629944304117643200 Time: 0.041408\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -9153228964338181824 Time: 0.041888\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -7394439838318485025 Time: 0.072992\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.041408\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CudnnConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.084864\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.0576\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 2 Time: 0.158144\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 4.88742\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.665024\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.0576\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CublasConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.023904\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.023744\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 0.068768\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.06032\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.023744\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CublasConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_291 + BatchNormalization_293 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3066127711859985668 Time: 0.055808\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3564772625446233998 Time: 0.058048\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5319956359050645452 Time: 0.05584\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 7205456024582378848 Time: 0.065248\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 8163473458334948789 Time: 0.06432\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -4212163711445252890 Time: 0.08432\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -3898373634979201110 Time: 0.085408\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -2409163523992614473 Time: 0.063872\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_291 + BatchNormalization_293 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -1716393687483585322 Time: 0.082528\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.055808\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 810) [Shuffle] + Reshape_295 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 810) [Shuffle] + Reshape_295 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.010496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.010496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 810) [Shuffle] + Reshape_295 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.034592\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.034592\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 810) [Shuffle] + Reshape_295 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 810) [Shuffle] + Reshape_295 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.01008\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.01008\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(131072,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_296 (MatrixMultiply)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.017088\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.017088\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(131072,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_296 (MatrixMultiply)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.034272\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.034272\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Flatten_297 + (Unnamed Layer* 831) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Flatten_297 + (Unnamed Layer* 831) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Flatten_297 + (Unnamed Layer* 831) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.0104\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.0104\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Flatten_297 + (Unnamed Layer* 831) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Flatten_297 + (Unnamed Layer* 831) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: BatchNormalization_298 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: BatchNormalization_298 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: BatchNormalization_298 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: BatchNormalization_298 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00736\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00736\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 833) [Shuffle] + Reshape_300 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 833) [Shuffle] + Reshape_300 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.018528\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.018528\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 833) [Shuffle] + Reshape_300 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.060864\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.060864\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 833) [Shuffle] + Reshape_300 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 833) [Shuffle] + Reshape_300 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.018272\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.018272\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Add_308 (ElementWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Add_308 (ElementWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.01536\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.01536\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Add_308 (ElementWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Add_308 (ElementWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_315 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_315 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_315 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_315 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_315 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CudnnConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.041696\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.04576\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 2 Time: 0.14528\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 4.93248\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.655296\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.041696\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CublasConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.021504\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.02176\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.021504\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1062367460111450758 Time: 0.067808\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1698681053543049347 Time: 0.072832\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4501471010995462441 Time: 0.098592\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5137655947464784826 Time: 0.0688\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5288347012147084929 Time: 0.097408\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5326823351883942011 Time: 0.097376\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5500448035057547314 Time: 0.084864\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 6645123197870846056 Time: 0.06992\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 7144526460361122478 Time: 0.074816\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -8262349710178828730 Time: 0.09856\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -6576203419454146580 Time: 0.065312\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -4787320710726427159 Time: 0.074208\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -3456450830548107839 Time: 0.065408\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -1218658103698133241 Time: 0.08736\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -836875257600482091 Time: 0.086272\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -410470605513481746 Time: 0.09824\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -377491875521947884 Time: 0.09632\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -37215280111360163 Time: 0.07024\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: -6576203419454146580 Time: 0.065312\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CublasConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3886731678879822788 Time: 0.040992\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 6629944304117643200 Time: 0.026624\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -9153228964338181824 Time: 0.026592\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -7394439838318485025 Time: 0.041856\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: -9153228964338181824 Time: 0.026592\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CudnnConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.049856\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.042272\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 2 Time: 0.1368\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 4.93418\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.653824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.042272\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CublasConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.028928\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.028032\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 0.043904\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.038976\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1 Time: 0.028032\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CublasConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_315 + BatchNormalization_317 (CaskConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3066127711859985668 Time: 0.037312\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3564772625446233998 Time: 0.03872\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5319956359050645452 Time: 0.037216\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 7205456024582378848 Time: 0.040192\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 8163473458334948789 Time: 0.039712\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -4212163711445252890 Time: 0.053504\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -3898373634979201110 Time: 0.053792\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -2409163523992614473 Time: 0.039712\n",
      "[05/24/2022-15:22:07] [TRT] [V] MatMul_315 + BatchNormalization_317 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: -1716393687483585322 Time: 0.052576\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 5319956359050645452 Time: 0.037216\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 888) [Shuffle] + Reshape_319 + Reshape_323 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 888) [Shuffle] + Reshape_319 + Reshape_323 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.010976\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.010976\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 888) [Shuffle] + Reshape_319 + Reshape_323 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.014624\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 888) [Shuffle] + Reshape_319 + Reshape_323 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.004928\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.004928\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 888) [Shuffle] + Reshape_319 + Reshape_323 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.010016\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.010016\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_325 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,128,8) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_325 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,16,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_325 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.012384\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.012384\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_325 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,16,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_325 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_327 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,392,8) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_327 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_327 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.012352\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.012352\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_327 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_327 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_326 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_326 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.008928\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_326 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.0192\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.0192\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_326 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_326 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(6272,784,16,1), Float(6272,784,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_328 (MatrixMultiply)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.012736\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.012736\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(6272,784,16,1), Half(6272,784,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_328 (MatrixMultiply)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.0136\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.0136\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: onnx::Add_831 + (Unnamed Layer* 920) [Shuffle] + Add_332 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(19208,1,392,8) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: onnx::Add_831 + (Unnamed Layer* 920) [Shuffle] + Add_332 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: onnx::Add_831 + (Unnamed Layer* 920) [Shuffle] + Add_332 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(9604,2401:2,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: onnx::Add_831 + (Unnamed Layer* 920) [Shuffle] + Add_332 (Scale)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006944\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 931) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005152\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.005152\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 931) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Softmax_333 (CudaSoftMax)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1002 Time: 0.045696\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1001 Time: 0.011712\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1001 Time: 0.011712\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Softmax_333 (CudaSoftMax)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1002 Time: 0.046112\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1001 Time: 0.01168\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 1001 Time: 0.01168\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Softmax_333 (CaskSoftMax)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CaskSoftMax has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 933) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 933) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1), Float(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_334 (MatrixMultiply)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.017696\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.017696\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1), Half(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_334 (MatrixMultiply)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.017248\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.017248\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544,1568,32,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_335 + Reshape_339 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544,1,256,8) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_335 + Reshape_339 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.010496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.010496\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1568,1568:32,32,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_335 + Reshape_339 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.034368\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.034368\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544,1568,32,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_335 + Reshape_339 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(6272,1568:2,32,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: Transpose_335 + Reshape_339 (Shuffle)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 0 Time: 0.009824\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWiseV2)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 2 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 6 Time: 0.006688\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 7 Time: 0.006048\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 8 Time: 0.005632\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 9 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 28 Time: 0.005888\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 2 Time: 0.005408\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWiseV2)\n",
      "[05/24/2022-15:22:07] [TRT] [V] PointWiseV2 has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWiseV2)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 24 Time: 0.009152\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 25 Time: 0.00784\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 26 Time: 0.00784\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 27 Time: 0.008192\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 31 Time: 0.008928\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 25 Time: 0.00784\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWiseV2)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 2 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 0.005376\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.005376\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 6 Time: 0.006912\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 7 Time: 0.006048\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 8 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 9 Time: 0.005632\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 28 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 4 Time: 0.005376\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWiseV2)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 2 Time: 0.005632\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 3 Time: 0.006048\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 4 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 5 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 6 Time: 0.007104\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 7 Time: 0.006816\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 8 Time: 0.00624\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 9 Time: 0.006464\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 10 Time: 0.006496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 11 Time: 0.00624\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 12 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 13 Time: 0.00624\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 14 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 15 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 16 Time: 0.007104\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 17 Time: 0.00624\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 18 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 19 Time: 0.005824\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 28 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 29 Time: 0.006496\n",
      "[05/24/2022-15:22:07] [TRT] [V] Fastest Tactic: 15 Time: 0.0056\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_340), Mul_341) (PointWise)\n",
      "[05/24/2022-15:22:07] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 15\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:07] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:07] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CudnnConvolution)\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 0 Time: 0.03584\n",
      "[05/24/2022-15:22:07] [TRT] [V] Tactic: 1 Time: 0.0376\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 2 Time: 0.141984\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 4 Time: 2.74586\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5 Time: 0.387072\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 0 Time: 0.03584\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CublasConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 0 Time: 0.018432\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.018432\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 0 Time: 0.018432\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CaskConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1062367460111450758 Time: 0.065344\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1698681053543049347 Time: 0.07056\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 4501471010995462441 Time: 0.105888\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5137655947464784826 Time: 0.074048\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5288347012147084929 Time: 0.10512\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5326823351883942011 Time: 0.104832\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5500448035057547314 Time: 0.095808\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 6645123197870846056 Time: 0.075264\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 7144526460361122478 Time: 0.073568\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -8262349710178828730 Time: 0.105728\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -6576203419454146580 Time: 0.06288\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -4787320710726427159 Time: 0.072\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -3456450830548107839 Time: 0.062944\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -1218658103698133241 Time: 0.098944\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -836875257600482091 Time: 0.096992\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -410470605513481746 Time: 0.10608\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -377491875521947884 Time: 0.103744\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -37215280111360163 Time: 0.075872\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: -6576203419454146580 Time: 0.06288\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CublasConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CaskConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 3886731678879822788 Time: 0.044096\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 6629944304117643200 Time: 0.028416\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -9153228964338181824 Time: 0.028416\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -7394439838318485025 Time: 0.045312\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.028416\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CudnnConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 0 Time: 0.045792\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.033856\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 2 Time: 0.13984\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 4 Time: 2.57197\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5 Time: 0.361504\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.033856\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CublasConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 0 Time: 0.020576\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.02064\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 4 Time: 0.043072\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5 Time: 0.037856\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 0 Time: 0.020576\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CaskConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CaskConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CublasConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_342 + BatchNormalization_344 (CaskConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 3066127711859985668 Time: 0.03408\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 3564772625446233998 Time: 0.035232\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5319956359050645452 Time: 0.034112\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 7205456024582378848 Time: 0.040192\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 8163473458334948789 Time: 0.039712\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -4212163711445252890 Time: 0.053536\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -3898373634979201110 Time: 0.05424\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -2409163523992614473 Time: 0.039744\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_342 + BatchNormalization_344 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: -1716393687483585322 Time: 0.0528\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.03408\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_347 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_347 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.015392\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.015392\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_347 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_347 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_360 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_360 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.0152\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.0152\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_360 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_360 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,128,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,392,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(6272,784,16,1), Float(6272,784,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(6272,784,16,1), Half(6272,784,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,1,392,8) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(9604,2401:2,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1), Float(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1), Half(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,1568,32,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,1,256,8) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1568,1568:32,32,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,1568,32,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(6272,1568:2,32,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_399 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_399 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.015104\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.015104\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_399 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_399 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_412 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_412 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.015264\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.015264\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_412 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_412 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,128,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,392,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(6272,784,16,1), Float(6272,784,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(6272,784,16,1), Half(6272,784,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,1,392,8) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(9604,2401:2,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1), Float(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1), Half(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,1568,32,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,1,256,8) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1568,1568:32,32,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,1568,32,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(6272,1568:2,32,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_451 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_451 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.01536\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.01536\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_451 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_451 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_464 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_464 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.01488\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.01488\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_464 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_464 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(25088,1,3136,49) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(1024,512:32,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(12800,512:2,64,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,128,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,16,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(6272,1,392,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(784,784:32,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(6272,784,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(3136,784:2,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,64,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,1,3136,49) -> Float(12544,1,256,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1024,512:32,64,1) -> Float(1568,1568:32,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,64,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12800,512:2,64,1) -> Half(6272,1568:2,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(6272,784,16,1), Float(6272,784,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(6272,784,16,1), Half(6272,784,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,1,392,8) -> Float(19208,1,392,8) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(9604,2401:2,49,1) -> Half(9604,2401:2,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(19208,2401,49,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(19208,2401,49,1), Float(12544,1568,32,1) -> Float(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(19208,2401,49,1), Half(12544,1568,32,1) -> Half(12544,1568,32,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,1568,32,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,1,256,8) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1568,1568:32,32,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,1568,32,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(6272,1568:2,32,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_503 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_503 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.0152\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.0152\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_503 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_503 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(25088:32,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(25088,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(25088:2,512,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088,512,1) -> Float(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(25088:32,512,1) -> Float(16,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088,512,1) -> Half(512,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(25088:2,512,1) -> Half(256,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(512,1,512,512) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(512,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1), Float(12544,256,1) -> Float(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_516 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1), Float(12544:32,256,1) -> Float(12544:32,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_516 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.01536\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.01536\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1), Half(12544,256,1) -> Half(12544,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_516 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1), Half(12544:2,256,1) -> Half(12544:2,256,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: Add_516 (ElementWise)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:08] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:08] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(1280,1,1,1) ***************\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CudnnConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 0 Time: 0.072448\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.078784\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 2 Time: 0.171104\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 4 Time: 12.069\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5 Time: 1.56342\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 0 Time: 0.072448\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CublasConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 0 Time: 0.039776\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1 Time: 0.039328\n",
      "[05/24/2022-15:22:08] [TRT] [V] Fastest Tactic: 1 Time: 0.039328\n",
      "[05/24/2022-15:22:08] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CaskConvolution)\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1062367460111450758 Time: 0.084\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 1698681053543049347 Time: 0.080192\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 4501471010995462441 Time: 0.098592\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:08] [TRT] [V] Tactic: 5137655947464784826 Time: 0.08288\n",
      "[05/24/2022-15:22:08] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5288347012147084929 Time: 0.097696\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5326823351883942011 Time: 0.097408\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5500448035057547314 Time: 0.102496\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 6645123197870846056 Time: 0.084032\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 7144526460361122478 Time: 0.082144\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -8262349710178828730 Time: 0.098816\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -6576203419454146580 Time: 0.082656\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -4787320710726427159 Time: 0.081824\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -3456450830548107839 Time: 0.08288\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -1218658103698133241 Time: 0.105056\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -836875257600482091 Time: 0.103104\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -410470605513481746 Time: 0.09936\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -377491875521947884 Time: 0.096768\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -37215280111360163 Time: 0.08432\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 1698681053543049347 Time: 0.080192\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(1280,1,1280,1280) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CublasConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CaskConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 3886731678879822788 Time: 0.041248\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 6629944304117643200 Time: 0.048096\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -9153228964338181824 Time: 0.048544\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -7394439838318485025 Time: 0.04192\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 3886731678879822788 Time: 0.041248\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(1280,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CudnnConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.078688\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1 Time: 0.068032\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 2 Time: 0.162752\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 4 Time: 12.0716\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5 Time: 1.52864\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 1 Time: 0.068032\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CublasConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.062944\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1 Time: 0.06064\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 4 Time: 0.050944\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5 Time: 0.046656\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 5 Time: 0.046656\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CaskConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 5\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(1280,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CaskConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(640,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CublasConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_523 + BatchNormalization_525 (CaskConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 3066127711859985668 Time: 0.052896\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 3564772625446233998 Time: 0.05296\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5319956359050645452 Time: 0.051872\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 7205456024582378848 Time: 0.0472\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 8163473458334948789 Time: 0.046432\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -4212163711445252890 Time: 0.053696\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -3898373634979201110 Time: 0.054432\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -2409163523992614473 Time: 0.046944\n",
      "[05/24/2022-15:22:09] [TRT] [V] MatMul_523 + BatchNormalization_525 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: -1716393687483585322 Time: 0.053056\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 8163473458334948789 Time: 0.046432\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(12544,256,1) -> Float(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_543 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12544,1,1792,7) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_543 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00832\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00832\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(12544:32,256,1) -> Float(1792,1792:32,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_543 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.021696\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.021696\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(12544,256,1) -> Half(12544,1792,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_543 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004672\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004672\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(12544:2,256,1) -> Half(7168,1792:2,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_543 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1280,1,1,1) -> Float(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1504) [Shuffle] + Reshape_527 + Reshape_531 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1280,1,1280,1280) -> Float(62720,1,3920,49) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1504) [Shuffle] + Reshape_527 + Reshape_531 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.031072\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.031072\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(40,1:32,1,1) -> Float(2560,1280:32,80,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1504) [Shuffle] + Reshape_527 + Reshape_531 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.027392\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.027392\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(1280,1,1,1) -> Half(62720,1280,80,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1504) [Shuffle] + Reshape_527 + Reshape_531 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005568\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005568\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(640,1:2,1,1) -> Half(32000,1280:2,80,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1504) [Shuffle] + Reshape_527 + Reshape_531 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.017408\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.017408\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(12544,1792,256,1) -> Float(7168,1792,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_548 (Slice)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_548 (Padding)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(12544,1792,256,1) -> Half(7168,1792,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_548 (Slice)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_548 (Padding)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(7168,1792:2,256,1) -> Half(3584,1792:2,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_548 (Padding)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(62720,1280,80,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_567 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00688\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00688\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(62720,1,3920,49) -> Float(12544,1,784,16) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_567 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.010656\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.010656\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(2560,1280:32,80,1) -> Float(784,784:32,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_567 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.012416\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.012416\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(62720,1280,80,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_567 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(32000,1280:2,80,1) -> Half(6272,784:2,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_567 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(62720,1280,80,1) -> Float(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_533 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(62720,1,3920,49) -> Float(50176,1,1024,16) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_533 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.019872\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.019872\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(2560,1280:32,80,1) -> Float(3136,3136:32,64,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_533 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.033824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.033824\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(62720,1280,80,1) -> Half(50176,3136,64,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_533 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.011776\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.011776\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(32000,1280:2,80,1) -> Half(25088,3136:2,64,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_533 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.014816\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.014816\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(7168,1792,256,1) -> Float(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_553 (Slice)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_553 (Padding)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(7168,1792,256,1) -> Half(4096,1024,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_553 (Slice)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_553 (Padding)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(3584,1792:2,256,1) -> Half(2048,1024:2,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Slice_553 (Padding)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Padding has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(4096,1024,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_557 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(4096,1,1024,4) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_557 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00672\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1024,1024:32,256,1) -> Float(4096:32,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_557 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.015648\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.015648\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(4096,1024,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_557 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004544\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004544\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(2048,1024:2,256,1) -> Half(4096:2,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Reshape_557 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(4096,256,1), Float(65536,256,1) -> Float(4096,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_558 (MatrixMultiply)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.012736\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.012736\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(4096,256,1), Half(65536,256,1) -> Half(4096,256,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_558 (MatrixMultiply)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.03424\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.03424\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(4096,256,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Flatten_559 + (Unnamed Layer* 1612) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Flatten_559 + (Unnamed Layer* 1612) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(4096:32,256,1) -> Float(8,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Flatten_559 + (Unnamed Layer* 1612) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(4096,256,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Flatten_559 + (Unnamed Layer* 1612) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004544\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004544\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(4096:2,256,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Flatten_559 + (Unnamed Layer* 1612) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: BatchNormalization_560 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(256,1,256,256) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: BatchNormalization_560 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(256,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: BatchNormalization_560 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(128,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: BatchNormalization_560 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(256,1,1,1) -> Float(4096,256,16,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 + Transpose_566 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(256,1,256,256) -> Float(4096,1,256,16) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 + Transpose_566 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006816\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(8,1:32,1,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 + Transpose_566 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(256,1,1,1) -> Half(4096,256,16,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 + Transpose_566 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(128,1:2,1,1) -> Half(2048,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 + Transpose_566 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(4096,256,16,1), Float(12544,784,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_568 (MatrixMultiply)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.008032\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.008032\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(4096,256,16,1), Half(12544,784,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_568 (MatrixMultiply)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.015104\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.015104\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(12544,784,49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: onnx::Add_1131 + (Unnamed Layer* 1631) [Shuffle] + Add_572 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(12544,1,784,16) -> Float(12544,1,784,16) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: onnx::Add_1131 + (Unnamed Layer* 1631) [Shuffle] + Add_572 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(12544,784,49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: onnx::Add_1131 + (Unnamed Layer* 1631) [Shuffle] + Add_572 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(6272,784:2,49,1) -> Half(6272,784:2,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: onnx::Add_1131 + (Unnamed Layer* 1631) [Shuffle] + Add_572 (Scale)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(12544,784,49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1642) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(12544,784,49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1642) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Softmax_573 (CudaSoftMax)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1002 Time: 0.03296\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1001 Time: 0.009568\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 1001 Time: 0.009568\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Softmax_573 (CudaSoftMax)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1002 Time: 0.032992\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1001 Time: 0.009536\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 1001 Time: 0.009536\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Softmax_573 (CaskSoftMax)\n",
      "[05/24/2022-15:22:09] [TRT] [V] CaskSoftMax has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(49,1) -> Float(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1644) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00496\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(49,1) -> Half(12544,784,49,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1644) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(12544,784,49,1), Float(50176,3136,64,1) -> Float(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_574 (MatrixMultiply)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(12544,784,49,1), Half(50176,3136,64,1) -> Half(16384,1024,64,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_574 (MatrixMultiply)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.018976\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.018976\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(16384,1024,64,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_575 + Reshape_578 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.007616\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(16384,1,1024,16) -> Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_575 + Reshape_578 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.016256\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.016256\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1024,1024:32,64,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_575 + Reshape_578 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.042016\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.042016\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(16384,1024,64,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_575 + Reshape_578 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.0072\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(8192,1024:2,64,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: Transpose_575 + Reshape_578 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.011776\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.011776\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(16384,1024,1) -> Float(16384,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWiseV2)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 2 Time: 0.0056\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 3 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 4 Time: 0.0056\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 6 Time: 0.00688\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 7 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 8 Time: 0.0056\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 9 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 28 Time: 0.00608\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 2 Time: 0.0056\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWise)\n",
      "[05/24/2022-15:22:09] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 1024 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWiseV2)\n",
      "[05/24/2022-15:22:09] [TRT] [V] PointWiseV2 has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWise)\n",
      "[05/24/2022-15:22:09] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(16384:32,1024,1) -> Float(16384:32,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWiseV2)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 24 Time: 0.010816\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 25 Time: 0.009152\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 26 Time: 0.00912\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 27 Time: 0.009568\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 31 Time: 0.01072\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 26 Time: 0.00912\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWise)\n",
      "[05/24/2022-15:22:09] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(16384,1024,1) -> Half(16384,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWiseV2)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00624\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 2 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 3 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 4 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5 Time: 0.005408\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 6 Time: 0.00688\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 7 Time: 0.006016\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 8 Time: 0.005632\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 9 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 28 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 5 Time: 0.005408\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWise)\n",
      "[05/24/2022-15:22:09] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(16384:2,1024,1) -> Half(16384:2,1024,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWiseV2)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1 Time: 0.005856\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 2 Time: 0.0056\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 3 Time: 0.00624\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 4 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 5 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 6 Time: 0.007328\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 7 Time: 0.006912\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 8 Time: 0.00624\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 9 Time: 0.006464\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 10 Time: 0.007136\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 11 Time: 0.006496\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 12 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 13 Time: 0.006464\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 14 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 15 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 16 Time: 0.007328\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 17 Time: 0.006272\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 18 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 19 Time: 0.005824\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 28 Time: 0.006048\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 29 Time: 0.007168\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 2 Time: 0.0056\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_579), Mul_580) (PointWise)\n",
      "[05/24/2022-15:22:09] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(16384,1024,1) -> Float(1024,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_581 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1,(* 1024 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1024,1,1024,1024) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_581 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.007808\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.007808\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(16384:32,1024,1) -> Float(32,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_581 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.008832\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.008832\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(16384,1024,1) -> Half(1024,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_581 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Half(16384:2,1024,1) -> Half(512,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_581 (Shuffle)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.00848\n",
      "[05/24/2022-15:22:09] [TRT] [V] Fastest Tactic: 0 Time: 0.00848\n",
      "[05/24/2022-15:22:09] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:09] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:09] [TRT] [V] *************** Autotuning format combination: Float(1024,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:09] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CudnnConvolution)\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 0 Time: 0.111744\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 1 Time: 0.11504\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 2 Time: 0.184864\n",
      "[05/24/2022-15:22:09] [TRT] [V] Tactic: 4 Time: 5.16653\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.793632\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.111744\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.040096\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.039808\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.039808\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1062367460111450758 Time: 0.15776\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1698681053543049347 Time: 0.180672\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4501471010995462441 Time: 0.291008\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5137655947464784826 Time: 0.158656\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5288347012147084929 Time: 0.269984\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5326823351883942011 Time: 0.268192\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5500448035057547314 Time: 0.222656\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6645123197870846056 Time: 0.163104\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7144526460361122478 Time: 0.174336\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -8262349710178828730 Time: 0.27136\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -6576203419454146580 Time: 0.130112\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -4787320710726427159 Time: 0.168352\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -3456450830548107839 Time: 0.130624\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -1218658103698133241 Time: 0.2256\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -836875257600482091 Time: 0.22096\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -410470605513481746 Time: 0.27344\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -377491875521947884 Time: 0.26432\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -37215280111360163 Time: 0.155232\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: -6576203419454146580 Time: 0.130112\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(1024,1,1024,1024) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3886731678879822788 Time: 0.132096\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6629944304117643200 Time: 0.072416\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -9153228964338181824 Time: 0.073344\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -7394439838318485025 Time: 0.136448\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.072416\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(1024,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CudnnConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.14592\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.092512\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 2 Time: 0.15264\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 4.8375\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.736064\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.092512\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.037216\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.037152\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 0.083872\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.07872\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.037152\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(512,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(512,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_581 + BatchNormalization_583 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3066127711859985668 Time: 0.06928\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3564772625446233998 Time: 0.079648\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5319956359050645452 Time: 0.070336\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7205456024582378848 Time: 0.083744\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 8163473458334948789 Time: 0.082144\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -4212163711445252890 Time: 0.13856\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -3898373634979201110 Time: 0.14016\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -2409163523992614473 Time: 0.082368\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_581 + BatchNormalization_583 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -1716393687483585322 Time: 0.136384\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.06928\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1674) [Shuffle] + Reshape_585 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1674) [Shuffle] + Reshape_585 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1674) [Shuffle] + Reshape_585 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.01968\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.01968\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1674) [Shuffle] + Reshape_585 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.0048\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.0048\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1674) [Shuffle] + Reshape_585 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007232\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(294912,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_586 (MatrixMultiply)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.016448\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.016448\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(294912,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_586 (MatrixMultiply)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.045696\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.045696\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Flatten_587 + (Unnamed Layer* 1695) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Flatten_587 + (Unnamed Layer* 1695) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Flatten_587 + (Unnamed Layer* 1695) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Flatten_587 + (Unnamed Layer* 1695) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Flatten_587 + (Unnamed Layer* 1695) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: BatchNormalization_588 (Scale)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: BatchNormalization_588 (Scale)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: BatchNormalization_588 (Scale)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: BatchNormalization_588 (Scale)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.006752\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1697) [Shuffle] + Reshape_590 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.005056\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.005056\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1697) [Shuffle] + Reshape_590 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.009376\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.009376\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1697) [Shuffle] + Reshape_590 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.032576\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.032576\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1697) [Shuffle] + Reshape_590 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1697) [Shuffle] + Reshape_590 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.010048\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWiseV2)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.005632\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 2 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3 Time: 0.005856\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 0.005632\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6 Time: 0.006752\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7 Time: 0.00608\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 8 Time: 0.005632\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 9 Time: 0.005664\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 28 Time: 0.005888\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 2 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 768 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWiseV2)\n",
      "[05/24/2022-15:22:10] [TRT] [V] PointWiseV2 has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWiseV2)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 24 Time: 0.008992\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 25 Time: 0.00784\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 26 Time: 0.007872\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 27 Time: 0.008224\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 31 Time: 0.008992\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 25 Time: 0.00784\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWiseV2)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 2 Time: 0.005664\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3 Time: 0.005856\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6 Time: 0.006944\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7 Time: 0.006048\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 8 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 9 Time: 0.005632\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 28 Time: 0.005888\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 4 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWiseV2)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 2 Time: 0.005632\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3 Time: 0.00608\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 0.005824\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.005824\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6 Time: 0.007392\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7 Time: 0.006944\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 8 Time: 0.006304\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 9 Time: 0.006496\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 10 Time: 0.006528\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 11 Time: 0.006304\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 12 Time: 0.005888\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 13 Time: 0.006272\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 14 Time: 0.005888\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 15 Time: 0.005632\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 16 Time: 0.0072\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 17 Time: 0.006304\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 18 Time: 0.005888\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 19 Time: 0.005856\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 28 Time: 0.005664\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 29 Time: 0.00656\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 2 Time: 0.005632\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_591), Mul_592) (PointWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_593 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_593 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007008\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_593 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007744\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_593 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_593 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CudnnConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.080576\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.083584\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 2 Time: 0.15296\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 3.67939\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.567968\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.080576\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.03024\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.02992\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.02992\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1062367460111450758 Time: 0.113856\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1698681053543049347 Time: 0.128352\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4501471010995462441 Time: 0.208352\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5137655947464784826 Time: 0.121312\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5288347012147084929 Time: 0.205888\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5326823351883942011 Time: 0.204032\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5500448035057547314 Time: 0.176128\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6645123197870846056 Time: 0.124832\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7144526460361122478 Time: 0.132064\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -8262349710178828730 Time: 0.207264\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -6576203419454146580 Time: 0.099744\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -4787320710726427159 Time: 0.127424\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -3456450830548107839 Time: 0.1\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -1218658103698133241 Time: 0.177472\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -836875257600482091 Time: 0.174624\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -410470605513481746 Time: 0.208864\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -377491875521947884 Time: 0.201888\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -37215280111360163 Time: 0.119104\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: -6576203419454146580 Time: 0.099744\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3886731678879822788 Time: 0.1008\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6629944304117643200 Time: 0.056448\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -9153228964338181824 Time: 0.05728\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -7394439838318485025 Time: 0.103872\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.056448\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CudnnConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.11264\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.073216\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 2 Time: 0.137856\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 3.68176\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.556416\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.073216\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.030368\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.030368\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 0.089792\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.077344\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.030368\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_593 + BatchNormalization_595 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3066127711859985668 Time: 0.054528\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3564772625446233998 Time: 0.062592\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5319956359050645452 Time: 0.055456\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7205456024582378848 Time: 0.06624\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 8163473458334948789 Time: 0.064416\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -4212163711445252890 Time: 0.107744\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -3898373634979201110 Time: 0.109088\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -2409163523992614473 Time: 0.064672\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_593 + BatchNormalization_595 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -1716393687483585322 Time: 0.105984\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.054528\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Add_598 (ElementWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Add_598 (ElementWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.009568\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.009568\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Add_598 (ElementWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.005216\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.005216\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: Add_598 (ElementWise)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_605 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_605 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_605 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.006528\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_605 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.004736\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: reshape_before_MatMul_605 (Shuffle)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CudnnConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.047424\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.049344\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 2 Time: 0.118336\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4 Time: 3.67251\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5 Time: 0.560192\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.047424\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 0 Time: 0.020096\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1 Time: 0.020288\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 0 Time: 0.020096\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1062367460111450758 Time: 0.063456\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 1698681053543049347 Time: 0.0696\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 4501471010995462441 Time: 0.11536\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5137655947464784826 Time: 0.068576\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5288347012147084929 Time: 0.114208\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5326823351883942011 Time: 0.113088\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 5500448035057547314 Time: 0.096192\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6645123197870846056 Time: 0.070368\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 7144526460361122478 Time: 0.072\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -8262349710178828730 Time: 0.124\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -6576203419454146580 Time: 0.060992\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -4787320710726427159 Time: 0.07472\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -3456450830548107839 Time: 0.060864\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -1218658103698133241 Time: 0.103968\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -836875257600482091 Time: 0.102272\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -410470605513481746 Time: 0.124512\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -377491875521947884 Time: 0.120832\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -37215280111360163 Time: 0.072736\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: -3456450830548107839 Time: 0.060864\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CublasConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CaskConvolution)\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 3886731678879822788 Time: 0.06016\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: 6629944304117643200 Time: 0.036608\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -9153228964338181824 Time: 0.036768\n",
      "[05/24/2022-15:22:10] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:10] [TRT] [V] Tactic: -7394439838318485025 Time: 0.061856\n",
      "[05/24/2022-15:22:10] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.036608\n",
      "[05/24/2022-15:22:10] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:10] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:10] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CudnnConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.067328\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.054624\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 2 Time: 0.117024\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 3.71098\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.555872\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.054624\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CublasConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.021024\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.020704\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 0.05744\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.0496\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.020704\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CublasConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_605 + BatchNormalization_607 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3066127711859985668 Time: 0.0336\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3564772625446233998 Time: 0.037856\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5319956359050645452 Time: 0.03408\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 7205456024582378848 Time: 0.039776\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 8163473458334948789 Time: 0.038816\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -4212163711445252890 Time: 0.062176\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -3898373634979201110 Time: 0.06288\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -2409163523992614473 Time: 0.039072\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_605 + BatchNormalization_607 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -1716393687483585322 Time: 0.061472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.0336\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1752) [Shuffle] + Reshape_609 + Reshape_613 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.004992\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1752) [Shuffle] + Reshape_609 + Reshape_613 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.00992\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1752) [Shuffle] + Reshape_609 + Reshape_613 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.012544\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.012544\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1752) [Shuffle] + Reshape_609 + Reshape_613 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.004768\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1752) [Shuffle] + Reshape_609 + Reshape_613 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.007424\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_615 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005728\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_615 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.006144\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_615 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.007456\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_615 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_615 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005696\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_617 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.00592\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_617 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.006336\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_617 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_617 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_617 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005664\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_616 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_616 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.006976\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_616 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.01024\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_616 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005888\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_616 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.006304\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_618 (MatrixMultiply)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.007136\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.007136\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_618 (MatrixMultiply)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: onnx::Add_1195 + (Unnamed Layer* 1784) [Shuffle] + Add_622 (Scale)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,1,192,12) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: onnx::Add_1195 + (Unnamed Layer* 1784) [Shuffle] + Add_622 (Scale)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: onnx::Add_1195 + (Unnamed Layer* 1784) [Shuffle] + Add_622 (Scale)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(1536,256:2,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: onnx::Add_1195 + (Unnamed Layer* 1784) [Shuffle] + Add_622 (Scale)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.006272\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1795) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.004576\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.004576\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1795) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Softmax_623 (CudaSoftMax)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1002 Time: 0.025248\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1001 Time: 0.006912\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1001 Time: 0.006912\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Softmax_623 (CudaSoftMax)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1002 Time: 0.02544\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1001 Time: 0.00688\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1001 Time: 0.00688\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Softmax_623 (CaskSoftMax)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CaskSoftMax has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 1001\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1797) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 1797) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_624 (MatrixMultiply)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.007136\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.007136\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_624 (MatrixMultiply)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.014432\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: MatrixMultiply Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,512,32,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_625 + Reshape_629 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.00608\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,1,384,12) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_625 + Reshape_629 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.007584\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(512,512:32,32,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_625 + Reshape_629 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.020224\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.020224\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,512,32,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_625 + Reshape_629 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,512:2,32,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Transpose_625 + Reshape_629 (Shuffle)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.007392\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWiseV2)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 2 Time: 0.005184\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3 Time: 0.005824\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 0.005376\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.005376\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 6 Time: 0.006688\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 7 Time: 0.00608\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 8 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 9 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 28 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 2 Time: 0.005184\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 384 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWiseV2)\n",
      "[05/24/2022-15:22:11] [TRT] [V] PointWiseV2 has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWiseV2)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 24 Time: 0.007136\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 25 Time: 0.00672\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 26 Time: 0.00672\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 27 Time: 0.008\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 31 Time: 0.006912\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 25 Time: 0.00672\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWiseV2)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 2 Time: 0.005184\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3 Time: 0.005824\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.005184\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 6 Time: 0.006912\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 7 Time: 0.006016\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 8 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 9 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 28 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 2 Time: 0.005184\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWiseV2)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 2 Time: 0.005376\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3 Time: 0.006016\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 0.005824\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 6 Time: 0.007136\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 7 Time: 0.00672\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 8 Time: 0.00624\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 9 Time: 0.006464\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 10 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 11 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 12 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 13 Time: 0.006048\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 14 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 15 Time: 0.005376\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 16 Time: 0.007104\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 17 Time: 0.006272\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 18 Time: 0.005856\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 19 Time: 0.005824\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 28 Time: 0.005408\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 29 Time: 0.005632\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 2 Time: 0.005376\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: PWN(PWN(HardSigmoid_630), Mul_631) (PointWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CudnnConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.046368\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.048896\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 2 Time: 0.117984\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 1.91722\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.302368\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.046368\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CublasConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.019808\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.019968\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 0 Time: 0.019808\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1062367460111450758 Time: 0.063936\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1698681053543049347 Time: 0.0696\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4501471010995462441 Time: 0.115136\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5137655947464784826 Time: 0.068576\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5288347012147084929 Time: 0.114432\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5326823351883942011 Time: 0.112896\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5500448035057547314 Time: 0.095008\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 6645123197870846056 Time: 0.07056\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 7144526460361122478 Time: 0.071616\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -8262349710178828730 Time: 0.114944\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -6576203419454146580 Time: 0.05648\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -4787320710726427159 Time: 0.069504\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -3456450830548107839 Time: 0.056768\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -1218658103698133241 Time: 0.09664\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -836875257600482091 Time: 0.094464\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -410470605513481746 Time: 0.11568\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -377491875521947884 Time: 0.112096\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -37215280111360163 Time: 0.067488\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: -6576203419454146580 Time: 0.05648\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CublasConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3886731678879822788 Time: 0.056096\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 6629944304117643200 Time: 0.033696\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -9153228964338181824 Time: 0.034208\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -7394439838318485025 Time: 0.0576\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.033696\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CudnnConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.062304\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.050688\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 2 Time: 0.115904\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 1.91955\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.296768\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.050688\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CublasConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 0 Time: 0.020512\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.020288\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 4 Time: 0.05664\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5 Time: 0.04912\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.020288\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CublasConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: MatMul_632 + BatchNormalization_634 (CaskConvolution)\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3066127711859985668 Time: 0.033312\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 3564772625446233998 Time: 0.03776\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 5319956359050645452 Time: 0.034208\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 7205456024582378848 Time: 0.039456\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 8163473458334948789 Time: 0.038688\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -4212163711445252890 Time: 0.061696\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -3898373634979201110 Time: 0.062176\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -2409163523992614473 Time: 0.038688\n",
      "[05/24/2022-15:22:11] [TRT] [V] MatMul_632 + BatchNormalization_634 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: -1716393687483585322 Time: 0.0608\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.033312\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_637 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005504\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005504\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_637 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.009728\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.009728\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_637 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_637 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005504\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005504\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 768 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_650 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_650 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.009632\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.009632\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_650 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_650 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,1,192,12) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(1536,256:2,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,512,32,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,1,384,12) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(512,512:32,32,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,512,32,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,512:2,32,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 384 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_689 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_689 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.009824\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.009824\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_689 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.00544\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_689 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005728\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005728\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 768 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_702 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_702 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.009632\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.009632\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_702 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_702 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,1,192,12) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(1536,256:2,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,512,32,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,1,384,12) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(512,512:32,32,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,512,32,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,512:2,32,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 384 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_741 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.0056\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_741 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.00976\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.00976\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_741 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005248\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005248\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_741 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 768 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_754 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_754 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.009664\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.009664\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_754 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_754 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(12288,1,1024,16) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(768,768:32,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(6144,768:2,64,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(256,256:32,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,768,64,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12288,1,1024,16) -> Float(6144,1,384,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(768,768:32,64,1) -> Float(512,512:32,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(12288,768,64,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,768:2,64,1) -> Half(3072,512:2,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,1,192,12) -> Float(3072,1,192,12) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(1536,256:2,16,1) -> Half(1536,256:2,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(16,1) -> Float(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(16,1) -> Half(3072,256,16,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(3072,256,16,1), Float(6144,512,32,1) -> Float(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,256,16,1), Half(6144,512,32,1) -> Half(6144,512,32,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,512,32,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,1,384,12) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(512,512:32,32,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,512,32,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(3072,512:2,32,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 384 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_793 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_793 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.009664\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.009664\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_793 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.00528\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] --------------- Timing Runner: Add_793 (ElementWise)\n",
      "[05/24/2022-15:22:11] [TRT] [V] Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] Fastest Tactic: 1 Time: 0.005472\n",
      "[05/24/2022-15:22:11] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1) -> Float(12,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:11] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(12288,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 768 (# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(12288:32,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(12288,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(12288:2,768,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(12288,768,1) -> Float(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(768,1,768,768) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(12288:32,768,1) -> Float(24,1:32,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(12288,768,1) -> Half(768,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(12288:2,768,1) -> Half(384,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(768,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(768,1,768,768) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(768,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1,(* 384 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(12,1:32,1,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1), Float(6144,384,1) -> Float(6144,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Add_806 (ElementWise)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(6144:32,384,1), Float(6144:32,384,1) -> Float(6144:32,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Add_806 (ElementWise)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.0096\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1 Time: 0.0096\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1), Half(6144,384,1) -> Half(6144,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Add_806 (ElementWise)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.005184\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1 Time: 0.005184\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(6144:2,384,1), Half(6144:2,384,1) -> Half(6144:2,384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Add_806 (ElementWise)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1 Time: 0.005408\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(6144,384,1) -> Float(384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: ReduceMean_807 (Reduce)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 7 Time: 0.006496\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 8 Time: 0.006496\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 7 Time: 0.006496\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 7\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(6144,384,1) -> Half(384,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: ReduceMean_807 (Reduce)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 7 Time: 0.006496\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 8 Time: 0.006496\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 7 Time: 0.006496\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 7\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 2349) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: (Unnamed Layer* 2349) [Shuffle] (Shuffle)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 0 Time: 0.004512\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: BatchNormalization_808 (Scale)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 0 Time: 0.005856\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: BatchNormalization_808 (Scale)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Scale has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: BatchNormalization_808 (Scale)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 0 Time: 0.005824\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: BatchNormalization_808 (Scale)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 0 Time: 0.006048\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(384,1,384,384) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(384,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(192,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CudnnConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.042464\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.013184\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 2 Time: 0.11136\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 4 Time: 3.32797\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5 Time: 0.464416\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1 Time: 0.013184\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CublasConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.012704\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.01376\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 0 Time: 0.012704\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CaskConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1062367460111450758 Time: 0.063264\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1698681053543049347 Time: 0.051744\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 4501471010995462441 Time: 0.106752\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5137655947464784826 Time: 0.065152\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5288347012147084929 Time: 0.105152\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5326823351883942011 Time: 0.10384\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5500448035057547314 Time: 0.072192\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 6645123197870846056 Time: 0.068736\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 7144526460361122478 Time: 0.052864\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -8262349710178828730 Time: 0.106336\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -6576203419454146580 Time: 0.052128\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -4787320710726427159 Time: 0.053568\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -3456450830548107839 Time: 0.055264\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -1218658103698133241 Time: 0.074816\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -836875257600482091 Time: 0.073536\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -410470605513481746 Time: 0.106048\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -377491875521947884 Time: 0.103232\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -37215280111360163 Time: 0.063616\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1698681053543049347 Time: 0.051744\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384) -> Float(1000,1,1000,1000) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CublasConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CaskConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 3886731678879822788 Time: 0.055808\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 6629944304117643200 Time: 0.033824\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -9153228964338181824 Time: 0.033984\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -7394439838318485025 Time: 0.057184\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.033824\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CudnnConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.057344\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.043008\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 2 Time: 0.109184\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 4 Time: 3.3224\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5 Time: 0.46016\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1 Time: 0.043008\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CublasConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.01968\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.018656\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 4 Time: 0.01552\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5 Time: 0.050144\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 4 Time: 0.01552\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CaskConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 4\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CaskConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1) -> Half(500,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CublasConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] (CaskConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 3066127711859985668 Time: 0.030752\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 3564772625446233998 Time: 0.037024\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5319956359050645452 Time: 0.032672\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 7205456024582378848 Time: 0.038048\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 8163473458334948789 Time: 0.03536\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -4212163711445252890 Time: 0.056928\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -3898373634979201110 Time: 0.057856\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -2409163523992614473 Time: 0.036064\n",
      "[05/24/2022-15:22:12] [TRT] [V] Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: -1716393687483585322 Time: 0.056064\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.030752\n",
      "[05/24/2022-15:22:12] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:12] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:12] [TRT] [V] *************** Autotuning format combination: Float(384,1,1,1), Float(1000,1,1,1) -> Float(1000,1,1,1) ***************\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CudaDepthwiseConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CudnnConvolution)\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 0 Time: 0.045728\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 1 Time: 0.016448\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 2 Time: 0.114784\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 4 Time: 3.33123\n",
      "[05/24/2022-15:22:12] [TRT] [V] Tactic: 5 Time: 0.464864\n",
      "[05/24/2022-15:22:12] [TRT] [V] Fastest Tactic: 1 Time: 0.016448\n",
      "[05/24/2022-15:22:12] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CublasConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 1 Time: 0.013984\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 0 Time: 0.01264\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CaskConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 1062367460111450758 Time: 0.064352\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 1698681053543049347 Time: 0.05216\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 4501471010995462441 Time: 0.10832\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 5137655947464784826 Time: 0.065984\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 5288347012147084929 Time: 0.10688\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 5326823351883942011 Time: 0.10576\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 5500448035057547314 Time: 0.073056\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 6645123197870846056 Time: 0.069888\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 7144526460361122478 Time: 0.053312\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -8262349710178828730 Time: 0.108224\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -6576203419454146580 Time: 0.053024\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -4787320710726427159 Time: 0.056704\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -3456450830548107839 Time: 0.055232\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -1218658103698133241 Time: 0.075392\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -836875257600482091 Time: 0.074528\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -410470605513481746 Time: 0.107552\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -377491875521947884 Time: 0.104256\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -37215280111360163 Time: 0.064448\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 1698681053543049347 Time: 0.05216\n",
      "[05/24/2022-15:22:13] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0\n",
      "[05/24/2022-15:22:13] [TRT] [V] *************** Autotuning format combination: Float(384,1,384,384), Float(1000,1,1000,1000) -> Float(1000,1,1000,1000) ***************\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CublasConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CaskConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 3886731678879822788 Time: 0.056736\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 6629944304117643200 Time: 0.034336\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -9153228964338181824 Time: 0.034592\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -7394439838318485025 Time: 0.058016\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 6629944304117643200 Time: 0.034336\n",
      "[05/24/2022-15:22:13] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200\n",
      "[05/24/2022-15:22:13] [TRT] [V] *************** Autotuning format combination: Half(384,1,1,1), Half(1000,1,1,1) -> Half(1000,1,1,1) ***************\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CudnnConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 0 Time: 0.060128\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 1 Time: 0.045888\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 2 Time: 0.112032\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 4 Time: 3.3264\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 5 Time: 0.460576\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 1 Time: 0.045888\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CublasConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 0 Time: 0.019616\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 1 Time: 0.018816\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 4 Time: 0.015424\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 5 Time: 0.050144\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 4 Time: 0.015424\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CaskConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:13] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 4\n",
      "[05/24/2022-15:22:13] [TRT] [V] *************** Autotuning format combination: Half(192,1:2,1,1), Half(500,1:2,1,1) -> Half(500,1:2,1,1) ***************\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (FusedConvActConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CublasConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 (CaskConvolution)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 3066127711859985668 Time: 0.031296\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 3564772625446233998 Time: 0.03744\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 5319956359050645452 Time: 0.033088\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 7205456024582378848 Time: 0.038496\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 8163473458334948789 Time: 0.035808\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -4212163711445252890 Time: 0.057408\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -3898373634979201110 Time: 0.058304\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -2409163523992614473 Time: 0.036736\n",
      "[05/24/2022-15:22:13] [TRT] [V] Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: -1716393687483585322 Time: 0.056896\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 3066127711859985668 Time: 0.031296\n",
      "[05/24/2022-15:22:13] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668\n",
      "[05/24/2022-15:22:13] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:13] [TRT] [V] *************** Autotuning format combination: Float(1000,1,1,1) -> Float(1000,1) ***************\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: copied_squeeze_after_Add_812 (Shuffle)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 0 Time: 0.004608\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 0 Time: 0.004608\n",
      "[05/24/2022-15:22:13] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:13] [TRT] [V] *************** Autotuning format combination: Half(1000,1,1,1) -> Half(1000,1) ***************\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: copied_squeeze_after_Add_812 (Shuffle)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 0 Time: 0.004608\n",
      "[05/24/2022-15:22:13] [TRT] [V] Fastest Tactic: 0 Time: 0.004608\n",
      "[05/24/2022-15:22:13] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[05/24/2022-15:22:13] [TRT] [V] =============== Computing costs for \n",
      "[05/24/2022-15:22:13] [TRT] [V] *************** Autotuning format combination: Float(1000,1) -> Float(1000,1) ***************\n",
      "[05/24/2022-15:22:13] [TRT] [V] --------------- Timing Runner: PWN(onnx::Div_1428 + (Unnamed Layer* 2374) [Shuffle], Div_814) (PointWiseV2)\n",
      "[05/24/2022-15:22:13] [TRT] [V] Tactic: 0 Time: 0.005216\n",
      "[05/24/2022-15:22:14] [TRT] [V] Tactic: 1 Time: 0.0056\n",
      "[05/24/2022-15:22:14] [TRT] [V] Tactic: 2 Time: 0.0056\n",
      "[05/24/2022-15:22:14] [TRT] [V] Tactic: 3 Time: 0.006464\n",
      "[05/24/2022-15:22:14] [TRT] [V] Tactic: 4 Time: 0.006304\n",
      "[05/24/2022-15:22:15] [TRT] [V] Tactic: 5 Time: 0.00624\n",
      "[05/24/2022-15:22:15] [TRT] [V] Tactic: 6 Time: 0.008192\n",
      "[05/24/2022-15:22:15] [TRT] [V] Tactic: 7 Time: 0.008\n",
      "[05/24/2022-15:22:15] [TRT] [V] Tactic: 8 Time: 0.007424\n",
      "[05/24/2022-15:22:16] [TRT] [V] Tactic: 9 Time: 0.007744\n",
      "[05/24/2022-15:22:16] [TRT] [V] Tactic: 28 Time: 0.005184\n",
      "[05/24/2022-15:22:16] [TRT] [V] Fastest Tactic: 28 Time: 0.005184\n",
      "[05/24/2022-15:22:16] [TRT] [V] --------------- Timing Runner: PWN(onnx::Div_1428 + (Unnamed Layer* 2374) [Shuffle], Div_814) (PointWise)\n",
      "[05/24/2022-15:22:16] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:16] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28\n",
      "[05/24/2022-15:22:16] [TRT] [V] *************** Autotuning format combination: Half(1000,1) -> Half(1000,1) ***************\n",
      "[05/24/2022-15:22:16] [TRT] [V] --------------- Timing Runner: PWN(onnx::Div_1428 + (Unnamed Layer* 2374) [Shuffle], Div_814) (PointWiseV2)\n",
      "[05/24/2022-15:22:16] [TRT] [V] Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:16] [TRT] [V] Tactic: 1 Time: 0.005664\n",
      "[05/24/2022-15:22:17] [TRT] [V] Tactic: 2 Time: 0.005632\n",
      "[05/24/2022-15:22:17] [TRT] [V] Tactic: 3 Time: 0.006496\n",
      "[05/24/2022-15:22:17] [TRT] [V] Tactic: 4 Time: 0.006496\n",
      "[05/24/2022-15:22:17] [TRT] [V] Tactic: 5 Time: 0.006272\n",
      "[05/24/2022-15:22:18] [TRT] [V] Tactic: 6 Time: 0.008192\n",
      "[05/24/2022-15:22:18] [TRT] [V] Tactic: 7 Time: 0.007968\n",
      "[05/24/2022-15:22:18] [TRT] [V] Tactic: 8 Time: 0.007328\n",
      "[05/24/2022-15:22:18] [TRT] [V] Tactic: 9 Time: 0.007744\n",
      "[05/24/2022-15:22:19] [TRT] [V] Tactic: 28 Time: 0.005184\n",
      "[05/24/2022-15:22:19] [TRT] [V] Fastest Tactic: 0 Time: 0.005184\n",
      "[05/24/2022-15:22:19] [TRT] [V] --------------- Timing Runner: PWN(onnx::Div_1428 + (Unnamed Layer* 2374) [Shuffle], Div_814) (PointWise)\n",
      "[05/24/2022-15:22:19] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[05/24/2022-15:22:19] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to Conv_0 (input) from Float(150528,50176,224,1) to Half(100352,50176:2,224,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to Reshape_17 + Transpose_18 (onnx::Shape_1439) from Half(12544,196:2,14,1) to Float(25088,196,14,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to BatchNormalization_27 ((Unnamed Layer* 38) [Shuffle]_output) from Float(256,1,1,1) to Half(128,1:2,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 ((Unnamed Layer* 39) [Scale]_output) from Half(128,1:2,1,1) to Half(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to reshape_before_MatMul_52 (onnx::MatMul_479) from Half(25088,128,1) to Float(25088,128,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_58 + BatchNormalization_60 (reshape_before_MatMul_58_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 137) [Shuffle] + Reshape_62 ((Unnamed Layer* 136) [Scale]_output) from Float(256,1,256,256) to Float(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_77 + BatchNormalization_79 (reshape_before_MatMul_77_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85 ((Unnamed Layer* 189) [Scale]_output) from Float(256,1,256,256) to Float(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Output Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85 (onnx::Split_521) from Float(50176,256,64,1) to Half(50176,256,64,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to reshape_before_MatMul_104 (onnx::MatMul_543) from Half(25088,128,1) to Float(25088,128,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_110 + BatchNormalization_112 (reshape_before_MatMul_110_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 287) [Shuffle] + Reshape_114 ((Unnamed Layer* 286) [Scale]_output) from Float(256,1,256,256) to Float(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_129 + BatchNormalization_131 (reshape_before_MatMul_129_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137 ((Unnamed Layer* 339) [Scale]_output) from Float(256,1,256,256) to Float(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Output Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137 (onnx::Split_585) from Float(50176,256,64,1) to Half(50176,256,64,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to reshape_before_MatMul_156 (onnx::MatMul_607) from Half(25088,128,1) to Float(25088,128,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_162 + BatchNormalization_164 (reshape_before_MatMul_162_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 437) [Shuffle] + Reshape_166 ((Unnamed Layer* 436) [Scale]_output) from Float(256,1,256,256) to Float(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_181 + BatchNormalization_183 (reshape_before_MatMul_181_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189 ((Unnamed Layer* 489) [Scale]_output) from Float(256,1,256,256) to Float(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Output Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189 (onnx::Split_649) from Float(50176,256,64,1) to Half(50176,256,64,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to reshape_before_MatMul_208 (onnx::MatMul_671) from Half(25088,128,1) to Float(25088,128,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_214 + BatchNormalization_216 (reshape_before_MatMul_214_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 587) [Shuffle] + Reshape_218 ((Unnamed Layer* 586) [Scale]_output) from Float(256,1,256,256) to Float(256,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_233 + BatchNormalization_235 (reshape_before_MatMul_233_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)\n",
      "[05/24/2022-15:22:19] [TRT] [V] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 ((Unnamed Layer* 639) [Scale]_output) from Float(640,1,640,640) to Float(640,1,1,1)\n",
      "[05/24/2022-15:22:19] [TRT] [V] For layer Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Set BuilderFlag::kPREFER_PRECISION_CONSTRAINTS to encourage choosing a conforming implementation, or set BuilderFlag::kOBEY_PRECISION_CONSTRAINTS to require choosing a conforming implementation.\n",
      "[05/24/2022-15:22:19] [TRT] [V] For layer Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Set BuilderFlag::kPREFER_PRECISION_CONSTRAINTS to encourage choosing a conforming implementation, or set BuilderFlag::kOBEY_PRECISION_CONSTRAINTS to require choosing a conforming implementation.\n",
      "[05/24/2022-15:22:19] [TRT] [V] Formats and tactics selection completed in 43.8649 seconds.\n",
      "[05/24/2022-15:22:19] [TRT] [V] After reformat layers: 427 layers\n",
      "[05/24/2022-15:22:19] [TRT] [V] Pre-optimized block assignment.\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 6422528\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 6422528\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 8028160\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 6422528\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1229312\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4014080\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 3211264\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 458752\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 262144\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 262144\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 262144\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 262144\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 802816\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1048576\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1048576\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1048576\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 196608\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 786432\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 393216\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 24576\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 24576\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 24576\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 64000\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 64000\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 6422528\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4\n",
      "[05/24/2022-15:22:19] [TRT] [V] Block size 4294967296\n",
      "[05/24/2022-15:22:19] [TRT] [V] Total Activation Memory: 4634584724\n",
      "[05/24/2022-15:22:19] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[05/24/2022-15:22:19] [TRT] [V] Conv_0 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:19] [TRT] [V] Conv_3 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:19] [TRT] [V] Conv_6 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:19] [TRT] [V] Conv_9 Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_58 + BatchNormalization_60 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_77 + BatchNormalization_79 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_110 + BatchNormalization_112 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_129 + BatchNormalization_131 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_162 + BatchNormalization_164 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_181 + BatchNormalization_183 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_214 + BatchNormalization_216 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[05/24/2022-15:22:19] [TRT] [V] MatMul_233 + BatchNormalization_235 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::MatMul_1442 + (Unnamed Layer* 23) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::MatMul_1476 + (Unnamed Layer* 733) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::MatMul_1483 + (Unnamed Layer* 815) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::MatMul_1519 + (Unnamed Layer* 1597) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::MatMul_1526 + (Unnamed Layer* 1679) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_0 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Conv_0 Host Persistent: 1664 Device Persistent: 75776 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_1), Mul_2) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Conv_3 Host Persistent: 1664 Device Persistent: 18944 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_4), Mul_5) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Conv_6 Host Persistent: 1664 Device Persistent: 5120 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_7), Mul_8) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Conv_9 Host Persistent: 1664 Device Persistent: 1536 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to Reshape_17 + Transpose_18 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reshape_17 + Transpose_18 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_25 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Flatten_26 + (Unnamed Layer* 38) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to BatchNormalization_27 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: BatchNormalization_27 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_35 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_37 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_36 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_38 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_467 + (Unnamed Layer* 72) [Shuffle] + Add_42 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 83) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_43 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 85) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_44 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_45 + Reshape_49 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_50), Mul_51) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_52 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_52 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_52 + BatchNormalization_54 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 114) [Shuffle] + Reshape_56 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_57 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_58 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_58 + BatchNormalization_60 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_58 + BatchNormalization_60 Host Persistent: 1664 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 137) [Shuffle] + Reshape_62 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 137) [Shuffle] + Reshape_62 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_63), Mul_64) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_65 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_65 + BatchNormalization_67 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 161) [Shuffle] + Reshape_69 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_70 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_77 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_77 + BatchNormalization_79 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_77 + BatchNormalization_79 Host Persistent: 1664 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Output Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_87 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_89 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_88 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_90 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_531 + (Unnamed Layer* 222) [Shuffle] + Add_94 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 233) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_95 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 235) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_96 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_97 + Reshape_101 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_102), Mul_103) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_104 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_104 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_104 + BatchNormalization_106 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 264) [Shuffle] + Reshape_108 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_109 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_110 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_110 + BatchNormalization_112 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_110 + BatchNormalization_112 Host Persistent: 1664 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 287) [Shuffle] + Reshape_114 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 287) [Shuffle] + Reshape_114 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_115), Mul_116) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_117 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_117 + BatchNormalization_119 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 311) [Shuffle] + Reshape_121 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_122 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_129 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_129 + BatchNormalization_131 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_129 + BatchNormalization_131 Host Persistent: 1664 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Output Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_139 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_141 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_140 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_142 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_595 + (Unnamed Layer* 372) [Shuffle] + Add_146 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 383) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_147 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 385) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_148 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_149 + Reshape_153 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_154), Mul_155) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_156 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_156 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_156 + BatchNormalization_158 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 414) [Shuffle] + Reshape_160 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_161 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_162 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_162 + BatchNormalization_164 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_162 + BatchNormalization_164 Host Persistent: 1664 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 437) [Shuffle] + Reshape_166 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 437) [Shuffle] + Reshape_166 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_167), Mul_168) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_169 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_169 + BatchNormalization_171 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 461) [Shuffle] + Reshape_173 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_174 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_181 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_181 + BatchNormalization_183 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_181 + BatchNormalization_183 Host Persistent: 1664 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Output Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_191 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_193 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_192 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_194 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_659 + (Unnamed Layer* 522) [Shuffle] + Add_198 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 533) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_199 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 535) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_200 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_201 + Reshape_205 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_206), Mul_207) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_208 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_208 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_208 + BatchNormalization_210 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 564) [Shuffle] + Reshape_212 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_213 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_214 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_214 + BatchNormalization_216 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_214 + BatchNormalization_216 Host Persistent: 1664 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 587) [Shuffle] + Reshape_218 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 587) [Shuffle] + Reshape_218 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_219), Mul_220) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_221 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_221 + BatchNormalization_223 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 611) [Shuffle] + Reshape_225 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_226 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_233 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_233 + BatchNormalization_235 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_233 + BatchNormalization_235 Host Persistent: 3200 Device Persistent: 512 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reshape_253 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Slice_258 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_277 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_243 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Slice_263 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reshape_267 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_268 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Flatten_269 + (Unnamed Layer* 748) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: BatchNormalization_270 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 + Transpose_276 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_278 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_767 + (Unnamed Layer* 767) [Shuffle] + Add_282 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 778) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_283 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 780) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_284 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_285 + Reshape_288 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_289), Mul_290) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_291 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_291 + BatchNormalization_293 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 810) [Shuffle] + Reshape_295 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_296 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Flatten_297 + (Unnamed Layer* 831) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: BatchNormalization_298 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 833) [Shuffle] + Reshape_300 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_301), Mul_302) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_303 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_303 + BatchNormalization_305 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 858) [Shuffle] + Reshape_307 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_308 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_315 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_315 + BatchNormalization_317 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 888) [Shuffle] + Reshape_319 + Reshape_323 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_325 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_327 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_326 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_328 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_831 + (Unnamed Layer* 920) [Shuffle] + Add_332 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 931) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_333 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 933) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_334 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_335 + Reshape_339 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_340), Mul_341) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_342 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_342 + BatchNormalization_344 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 963) [Shuffle] + Reshape_346 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_347 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_348 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_348 + BatchNormalization_350 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 987) [Shuffle] + Reshape_352 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_353), Mul_354) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_355 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_355 + BatchNormalization_357 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1012) [Shuffle] + Reshape_359 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_360 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_367 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_367 + BatchNormalization_369 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1042) [Shuffle] + Reshape_371 + Reshape_375 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_377 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_379 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_378 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_380 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_895 + (Unnamed Layer* 1074) [Shuffle] + Add_384 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1085) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_385 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1087) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_386 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_387 + Reshape_391 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_392), Mul_393) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_394 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_394 + BatchNormalization_396 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1117) [Shuffle] + Reshape_398 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_399 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_400 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_400 + BatchNormalization_402 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1141) [Shuffle] + Reshape_404 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_405), Mul_406) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_407 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_407 + BatchNormalization_409 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1166) [Shuffle] + Reshape_411 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_412 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_419 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_419 + BatchNormalization_421 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1196) [Shuffle] + Reshape_423 + Reshape_427 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_429 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_431 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_430 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_432 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_959 + (Unnamed Layer* 1228) [Shuffle] + Add_436 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1239) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_437 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1241) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_438 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_439 + Reshape_443 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_444), Mul_445) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_446 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_446 + BatchNormalization_448 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1271) [Shuffle] + Reshape_450 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_451 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_452 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_452 + BatchNormalization_454 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1295) [Shuffle] + Reshape_456 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_457), Mul_458) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_459 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_459 + BatchNormalization_461 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1320) [Shuffle] + Reshape_463 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_464 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_471 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_471 + BatchNormalization_473 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1350) [Shuffle] + Reshape_475 + Reshape_479 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_481 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_483 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_482 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_484 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_1023 + (Unnamed Layer* 1382) [Shuffle] + Add_488 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1393) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_489 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1395) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_490 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_491 + Reshape_495 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_496), Mul_497) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_498 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_498 + BatchNormalization_500 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1425) [Shuffle] + Reshape_502 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_503 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_504 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_504 + BatchNormalization_506 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1449) [Shuffle] + Reshape_508 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_509), Mul_510) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_511 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_511 + BatchNormalization_513 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1474) [Shuffle] + Reshape_515 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_516 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_523 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_523 + BatchNormalization_525 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reshape_543 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1504) [Shuffle] + Reshape_527 + Reshape_531 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Slice_548 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_567 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_533 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Slice_553 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Reshape_557 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_558 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Flatten_559 + (Unnamed Layer* 1612) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: BatchNormalization_560 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 + Transpose_566 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_568 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_1131 + (Unnamed Layer* 1631) [Shuffle] + Add_572 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1642) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_573 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1644) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_574 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_575 + Reshape_578 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_579), Mul_580) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_581 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_581 + BatchNormalization_583 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1674) [Shuffle] + Reshape_585 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_586 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Flatten_587 + (Unnamed Layer* 1695) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: BatchNormalization_588 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1697) [Shuffle] + Reshape_590 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_591), Mul_592) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_593 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_593 + BatchNormalization_595 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1722) [Shuffle] + Reshape_597 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_598 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_605 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_605 + BatchNormalization_607 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1752) [Shuffle] + Reshape_609 + Reshape_613 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_615 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_617 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_616 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_618 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_1195 + (Unnamed Layer* 1784) [Shuffle] + Add_622 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1795) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_623 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1797) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_624 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_625 + Reshape_629 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_630), Mul_631) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_632 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_632 + BatchNormalization_634 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1827) [Shuffle] + Reshape_636 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_637 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_638 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_638 + BatchNormalization_640 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1851) [Shuffle] + Reshape_642 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_643), Mul_644) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_645 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_645 + BatchNormalization_647 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1876) [Shuffle] + Reshape_649 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_650 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_657 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_657 + BatchNormalization_659 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1906) [Shuffle] + Reshape_661 + Reshape_665 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_667 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_669 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_668 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_670 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: onnx::Add_1259 + (Unnamed Layer* 1938) [Shuffle] + Add_674 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1949) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Softmax_675 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1951) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_676 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_677 + Reshape_681 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_682), Mul_683) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_684 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_684 + BatchNormalization_686 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 1981) [Shuffle] + Reshape_688 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_689 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_690 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_690 + BatchNormalization_692 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 2005) [Shuffle] + Reshape_694 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: PWN(PWN(HardSigmoid_695), Mul_696) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_697 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_697 + BatchNormalization_699 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 2030) [Shuffle] + Reshape_701 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Add_702 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: reshape_before_MatMul_709 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: MatMul_709 + BatchNormalization_711 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: (Unnamed Layer* 2060) [Shuffle] + Reshape_713 + Reshape_717 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:19] [TRT] [V] Layer: Transpose_719 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Transpose_721 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Transpose_720 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_722 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: onnx::Add_1323 + (Unnamed Layer* 2092) [Shuffle] + Add_726 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2103) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Softmax_727 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2105) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_728 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Transpose_729 + Reshape_733 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: PWN(PWN(HardSigmoid_734), Mul_735) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: reshape_before_MatMul_736 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_736 + BatchNormalization_738 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2135) [Shuffle] + Reshape_740 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Add_741 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: reshape_before_MatMul_742 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_742 + BatchNormalization_744 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2159) [Shuffle] + Reshape_746 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: PWN(PWN(HardSigmoid_747), Mul_748) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: reshape_before_MatMul_749 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_749 + BatchNormalization_751 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2184) [Shuffle] + Reshape_753 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Add_754 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: reshape_before_MatMul_761 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_761 + BatchNormalization_763 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2214) [Shuffle] + Reshape_765 + Reshape_769 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Transpose_771 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Transpose_773 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Transpose_772 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_774 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: onnx::Add_1387 + (Unnamed Layer* 2246) [Shuffle] + Add_778 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2257) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Softmax_779 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2259) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_780 Host Persistent: 204 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Transpose_781 + Reshape_785 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: PWN(PWN(HardSigmoid_786), Mul_787) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: reshape_before_MatMul_788 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_788 + BatchNormalization_790 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2289) [Shuffle] + Reshape_792 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Add_793 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: reshape_before_MatMul_794 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_794 + BatchNormalization_796 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2313) [Shuffle] + Reshape_798 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: PWN(PWN(HardSigmoid_799), Mul_800) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: reshape_before_MatMul_801 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: MatMul_801 + BatchNormalization_803 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2338) [Shuffle] + Reshape_805 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Add_806 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: ReduceMean_807 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: (Unnamed Layer* 2349) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: BatchNormalization_808 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: BatchNormalization_810 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise] Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812 Host Persistent: 436 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: copied_squeeze_after_Add_812 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [V] Layer: PWN(onnx::Div_1428 + (Unnamed Layer* 2374) [Shuffle], Div_814) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [I] Total Host Persistent Memory: 53200\n",
      "[05/24/2022-15:22:20] [TRT] [I] Total Device Persistent Memory: 105472\n",
      "[05/24/2022-15:22:20] [TRT] [I] Total Scratch Memory: 0\n",
      "[05/24/2022-15:22:20] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 59 MiB, GPU 2222 MiB\n",
      "[05/24/2022-15:22:20] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 287.919ms to assign 6 blocks to 421 nodes requiring 21776384 bytes.\n",
      "[05/24/2022-15:22:20] [TRT] [V] Optimized block assignment.\n",
      "[05/24/2022-15:22:20] [TRT] [V] Block size 8028160\n",
      "[05/24/2022-15:22:20] [TRT] [V] Block size 6422528\n",
      "[05/24/2022-15:22:20] [TRT] [V] Block size 4917248\n",
      "[05/24/2022-15:22:20] [TRT] [V] Block size 1605632\n",
      "[05/24/2022-15:22:20] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:20] [TRT] [V] Block size 401408\n",
      "[05/24/2022-15:22:20] [TRT] [I] Total Activation Memory: 21776384\n",
      "[05/24/2022-15:22:20] [TRT] [V] Disabling unused tactic source: CUDNN\n",
      "[05/24/2022-15:22:20] [TRT] [V] Using cublas as a tactic source\n",
      "[05/24/2022-15:22:20] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.8.0 but loaded cuBLAS/cuBLAS LT 11.5.1\n",
      "[05/24/2022-15:22:20] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 4171, GPU 1231 (MiB)\n",
      "[05/24/2022-15:22:20] [TRT] [V] Engine generation completed in 46.1406 seconds.\n",
      "[05/24/2022-15:22:20] [TRT] [V] Deleting timing cache: 1683 entries, served 7389 hits since creation.\n",
      "[05/24/2022-15:22:20] [TRT] [V] Engine Layer Information:\n",
      "Layer(Constant): onnx::MatMul_1442 + (Unnamed Layer* 23) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 23) [Shuffle]_output[Float(1,128,256)]\n",
      "Layer(Constant): onnx::MatMul_1476 + (Unnamed Layer* 733) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 733) [Shuffle]_output[Float(1,128,128)]\n",
      "Layer(Constant): onnx::MatMul_1483 + (Unnamed Layer* 815) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 815) [Shuffle]_output[Float(1,256,512)]\n",
      "Layer(Constant): onnx::MatMul_1519 + (Unnamed Layer* 1597) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 1597) [Shuffle]_output[Float(1,256,256)]\n",
      "Layer(Constant): onnx::MatMul_1526 + (Unnamed Layer* 1679) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 1679) [Shuffle]_output[Float(1,384,768)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_0, Tactic: 0, input[Float(-13,3,224,224)] -> Reformatted Input Tensor 0 to Conv_0[Half(-13,3,224,224)]\n",
      "Layer(CaskConvolution): Conv_0, Tactic: 5319956359050645452, Reformatted Input Tensor 0 to Conv_0[Half(-13,3,224,224)] -> input.4[Half(-13,16,112,112)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_1), Mul_2), Tactic: 8, input.4[Half(-13,16,112,112)] -> input.8[Half(-13,16,112,112)]\n",
      "Layer(CaskConvolution): Conv_3, Tactic: 5319956359050645452, input.8[Half(-13,16,112,112)] -> input.16[Half(-13,32,56,56)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_4), Mul_5), Tactic: 8, input.16[Half(-13,32,56,56)] -> input.20[Half(-13,32,56,56)]\n",
      "Layer(CaskConvolution): Conv_6, Tactic: 5319956359050645452, input.20[Half(-13,32,56,56)] -> input.28[Half(-13,64,28,28)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_7), Mul_8), Tactic: 4, input.28[Half(-13,64,28,28)] -> input.32[Half(-13,64,28,28)]\n",
      "Layer(CaskConvolution): Conv_9, Tactic: 5319956359050645452, input.32[Half(-13,64,28,28)] -> onnx::Shape_1439[Half(-13,128,14,14)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Reshape_17 + Transpose_18, Tactic: 0, onnx::Shape_1439[Half(-13,128,14,14)] -> Reformatted Input Tensor 0 to Reshape_17 + Transpose_18[Float(-13,128,14,14)]\n",
      "Layer(Shuffle): Reshape_17 + Transpose_18, Tactic: 0, Reformatted Input Tensor 0 to Reshape_17 + Transpose_18[Float(-13,128,14,14)] -> onnx::Shape_437[Float(-13,196,128)]\n",
      "Layer(MatrixMultiply): MatMul_25, Tactic: 0, onnx::Shape_437[Float(-13,196,128)], (Unnamed Layer* 23) [Shuffle]_output[Float(1,128,256)] -> onnx::Flatten_445[Float(-13,196,256)]\n",
      "Layer(NoOp): Flatten_26 + (Unnamed Layer* 38) [Shuffle], Tactic: 0, onnx::Flatten_445[Float(-13,196,256)] -> (Unnamed Layer* 38) [Shuffle]_output[Float(-22,256,1,1)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to BatchNormalization_27, Tactic: 0, (Unnamed Layer* 38) [Shuffle]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to BatchNormalization_27[Half(-22,256,1,1)]\n",
      "Layer(Scale): BatchNormalization_27, Tactic: 0, Reformatted Input Tensor 0 to BatchNormalization_27[Half(-22,256,1,1)] -> (Unnamed Layer* 39) [Scale]_output[Half(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33, Tactic: 0, (Unnamed Layer* 39) [Scale]_output[Half(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33[Half(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 40) [Shuffle] + Reshape_29 + Reshape_33[Half(-22,256,1,1)] -> onnx::Split_457[Half(-13,196,4,64)]\n",
      "Layer(Shuffle): Transpose_35, Tactic: 0, onnx::Split_457[Half(-13,196,4,16)] -> onnx::MatMul_461[Half(-13,4,196,16)]\n",
      "Layer(Shuffle): Transpose_37, Tactic: 0, onnx::Split_457[Half(-13,196,4,16)] -> onnx::MatMul_463[Half(-13,4,16,196)]\n",
      "Layer(Shuffle): Transpose_36, Tactic: 0, onnx::Split_457[Half(-13,196,4,32)] -> onnx::MatMul_462[Half(-13,4,196,32)]\n",
      "Layer(MatrixMultiply): MatMul_38, Tactic: 0, onnx::MatMul_461[Half(-13,4,196,16)], onnx::MatMul_463[Half(-13,4,16,196)] -> onnx::Add_466[Half(-13,4,196,196)]\n",
      "Layer(Scale): onnx::Add_467 + (Unnamed Layer* 72) [Shuffle] + Add_42, Tactic: 0, onnx::Add_466[Half(-13,4,196,196)] -> onnx::Softmax_468[Half(-13,4,196,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 83) [Shuffle], Tactic: 0, onnx::Softmax_468[Half(-13,4,196,196)] -> (Unnamed Layer* 83) [Shuffle]_output[Half(-21,196)]\n",
      "Layer(CudaSoftMax): Softmax_43, Tactic: 1001, (Unnamed Layer* 83) [Shuffle]_output[Half(-21,196)] -> (Unnamed Layer* 84) [Softmax]_output[Half(-21,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 85) [Shuffle], Tactic: 0, (Unnamed Layer* 84) [Softmax]_output[Half(-21,196)] -> onnx::MatMul_469[Half(-13,4,196,196)]\n",
      "Layer(MatrixMultiply): MatMul_44, Tactic: 0, onnx::MatMul_469[Half(-13,4,196,196)], onnx::MatMul_462[Half(-13,4,196,32)] -> onnx::Transpose_470[Half(-13,4,196,32)]\n",
      "Layer(Shuffle): Transpose_45 + Reshape_49, Tactic: 0, onnx::Transpose_470[Half(-13,4,196,32)] -> input.44[Half(-13,196,128)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_50), Mul_51), Tactic: 8, input.44[Half(-13,196,128)] -> onnx::MatMul_479[Half(-13,196,128)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_52, Tactic: 0, onnx::MatMul_479[Half(-13,196,128)] -> Reformatted Input Tensor 0 to reshape_before_MatMul_52[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_52, Tactic: 0, Reformatted Input Tensor 0 to reshape_before_MatMul_52[Float(-13,196,128)] -> reshape_before_MatMul_52_out_region[Float(-22,128,1,1)]\n",
      "Layer(CublasConvolution): MatMul_52 + BatchNormalization_54, Tactic: 0, reshape_before_MatMul_52_out_region[Float(-22,128,1,1)] -> (Unnamed Layer* 113) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 114) [Shuffle] + Reshape_56, Tactic: 0, (Unnamed Layer* 113) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_485[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_57, Tactic: 1, onnx::Shape_437[Float(-13,196,128)], onnx::Add_485[Float(-13,196,128)] -> onnx::MatMul_486[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_58, Tactic: 0, onnx::MatMul_486[Float(-13,196,128)] -> reshape_before_MatMul_58_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_58 + BatchNormalization_60, Tactic: 0, reshape_before_MatMul_58_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_58 + BatchNormalization_60[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_58 + BatchNormalization_60, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to MatMul_58 + BatchNormalization_60[Float(-22,128,1,1)] -> (Unnamed Layer* 136) [Scale]_output[Float(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 137) [Shuffle] + Reshape_62, Tactic: 0, (Unnamed Layer* 136) [Scale]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 137) [Shuffle] + Reshape_62[Float(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 137) [Shuffle] + Reshape_62, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 137) [Shuffle] + Reshape_62[Float(-22,256,1,1)] -> input.56[Float(-13,196,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_63), Mul_64), Tactic: 8, input.56[Float(-13,196,256)] -> onnx::MatMul_494[Float(-13,196,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_65, Tactic: 0, onnx::MatMul_494[Float(-13,196,256)] -> reshape_before_MatMul_65_out_region[Float(-22,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_65 + BatchNormalization_67, Tactic: 1, reshape_before_MatMul_65_out_region[Float(-22,256,1,1)] -> (Unnamed Layer* 160) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 161) [Shuffle] + Reshape_69, Tactic: 0, (Unnamed Layer* 160) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_500[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_70, Tactic: 1, onnx::MatMul_486[Float(-13,196,128)], onnx::Add_500[Float(-13,196,128)] -> onnx::Shape_501[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_77, Tactic: 0, onnx::Shape_501[Float(-13,196,128)] -> reshape_before_MatMul_77_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_77 + BatchNormalization_79, Tactic: 0, reshape_before_MatMul_77_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_77 + BatchNormalization_79[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_77 + BatchNormalization_79, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to MatMul_77 + BatchNormalization_79[Float(-22,128,1,1)] -> (Unnamed Layer* 189) [Scale]_output[Float(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85, Tactic: 0, (Unnamed Layer* 189) [Scale]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85[Float(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85[Float(-22,256,1,1)] -> Reformatted Output Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85[Float(-13,196,4,64)]\n",
      "Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85, Tactic: 0, Reformatted Output Tensor 0 to (Unnamed Layer* 190) [Shuffle] + Reshape_81 + Reshape_85[Float(-13,196,4,64)] -> onnx::Split_521[Half(-13,196,4,64)]\n",
      "Layer(Shuffle): Transpose_87, Tactic: 0, onnx::Split_521[Half(-13,196,4,16)] -> onnx::MatMul_525[Half(-13,4,196,16)]\n",
      "Layer(Shuffle): Transpose_89, Tactic: 0, onnx::Split_521[Half(-13,196,4,16)] -> onnx::MatMul_527[Half(-13,4,16,196)]\n",
      "Layer(Shuffle): Transpose_88, Tactic: 0, onnx::Split_521[Half(-13,196,4,32)] -> onnx::MatMul_526[Half(-13,4,196,32)]\n",
      "Layer(MatrixMultiply): MatMul_90, Tactic: 0, onnx::MatMul_525[Half(-13,4,196,16)], onnx::MatMul_527[Half(-13,4,16,196)] -> onnx::Add_530[Half(-13,4,196,196)]\n",
      "Layer(Scale): onnx::Add_531 + (Unnamed Layer* 222) [Shuffle] + Add_94, Tactic: 0, onnx::Add_530[Half(-13,4,196,196)] -> onnx::Softmax_532[Half(-13,4,196,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 233) [Shuffle], Tactic: 0, onnx::Softmax_532[Half(-13,4,196,196)] -> (Unnamed Layer* 233) [Shuffle]_output[Half(-21,196)]\n",
      "Layer(CudaSoftMax): Softmax_95, Tactic: 1001, (Unnamed Layer* 233) [Shuffle]_output[Half(-21,196)] -> (Unnamed Layer* 234) [Softmax]_output[Half(-21,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 235) [Shuffle], Tactic: 0, (Unnamed Layer* 234) [Softmax]_output[Half(-21,196)] -> onnx::MatMul_533[Half(-13,4,196,196)]\n",
      "Layer(MatrixMultiply): MatMul_96, Tactic: 0, onnx::MatMul_533[Half(-13,4,196,196)], onnx::MatMul_526[Half(-13,4,196,32)] -> onnx::Transpose_534[Half(-13,4,196,32)]\n",
      "Layer(Shuffle): Transpose_97 + Reshape_101, Tactic: 0, onnx::Transpose_534[Half(-13,4,196,32)] -> input.68[Half(-13,196,128)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_102), Mul_103), Tactic: 8, input.68[Half(-13,196,128)] -> onnx::MatMul_543[Half(-13,196,128)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_104, Tactic: 0, onnx::MatMul_543[Half(-13,196,128)] -> Reformatted Input Tensor 0 to reshape_before_MatMul_104[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_104, Tactic: 0, Reformatted Input Tensor 0 to reshape_before_MatMul_104[Float(-13,196,128)] -> reshape_before_MatMul_104_out_region[Float(-22,128,1,1)]\n",
      "Layer(CublasConvolution): MatMul_104 + BatchNormalization_106, Tactic: 0, reshape_before_MatMul_104_out_region[Float(-22,128,1,1)] -> (Unnamed Layer* 263) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 264) [Shuffle] + Reshape_108, Tactic: 0, (Unnamed Layer* 263) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_549[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_109, Tactic: 1, onnx::Shape_501[Float(-13,196,128)], onnx::Add_549[Float(-13,196,128)] -> onnx::MatMul_550[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_110, Tactic: 0, onnx::MatMul_550[Float(-13,196,128)] -> reshape_before_MatMul_110_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_110 + BatchNormalization_112, Tactic: 0, reshape_before_MatMul_110_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_110 + BatchNormalization_112[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_110 + BatchNormalization_112, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to MatMul_110 + BatchNormalization_112[Float(-22,128,1,1)] -> (Unnamed Layer* 286) [Scale]_output[Float(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 287) [Shuffle] + Reshape_114, Tactic: 0, (Unnamed Layer* 286) [Scale]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 287) [Shuffle] + Reshape_114[Float(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 287) [Shuffle] + Reshape_114, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 287) [Shuffle] + Reshape_114[Float(-22,256,1,1)] -> input.80[Float(-13,196,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_115), Mul_116), Tactic: 8, input.80[Float(-13,196,256)] -> onnx::MatMul_558[Float(-13,196,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_117, Tactic: 0, onnx::MatMul_558[Float(-13,196,256)] -> reshape_before_MatMul_117_out_region[Float(-22,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_117 + BatchNormalization_119, Tactic: 1, reshape_before_MatMul_117_out_region[Float(-22,256,1,1)] -> (Unnamed Layer* 310) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 311) [Shuffle] + Reshape_121, Tactic: 0, (Unnamed Layer* 310) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_564[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_122, Tactic: 1, onnx::MatMul_550[Float(-13,196,128)], onnx::Add_564[Float(-13,196,128)] -> onnx::Shape_565[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_129, Tactic: 0, onnx::Shape_565[Float(-13,196,128)] -> reshape_before_MatMul_129_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_129 + BatchNormalization_131, Tactic: 0, reshape_before_MatMul_129_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_129 + BatchNormalization_131[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_129 + BatchNormalization_131, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to MatMul_129 + BatchNormalization_131[Float(-22,128,1,1)] -> (Unnamed Layer* 339) [Scale]_output[Float(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137, Tactic: 0, (Unnamed Layer* 339) [Scale]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137[Float(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137[Float(-22,256,1,1)] -> Reformatted Output Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137[Float(-13,196,4,64)]\n",
      "Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137, Tactic: 0, Reformatted Output Tensor 0 to (Unnamed Layer* 340) [Shuffle] + Reshape_133 + Reshape_137[Float(-13,196,4,64)] -> onnx::Split_585[Half(-13,196,4,64)]\n",
      "Layer(Shuffle): Transpose_139, Tactic: 0, onnx::Split_585[Half(-13,196,4,16)] -> onnx::MatMul_589[Half(-13,4,196,16)]\n",
      "Layer(Shuffle): Transpose_141, Tactic: 0, onnx::Split_585[Half(-13,196,4,16)] -> onnx::MatMul_591[Half(-13,4,16,196)]\n",
      "Layer(Shuffle): Transpose_140, Tactic: 0, onnx::Split_585[Half(-13,196,4,32)] -> onnx::MatMul_590[Half(-13,4,196,32)]\n",
      "Layer(MatrixMultiply): MatMul_142, Tactic: 0, onnx::MatMul_589[Half(-13,4,196,16)], onnx::MatMul_591[Half(-13,4,16,196)] -> onnx::Add_594[Half(-13,4,196,196)]\n",
      "Layer(Scale): onnx::Add_595 + (Unnamed Layer* 372) [Shuffle] + Add_146, Tactic: 0, onnx::Add_594[Half(-13,4,196,196)] -> onnx::Softmax_596[Half(-13,4,196,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 383) [Shuffle], Tactic: 0, onnx::Softmax_596[Half(-13,4,196,196)] -> (Unnamed Layer* 383) [Shuffle]_output[Half(-21,196)]\n",
      "Layer(CudaSoftMax): Softmax_147, Tactic: 1001, (Unnamed Layer* 383) [Shuffle]_output[Half(-21,196)] -> (Unnamed Layer* 384) [Softmax]_output[Half(-21,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 385) [Shuffle], Tactic: 0, (Unnamed Layer* 384) [Softmax]_output[Half(-21,196)] -> onnx::MatMul_597[Half(-13,4,196,196)]\n",
      "Layer(MatrixMultiply): MatMul_148, Tactic: 0, onnx::MatMul_597[Half(-13,4,196,196)], onnx::MatMul_590[Half(-13,4,196,32)] -> onnx::Transpose_598[Half(-13,4,196,32)]\n",
      "Layer(Shuffle): Transpose_149 + Reshape_153, Tactic: 0, onnx::Transpose_598[Half(-13,4,196,32)] -> input.92[Half(-13,196,128)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_154), Mul_155), Tactic: 8, input.92[Half(-13,196,128)] -> onnx::MatMul_607[Half(-13,196,128)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_156, Tactic: 0, onnx::MatMul_607[Half(-13,196,128)] -> Reformatted Input Tensor 0 to reshape_before_MatMul_156[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_156, Tactic: 0, Reformatted Input Tensor 0 to reshape_before_MatMul_156[Float(-13,196,128)] -> reshape_before_MatMul_156_out_region[Float(-22,128,1,1)]\n",
      "Layer(CublasConvolution): MatMul_156 + BatchNormalization_158, Tactic: 0, reshape_before_MatMul_156_out_region[Float(-22,128,1,1)] -> (Unnamed Layer* 413) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 414) [Shuffle] + Reshape_160, Tactic: 0, (Unnamed Layer* 413) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_613[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_161, Tactic: 1, onnx::Shape_565[Float(-13,196,128)], onnx::Add_613[Float(-13,196,128)] -> onnx::MatMul_614[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_162, Tactic: 0, onnx::MatMul_614[Float(-13,196,128)] -> reshape_before_MatMul_162_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_162 + BatchNormalization_164, Tactic: 0, reshape_before_MatMul_162_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_162 + BatchNormalization_164[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_162 + BatchNormalization_164, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to MatMul_162 + BatchNormalization_164[Float(-22,128,1,1)] -> (Unnamed Layer* 436) [Scale]_output[Float(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 437) [Shuffle] + Reshape_166, Tactic: 0, (Unnamed Layer* 436) [Scale]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 437) [Shuffle] + Reshape_166[Float(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 437) [Shuffle] + Reshape_166, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 437) [Shuffle] + Reshape_166[Float(-22,256,1,1)] -> input.104[Float(-13,196,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_167), Mul_168), Tactic: 8, input.104[Float(-13,196,256)] -> onnx::MatMul_622[Float(-13,196,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_169, Tactic: 0, onnx::MatMul_622[Float(-13,196,256)] -> reshape_before_MatMul_169_out_region[Float(-22,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_169 + BatchNormalization_171, Tactic: 1, reshape_before_MatMul_169_out_region[Float(-22,256,1,1)] -> (Unnamed Layer* 460) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 461) [Shuffle] + Reshape_173, Tactic: 0, (Unnamed Layer* 460) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_628[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_174, Tactic: 1, onnx::MatMul_614[Float(-13,196,128)], onnx::Add_628[Float(-13,196,128)] -> onnx::Shape_629[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_181, Tactic: 0, onnx::Shape_629[Float(-13,196,128)] -> reshape_before_MatMul_181_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_181 + BatchNormalization_183, Tactic: 0, reshape_before_MatMul_181_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_181 + BatchNormalization_183[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_181 + BatchNormalization_183, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to MatMul_181 + BatchNormalization_183[Float(-22,128,1,1)] -> (Unnamed Layer* 489) [Scale]_output[Float(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189, Tactic: 0, (Unnamed Layer* 489) [Scale]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189[Float(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189[Float(-22,256,1,1)] -> Reformatted Output Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189[Float(-13,196,4,64)]\n",
      "Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189, Tactic: 0, Reformatted Output Tensor 0 to (Unnamed Layer* 490) [Shuffle] + Reshape_185 + Reshape_189[Float(-13,196,4,64)] -> onnx::Split_649[Half(-13,196,4,64)]\n",
      "Layer(Shuffle): Transpose_191, Tactic: 0, onnx::Split_649[Half(-13,196,4,16)] -> onnx::MatMul_653[Half(-13,4,196,16)]\n",
      "Layer(Shuffle): Transpose_193, Tactic: 0, onnx::Split_649[Half(-13,196,4,16)] -> onnx::MatMul_655[Half(-13,4,16,196)]\n",
      "Layer(Shuffle): Transpose_192, Tactic: 0, onnx::Split_649[Half(-13,196,4,32)] -> onnx::MatMul_654[Half(-13,4,196,32)]\n",
      "Layer(MatrixMultiply): MatMul_194, Tactic: 0, onnx::MatMul_653[Half(-13,4,196,16)], onnx::MatMul_655[Half(-13,4,16,196)] -> onnx::Add_658[Half(-13,4,196,196)]\n",
      "Layer(Scale): onnx::Add_659 + (Unnamed Layer* 522) [Shuffle] + Add_198, Tactic: 0, onnx::Add_658[Half(-13,4,196,196)] -> onnx::Softmax_660[Half(-13,4,196,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 533) [Shuffle], Tactic: 0, onnx::Softmax_660[Half(-13,4,196,196)] -> (Unnamed Layer* 533) [Shuffle]_output[Half(-21,196)]\n",
      "Layer(CudaSoftMax): Softmax_199, Tactic: 1001, (Unnamed Layer* 533) [Shuffle]_output[Half(-21,196)] -> (Unnamed Layer* 534) [Softmax]_output[Half(-21,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 535) [Shuffle], Tactic: 0, (Unnamed Layer* 534) [Softmax]_output[Half(-21,196)] -> onnx::MatMul_661[Half(-13,4,196,196)]\n",
      "Layer(MatrixMultiply): MatMul_200, Tactic: 0, onnx::MatMul_661[Half(-13,4,196,196)], onnx::MatMul_654[Half(-13,4,196,32)] -> onnx::Transpose_662[Half(-13,4,196,32)]\n",
      "Layer(Shuffle): Transpose_201 + Reshape_205, Tactic: 0, onnx::Transpose_662[Half(-13,4,196,32)] -> input.116[Half(-13,196,128)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_206), Mul_207), Tactic: 8, input.116[Half(-13,196,128)] -> onnx::MatMul_671[Half(-13,196,128)]\n",
      "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to reshape_before_MatMul_208, Tactic: 0, onnx::MatMul_671[Half(-13,196,128)] -> Reformatted Input Tensor 0 to reshape_before_MatMul_208[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_208, Tactic: 0, Reformatted Input Tensor 0 to reshape_before_MatMul_208[Float(-13,196,128)] -> reshape_before_MatMul_208_out_region[Float(-22,128,1,1)]\n",
      "Layer(CublasConvolution): MatMul_208 + BatchNormalization_210, Tactic: 0, reshape_before_MatMul_208_out_region[Float(-22,128,1,1)] -> (Unnamed Layer* 563) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 564) [Shuffle] + Reshape_212, Tactic: 0, (Unnamed Layer* 563) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_677[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_213, Tactic: 1, onnx::Shape_629[Float(-13,196,128)], onnx::Add_677[Float(-13,196,128)] -> onnx::MatMul_678[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_214, Tactic: 0, onnx::MatMul_678[Float(-13,196,128)] -> reshape_before_MatMul_214_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_214 + BatchNormalization_216, Tactic: 0, reshape_before_MatMul_214_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_214 + BatchNormalization_216[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_214 + BatchNormalization_216, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to MatMul_214 + BatchNormalization_216[Float(-22,128,1,1)] -> (Unnamed Layer* 586) [Scale]_output[Float(-22,256,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 587) [Shuffle] + Reshape_218, Tactic: 0, (Unnamed Layer* 586) [Scale]_output[Float(-22,256,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 587) [Shuffle] + Reshape_218[Float(-22,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 587) [Shuffle] + Reshape_218, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 587) [Shuffle] + Reshape_218[Float(-22,256,1,1)] -> input.128[Float(-13,196,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_219), Mul_220), Tactic: 8, input.128[Float(-13,196,256)] -> onnx::MatMul_686[Float(-13,196,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_221, Tactic: 0, onnx::MatMul_686[Float(-13,196,256)] -> reshape_before_MatMul_221_out_region[Float(-22,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_221 + BatchNormalization_223, Tactic: 1, reshape_before_MatMul_221_out_region[Float(-22,256,1,1)] -> (Unnamed Layer* 610) [Scale]_output[Float(-22,128,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 611) [Shuffle] + Reshape_225, Tactic: 0, (Unnamed Layer* 610) [Scale]_output[Float(-22,128,1,1)] -> onnx::Add_692[Float(-13,196,128)]\n",
      "Layer(ElementWise): Add_226, Tactic: 1, onnx::MatMul_678[Float(-13,196,128)], onnx::Add_692[Float(-13,196,128)] -> onnx::Shape_693[Float(-13,196,128)]\n",
      "Layer(NoOp): reshape_before_MatMul_233, Tactic: 0, onnx::Shape_693[Float(-13,196,128)] -> reshape_before_MatMul_233_out_region[Float(-22,128,1,1)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_233 + BatchNormalization_235, Tactic: 0, reshape_before_MatMul_233_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_233 + BatchNormalization_235[Float(-22,128,1,1)]\n",
      "Layer(CaskConvolution): MatMul_233 + BatchNormalization_235, Tactic: 3886731678879822788, Reformatted Input Tensor 0 to MatMul_233 + BatchNormalization_235[Float(-22,128,1,1)] -> (Unnamed Layer* 639) [Scale]_output[Float(-22,640,1,1)]\n",
      "Layer(NoOp): Reshape_253, Tactic: 0, onnx::Shape_693[Float(-13,196,128)] -> onnx::Slice_730[Float(-13,14,14,128)]\n",
      "Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241, Tactic: 0, (Unnamed Layer* 639) [Scale]_output[Float(-22,640,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241[Float(-22,640,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241, Tactic: 0, Reformatted Input Tensor 0 to (Unnamed Layer* 640) [Shuffle] + Reshape_237 + Reshape_241[Float(-22,640,1,1)] -> onnx::Split_713[Float(-13,196,8,80)]\n",
      "Layer(Slice): Slice_258, Tactic: 0, onnx::Slice_730[Float(-13,14,14,128)] -> onnx::Slice_735[Float(-13,7,14,128)]\n",
      "Layer(Shuffle): Transpose_277, Tactic: 0, onnx::Split_713[Float(-13,196,8,16)] -> onnx::MatMul_763[Float(-13,8,16,196)]\n",
      "Layer(Shuffle): Transpose_243, Tactic: 0, onnx::Split_713[Float(-13,196,8,64)] -> onnx::MatMul_716[Float(-13,8,196,64)]\n",
      "Layer(Slice): Slice_263, Tactic: 0, onnx::Slice_735[Float(-13,7,14,128)] -> onnx::Reshape_740[Float(-13,7,7,128)]\n",
      "Layer(NoOp): Reshape_267, Tactic: 0, onnx::Reshape_740[Float(-13,7,7,128)] -> onnx::MatMul_746[Float(-13,49,128)]\n",
      "Layer(MatrixMultiply): MatMul_268, Tactic: 0, onnx::MatMul_746[Float(-13,49,128)], (Unnamed Layer* 733) [Shuffle]_output[Float(1,128,128)] -> onnx::Flatten_748[Float(-13,49,128)]\n",
      "Layer(NoOp): Flatten_269 + (Unnamed Layer* 748) [Shuffle], Tactic: 0, onnx::Flatten_748[Float(-13,49,128)] -> (Unnamed Layer* 748) [Shuffle]_output[Float(-26,128,1,1)]\n",
      "Layer(Scale): BatchNormalization_270, Tactic: 0, (Unnamed Layer* 748) [Shuffle]_output[Float(-26,128,1,1)] -> (Unnamed Layer* 749) [Scale]_output[Float(-26,128,1,1)]\n",
      "Layer(Shuffle): (Unnamed Layer* 750) [Shuffle] + Reshape_272 + Reshape_275 + Transpose_276, Tactic: 0, (Unnamed Layer* 749) [Scale]_output[Float(-26,128,1,1)] -> onnx::MatMul_762[Float(-13,8,49,16)]\n",
      "Layer(MatrixMultiply): MatMul_278, Tactic: 0, onnx::MatMul_762[Float(-13,8,49,16)], onnx::MatMul_763[Float(-13,8,16,196)] -> onnx::Add_766[Float(-13,8,49,196)]\n",
      "Layer(Scale): onnx::Add_767 + (Unnamed Layer* 767) [Shuffle] + Add_282, Tactic: 0, onnx::Add_766[Float(-13,8,49,196)] -> onnx::Softmax_768[Float(-13,8,49,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 778) [Shuffle], Tactic: 0, onnx::Softmax_768[Float(-13,8,49,196)] -> (Unnamed Layer* 778) [Shuffle]_output[Float(-23,196)]\n",
      "Layer(CudaSoftMax): Softmax_283, Tactic: 1001, (Unnamed Layer* 778) [Shuffle]_output[Float(-23,196)] -> (Unnamed Layer* 779) [Softmax]_output[Float(-23,196)]\n",
      "Layer(NoOp): (Unnamed Layer* 780) [Shuffle], Tactic: 0, (Unnamed Layer* 779) [Softmax]_output[Float(-23,196)] -> onnx::MatMul_769[Float(-13,8,49,196)]\n",
      "Layer(MatrixMultiply): MatMul_284, Tactic: 0, onnx::MatMul_769[Float(-13,8,49,196)], onnx::MatMul_716[Float(-13,8,196,64)] -> onnx::Transpose_770[Float(-13,8,49,64)]\n",
      "Layer(Shuffle): Transpose_285 + Reshape_288, Tactic: 0, onnx::Transpose_770[Float(-13,8,49,64)] -> input.144[Float(-13,49,512)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_289), Mul_290), Tactic: 5, input.144[Float(-13,49,512)] -> onnx::MatMul_780[Float(-13,49,512)]\n",
      "Layer(NoOp): reshape_before_MatMul_291, Tactic: 0, onnx::MatMul_780[Float(-13,49,512)] -> reshape_before_MatMul_291_out_region[Float(-26,512,1,1)]\n",
      "Layer(CublasConvolution): MatMul_291 + BatchNormalization_293, Tactic: 0, reshape_before_MatMul_291_out_region[Float(-26,512,1,1)] -> (Unnamed Layer* 809) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 810) [Shuffle] + Reshape_295, Tactic: 0, (Unnamed Layer* 809) [Scale]_output[Float(-26,256,1,1)] -> onnx::MatMul_786[Float(-13,49,256)]\n",
      "Layer(MatrixMultiply): MatMul_296, Tactic: 0, onnx::MatMul_786[Float(-13,49,256)], (Unnamed Layer* 815) [Shuffle]_output[Float(1,256,512)] -> onnx::Flatten_788[Float(-13,49,512)]\n",
      "Layer(NoOp): Flatten_297 + (Unnamed Layer* 831) [Shuffle], Tactic: 0, onnx::Flatten_788[Float(-13,49,512)] -> (Unnamed Layer* 831) [Shuffle]_output[Float(-26,512,1,1)]\n",
      "Layer(Scale): BatchNormalization_298, Tactic: 0, (Unnamed Layer* 831) [Shuffle]_output[Float(-26,512,1,1)] -> (Unnamed Layer* 832) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 833) [Shuffle] + Reshape_300, Tactic: 0, (Unnamed Layer* 832) [Scale]_output[Float(-26,512,1,1)] -> input.156[Float(-13,49,512)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_301), Mul_302), Tactic: 5, input.156[Float(-13,49,512)] -> onnx::MatMul_794[Float(-13,49,512)]\n",
      "Layer(NoOp): reshape_before_MatMul_303, Tactic: 0, onnx::MatMul_794[Float(-13,49,512)] -> reshape_before_MatMul_303_out_region[Float(-26,512,1,1)]\n",
      "Layer(CublasConvolution): MatMul_303 + BatchNormalization_305, Tactic: 0, reshape_before_MatMul_303_out_region[Float(-26,512,1,1)] -> (Unnamed Layer* 857) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 858) [Shuffle] + Reshape_307, Tactic: 0, (Unnamed Layer* 857) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_800[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_308, Tactic: 1, onnx::MatMul_786[Float(-13,49,256)], onnx::Add_800[Float(-13,49,256)] -> onnx::Shape_801[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_315, Tactic: 0, onnx::Shape_801[Float(-13,49,256)] -> reshape_before_MatMul_315_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_315 + BatchNormalization_317, Tactic: 0, reshape_before_MatMul_315_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 887) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 888) [Shuffle] + Reshape_319 + Reshape_323, Tactic: 0, (Unnamed Layer* 887) [Scale]_output[Float(-26,512,1,1)] -> onnx::Split_821[Float(-13,49,8,64)]\n",
      "Layer(Shuffle): Transpose_325, Tactic: 0, onnx::Split_821[Float(-13,49,8,16)] -> onnx::MatMul_825[Float(-13,8,49,16)]\n",
      "Layer(Shuffle): Transpose_327, Tactic: 0, onnx::Split_821[Float(-13,49,8,16)] -> onnx::MatMul_827[Float(-13,8,16,49)]\n",
      "Layer(Shuffle): Transpose_326, Tactic: 0, onnx::Split_821[Float(-13,49,8,32)] -> onnx::MatMul_826[Float(-13,8,49,32)]\n",
      "Layer(MatrixMultiply): MatMul_328, Tactic: 0, onnx::MatMul_825[Float(-13,8,49,16)], onnx::MatMul_827[Float(-13,8,16,49)] -> onnx::Add_830[Float(-13,8,49,49)]\n",
      "Layer(Scale): onnx::Add_831 + (Unnamed Layer* 920) [Shuffle] + Add_332, Tactic: 0, onnx::Add_830[Float(-13,8,49,49)] -> onnx::Softmax_832[Float(-13,8,49,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 931) [Shuffle], Tactic: 0, onnx::Softmax_832[Float(-13,8,49,49)] -> (Unnamed Layer* 931) [Shuffle]_output[Float(-23,49)]\n",
      "Layer(CudaSoftMax): Softmax_333, Tactic: 1001, (Unnamed Layer* 931) [Shuffle]_output[Float(-23,49)] -> (Unnamed Layer* 932) [Softmax]_output[Float(-23,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 933) [Shuffle], Tactic: 0, (Unnamed Layer* 932) [Softmax]_output[Float(-23,49)] -> onnx::MatMul_833[Float(-13,8,49,49)]\n",
      "Layer(MatrixMultiply): MatMul_334, Tactic: 0, onnx::MatMul_833[Float(-13,8,49,49)], onnx::MatMul_826[Float(-13,8,49,32)] -> onnx::Transpose_834[Float(-13,8,49,32)]\n",
      "Layer(Shuffle): Transpose_335 + Reshape_339, Tactic: 0, onnx::Transpose_834[Float(-13,8,49,32)] -> input.168[Float(-13,49,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_340), Mul_341), Tactic: 2, input.168[Float(-13,49,256)] -> onnx::MatMul_843[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_342, Tactic: 0, onnx::MatMul_843[Float(-13,49,256)] -> reshape_before_MatMul_342_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_342 + BatchNormalization_344, Tactic: 0, reshape_before_MatMul_342_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 962) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 963) [Shuffle] + Reshape_346, Tactic: 0, (Unnamed Layer* 962) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_849[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_347, Tactic: 1, onnx::Shape_801[Float(-13,49,256)], onnx::Add_849[Float(-13,49,256)] -> onnx::MatMul_850[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_348, Tactic: 0, onnx::MatMul_850[Float(-13,49,256)] -> reshape_before_MatMul_348_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_348 + BatchNormalization_350, Tactic: 0, reshape_before_MatMul_348_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 986) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 987) [Shuffle] + Reshape_352, Tactic: 0, (Unnamed Layer* 986) [Scale]_output[Float(-26,512,1,1)] -> input.180[Float(-13,49,512)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_353), Mul_354), Tactic: 5, input.180[Float(-13,49,512)] -> onnx::MatMul_858[Float(-13,49,512)]\n",
      "Layer(NoOp): reshape_before_MatMul_355, Tactic: 0, onnx::MatMul_858[Float(-13,49,512)] -> reshape_before_MatMul_355_out_region[Float(-26,512,1,1)]\n",
      "Layer(CublasConvolution): MatMul_355 + BatchNormalization_357, Tactic: 0, reshape_before_MatMul_355_out_region[Float(-26,512,1,1)] -> (Unnamed Layer* 1011) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1012) [Shuffle] + Reshape_359, Tactic: 0, (Unnamed Layer* 1011) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_864[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_360, Tactic: 1, onnx::MatMul_850[Float(-13,49,256)], onnx::Add_864[Float(-13,49,256)] -> onnx::Shape_865[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_367, Tactic: 0, onnx::Shape_865[Float(-13,49,256)] -> reshape_before_MatMul_367_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_367 + BatchNormalization_369, Tactic: 0, reshape_before_MatMul_367_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1041) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1042) [Shuffle] + Reshape_371 + Reshape_375, Tactic: 0, (Unnamed Layer* 1041) [Scale]_output[Float(-26,512,1,1)] -> onnx::Split_885[Float(-13,49,8,64)]\n",
      "Layer(Shuffle): Transpose_377, Tactic: 0, onnx::Split_885[Float(-13,49,8,16)] -> onnx::MatMul_889[Float(-13,8,49,16)]\n",
      "Layer(Shuffle): Transpose_379, Tactic: 0, onnx::Split_885[Float(-13,49,8,16)] -> onnx::MatMul_891[Float(-13,8,16,49)]\n",
      "Layer(Shuffle): Transpose_378, Tactic: 0, onnx::Split_885[Float(-13,49,8,32)] -> onnx::MatMul_890[Float(-13,8,49,32)]\n",
      "Layer(MatrixMultiply): MatMul_380, Tactic: 0, onnx::MatMul_889[Float(-13,8,49,16)], onnx::MatMul_891[Float(-13,8,16,49)] -> onnx::Add_894[Float(-13,8,49,49)]\n",
      "Layer(Scale): onnx::Add_895 + (Unnamed Layer* 1074) [Shuffle] + Add_384, Tactic: 0, onnx::Add_894[Float(-13,8,49,49)] -> onnx::Softmax_896[Float(-13,8,49,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1085) [Shuffle], Tactic: 0, onnx::Softmax_896[Float(-13,8,49,49)] -> (Unnamed Layer* 1085) [Shuffle]_output[Float(-23,49)]\n",
      "Layer(CudaSoftMax): Softmax_385, Tactic: 1001, (Unnamed Layer* 1085) [Shuffle]_output[Float(-23,49)] -> (Unnamed Layer* 1086) [Softmax]_output[Float(-23,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1087) [Shuffle], Tactic: 0, (Unnamed Layer* 1086) [Softmax]_output[Float(-23,49)] -> onnx::MatMul_897[Float(-13,8,49,49)]\n",
      "Layer(MatrixMultiply): MatMul_386, Tactic: 0, onnx::MatMul_897[Float(-13,8,49,49)], onnx::MatMul_890[Float(-13,8,49,32)] -> onnx::Transpose_898[Float(-13,8,49,32)]\n",
      "Layer(Shuffle): Transpose_387 + Reshape_391, Tactic: 0, onnx::Transpose_898[Float(-13,8,49,32)] -> input.192[Float(-13,49,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_392), Mul_393), Tactic: 2, input.192[Float(-13,49,256)] -> onnx::MatMul_907[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_394, Tactic: 0, onnx::MatMul_907[Float(-13,49,256)] -> reshape_before_MatMul_394_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_394 + BatchNormalization_396, Tactic: 0, reshape_before_MatMul_394_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1116) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1117) [Shuffle] + Reshape_398, Tactic: 0, (Unnamed Layer* 1116) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_913[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_399, Tactic: 1, onnx::Shape_865[Float(-13,49,256)], onnx::Add_913[Float(-13,49,256)] -> onnx::MatMul_914[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_400, Tactic: 0, onnx::MatMul_914[Float(-13,49,256)] -> reshape_before_MatMul_400_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_400 + BatchNormalization_402, Tactic: 0, reshape_before_MatMul_400_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1140) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1141) [Shuffle] + Reshape_404, Tactic: 0, (Unnamed Layer* 1140) [Scale]_output[Float(-26,512,1,1)] -> input.204[Float(-13,49,512)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_405), Mul_406), Tactic: 5, input.204[Float(-13,49,512)] -> onnx::MatMul_922[Float(-13,49,512)]\n",
      "Layer(NoOp): reshape_before_MatMul_407, Tactic: 0, onnx::MatMul_922[Float(-13,49,512)] -> reshape_before_MatMul_407_out_region[Float(-26,512,1,1)]\n",
      "Layer(CublasConvolution): MatMul_407 + BatchNormalization_409, Tactic: 0, reshape_before_MatMul_407_out_region[Float(-26,512,1,1)] -> (Unnamed Layer* 1165) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1166) [Shuffle] + Reshape_411, Tactic: 0, (Unnamed Layer* 1165) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_928[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_412, Tactic: 1, onnx::MatMul_914[Float(-13,49,256)], onnx::Add_928[Float(-13,49,256)] -> onnx::Shape_929[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_419, Tactic: 0, onnx::Shape_929[Float(-13,49,256)] -> reshape_before_MatMul_419_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_419 + BatchNormalization_421, Tactic: 0, reshape_before_MatMul_419_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1195) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1196) [Shuffle] + Reshape_423 + Reshape_427, Tactic: 0, (Unnamed Layer* 1195) [Scale]_output[Float(-26,512,1,1)] -> onnx::Split_949[Float(-13,49,8,64)]\n",
      "Layer(Shuffle): Transpose_429, Tactic: 0, onnx::Split_949[Float(-13,49,8,16)] -> onnx::MatMul_953[Float(-13,8,49,16)]\n",
      "Layer(Shuffle): Transpose_431, Tactic: 0, onnx::Split_949[Float(-13,49,8,16)] -> onnx::MatMul_955[Float(-13,8,16,49)]\n",
      "Layer(Shuffle): Transpose_430, Tactic: 0, onnx::Split_949[Float(-13,49,8,32)] -> onnx::MatMul_954[Float(-13,8,49,32)]\n",
      "Layer(MatrixMultiply): MatMul_432, Tactic: 0, onnx::MatMul_953[Float(-13,8,49,16)], onnx::MatMul_955[Float(-13,8,16,49)] -> onnx::Add_958[Float(-13,8,49,49)]\n",
      "Layer(Scale): onnx::Add_959 + (Unnamed Layer* 1228) [Shuffle] + Add_436, Tactic: 0, onnx::Add_958[Float(-13,8,49,49)] -> onnx::Softmax_960[Float(-13,8,49,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1239) [Shuffle], Tactic: 0, onnx::Softmax_960[Float(-13,8,49,49)] -> (Unnamed Layer* 1239) [Shuffle]_output[Float(-23,49)]\n",
      "Layer(CudaSoftMax): Softmax_437, Tactic: 1001, (Unnamed Layer* 1239) [Shuffle]_output[Float(-23,49)] -> (Unnamed Layer* 1240) [Softmax]_output[Float(-23,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1241) [Shuffle], Tactic: 0, (Unnamed Layer* 1240) [Softmax]_output[Float(-23,49)] -> onnx::MatMul_961[Float(-13,8,49,49)]\n",
      "Layer(MatrixMultiply): MatMul_438, Tactic: 0, onnx::MatMul_961[Float(-13,8,49,49)], onnx::MatMul_954[Float(-13,8,49,32)] -> onnx::Transpose_962[Float(-13,8,49,32)]\n",
      "Layer(Shuffle): Transpose_439 + Reshape_443, Tactic: 0, onnx::Transpose_962[Float(-13,8,49,32)] -> input.216[Float(-13,49,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_444), Mul_445), Tactic: 2, input.216[Float(-13,49,256)] -> onnx::MatMul_971[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_446, Tactic: 0, onnx::MatMul_971[Float(-13,49,256)] -> reshape_before_MatMul_446_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_446 + BatchNormalization_448, Tactic: 0, reshape_before_MatMul_446_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1270) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1271) [Shuffle] + Reshape_450, Tactic: 0, (Unnamed Layer* 1270) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_977[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_451, Tactic: 1, onnx::Shape_929[Float(-13,49,256)], onnx::Add_977[Float(-13,49,256)] -> onnx::MatMul_978[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_452, Tactic: 0, onnx::MatMul_978[Float(-13,49,256)] -> reshape_before_MatMul_452_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_452 + BatchNormalization_454, Tactic: 0, reshape_before_MatMul_452_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1294) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1295) [Shuffle] + Reshape_456, Tactic: 0, (Unnamed Layer* 1294) [Scale]_output[Float(-26,512,1,1)] -> input.228[Float(-13,49,512)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_457), Mul_458), Tactic: 5, input.228[Float(-13,49,512)] -> onnx::MatMul_986[Float(-13,49,512)]\n",
      "Layer(NoOp): reshape_before_MatMul_459, Tactic: 0, onnx::MatMul_986[Float(-13,49,512)] -> reshape_before_MatMul_459_out_region[Float(-26,512,1,1)]\n",
      "Layer(CublasConvolution): MatMul_459 + BatchNormalization_461, Tactic: 0, reshape_before_MatMul_459_out_region[Float(-26,512,1,1)] -> (Unnamed Layer* 1319) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1320) [Shuffle] + Reshape_463, Tactic: 0, (Unnamed Layer* 1319) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_992[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_464, Tactic: 1, onnx::MatMul_978[Float(-13,49,256)], onnx::Add_992[Float(-13,49,256)] -> onnx::Shape_993[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_471, Tactic: 0, onnx::Shape_993[Float(-13,49,256)] -> reshape_before_MatMul_471_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_471 + BatchNormalization_473, Tactic: 0, reshape_before_MatMul_471_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1349) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1350) [Shuffle] + Reshape_475 + Reshape_479, Tactic: 0, (Unnamed Layer* 1349) [Scale]_output[Float(-26,512,1,1)] -> onnx::Split_1013[Float(-13,49,8,64)]\n",
      "Layer(Shuffle): Transpose_481, Tactic: 0, onnx::Split_1013[Float(-13,49,8,16)] -> onnx::MatMul_1017[Float(-13,8,49,16)]\n",
      "Layer(Shuffle): Transpose_483, Tactic: 0, onnx::Split_1013[Float(-13,49,8,16)] -> onnx::MatMul_1019[Float(-13,8,16,49)]\n",
      "Layer(Shuffle): Transpose_482, Tactic: 0, onnx::Split_1013[Float(-13,49,8,32)] -> onnx::MatMul_1018[Float(-13,8,49,32)]\n",
      "Layer(MatrixMultiply): MatMul_484, Tactic: 0, onnx::MatMul_1017[Float(-13,8,49,16)], onnx::MatMul_1019[Float(-13,8,16,49)] -> onnx::Add_1022[Float(-13,8,49,49)]\n",
      "Layer(Scale): onnx::Add_1023 + (Unnamed Layer* 1382) [Shuffle] + Add_488, Tactic: 0, onnx::Add_1022[Float(-13,8,49,49)] -> onnx::Softmax_1024[Float(-13,8,49,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1393) [Shuffle], Tactic: 0, onnx::Softmax_1024[Float(-13,8,49,49)] -> (Unnamed Layer* 1393) [Shuffle]_output[Float(-23,49)]\n",
      "Layer(CudaSoftMax): Softmax_489, Tactic: 1001, (Unnamed Layer* 1393) [Shuffle]_output[Float(-23,49)] -> (Unnamed Layer* 1394) [Softmax]_output[Float(-23,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1395) [Shuffle], Tactic: 0, (Unnamed Layer* 1394) [Softmax]_output[Float(-23,49)] -> onnx::MatMul_1025[Float(-13,8,49,49)]\n",
      "Layer(MatrixMultiply): MatMul_490, Tactic: 0, onnx::MatMul_1025[Float(-13,8,49,49)], onnx::MatMul_1018[Float(-13,8,49,32)] -> onnx::Transpose_1026[Float(-13,8,49,32)]\n",
      "Layer(Shuffle): Transpose_491 + Reshape_495, Tactic: 0, onnx::Transpose_1026[Float(-13,8,49,32)] -> input.240[Float(-13,49,256)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_496), Mul_497), Tactic: 2, input.240[Float(-13,49,256)] -> onnx::MatMul_1035[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_498, Tactic: 0, onnx::MatMul_1035[Float(-13,49,256)] -> reshape_before_MatMul_498_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_498 + BatchNormalization_500, Tactic: 0, reshape_before_MatMul_498_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1424) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1425) [Shuffle] + Reshape_502, Tactic: 0, (Unnamed Layer* 1424) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_1041[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_503, Tactic: 1, onnx::Shape_993[Float(-13,49,256)], onnx::Add_1041[Float(-13,49,256)] -> onnx::MatMul_1042[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_504, Tactic: 0, onnx::MatMul_1042[Float(-13,49,256)] -> reshape_before_MatMul_504_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_504 + BatchNormalization_506, Tactic: 0, reshape_before_MatMul_504_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1448) [Scale]_output[Float(-26,512,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1449) [Shuffle] + Reshape_508, Tactic: 0, (Unnamed Layer* 1448) [Scale]_output[Float(-26,512,1,1)] -> input.252[Float(-13,49,512)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_509), Mul_510), Tactic: 5, input.252[Float(-13,49,512)] -> onnx::MatMul_1050[Float(-13,49,512)]\n",
      "Layer(NoOp): reshape_before_MatMul_511, Tactic: 0, onnx::MatMul_1050[Float(-13,49,512)] -> reshape_before_MatMul_511_out_region[Float(-26,512,1,1)]\n",
      "Layer(CublasConvolution): MatMul_511 + BatchNormalization_513, Tactic: 0, reshape_before_MatMul_511_out_region[Float(-26,512,1,1)] -> (Unnamed Layer* 1473) [Scale]_output[Float(-26,256,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1474) [Shuffle] + Reshape_515, Tactic: 0, (Unnamed Layer* 1473) [Scale]_output[Float(-26,256,1,1)] -> onnx::Add_1056[Float(-13,49,256)]\n",
      "Layer(ElementWise): Add_516, Tactic: 1, onnx::MatMul_1042[Float(-13,49,256)], onnx::Add_1056[Float(-13,49,256)] -> onnx::Shape_1057[Float(-13,49,256)]\n",
      "Layer(NoOp): reshape_before_MatMul_523, Tactic: 0, onnx::Shape_1057[Float(-13,49,256)] -> reshape_before_MatMul_523_out_region[Float(-26,256,1,1)]\n",
      "Layer(CublasConvolution): MatMul_523 + BatchNormalization_525, Tactic: 1, reshape_before_MatMul_523_out_region[Float(-26,256,1,1)] -> (Unnamed Layer* 1503) [Scale]_output[Float(-26,1280,1,1)]\n",
      "Layer(NoOp): Reshape_543, Tactic: 0, onnx::Shape_1057[Float(-13,49,256)] -> onnx::Slice_1094[Float(-13,7,7,256)]\n",
      "Layer(NoOp): (Unnamed Layer* 1504) [Shuffle] + Reshape_527 + Reshape_531, Tactic: 0, (Unnamed Layer* 1503) [Scale]_output[Float(-26,1280,1,1)] -> onnx::Split_1077[Float(-13,49,16,80)]\n",
      "Layer(Slice): Slice_548, Tactic: 0, onnx::Slice_1094[Float(-13,7,7,256)] -> onnx::Slice_1099[Float(-13,4,7,256)]\n",
      "Layer(Shuffle): Transpose_567, Tactic: 0, onnx::Split_1077[Float(-13,49,16,16)] -> onnx::MatMul_1127[Float(-13,16,16,49)]\n",
      "Layer(Shuffle): Transpose_533, Tactic: 0, onnx::Split_1077[Float(-13,49,16,64)] -> onnx::MatMul_1080[Float(-13,16,49,64)]\n",
      "Layer(Slice): Slice_553, Tactic: 0, onnx::Slice_1099[Float(-13,4,7,256)] -> onnx::Reshape_1104[Float(-13,4,4,256)]\n",
      "Layer(NoOp): Reshape_557, Tactic: 0, onnx::Reshape_1104[Float(-13,4,4,256)] -> onnx::MatMul_1110[Float(-13,16,256)]\n",
      "Layer(MatrixMultiply): MatMul_558, Tactic: 0, onnx::MatMul_1110[Float(-13,16,256)], (Unnamed Layer* 1597) [Shuffle]_output[Float(1,256,256)] -> onnx::Flatten_1112[Float(-13,16,256)]\n",
      "Layer(NoOp): Flatten_559 + (Unnamed Layer* 1612) [Shuffle], Tactic: 0, onnx::Flatten_1112[Float(-13,16,256)] -> (Unnamed Layer* 1612) [Shuffle]_output[Float(-19,256,1,1)]\n",
      "Layer(Scale): BatchNormalization_560, Tactic: 0, (Unnamed Layer* 1612) [Shuffle]_output[Float(-19,256,1,1)] -> (Unnamed Layer* 1613) [Scale]_output[Float(-19,256,1,1)]\n",
      "Layer(Shuffle): (Unnamed Layer* 1614) [Shuffle] + Reshape_562 + Reshape_565 + Transpose_566, Tactic: 0, (Unnamed Layer* 1613) [Scale]_output[Float(-19,256,1,1)] -> onnx::MatMul_1126[Float(-13,16,16,16)]\n",
      "Layer(MatrixMultiply): MatMul_568, Tactic: 0, onnx::MatMul_1126[Float(-13,16,16,16)], onnx::MatMul_1127[Float(-13,16,16,49)] -> onnx::Add_1130[Float(-13,16,16,49)]\n",
      "Layer(Scale): onnx::Add_1131 + (Unnamed Layer* 1631) [Shuffle] + Add_572, Tactic: 0, onnx::Add_1130[Float(-13,16,16,49)] -> onnx::Softmax_1132[Float(-13,16,16,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1642) [Shuffle], Tactic: 0, onnx::Softmax_1132[Float(-13,16,16,49)] -> (Unnamed Layer* 1642) [Shuffle]_output[Float(-20,49)]\n",
      "Layer(CudaSoftMax): Softmax_573, Tactic: 1001, (Unnamed Layer* 1642) [Shuffle]_output[Float(-20,49)] -> (Unnamed Layer* 1643) [Softmax]_output[Float(-20,49)]\n",
      "Layer(NoOp): (Unnamed Layer* 1644) [Shuffle], Tactic: 0, (Unnamed Layer* 1643) [Softmax]_output[Float(-20,49)] -> onnx::MatMul_1133[Float(-13,16,16,49)]\n",
      "Layer(MatrixMultiply): MatMul_574, Tactic: 0, onnx::MatMul_1133[Float(-13,16,16,49)], onnx::MatMul_1080[Float(-13,16,49,64)] -> onnx::Transpose_1134[Float(-13,16,16,64)]\n",
      "Layer(Shuffle): Transpose_575 + Reshape_578, Tactic: 0, onnx::Transpose_1134[Float(-13,16,16,64)] -> input.268[Float(-13,16,1024)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_579), Mul_580), Tactic: 2, input.268[Float(-13,16,1024)] -> onnx::MatMul_1144[Float(-13,16,1024)]\n",
      "Layer(NoOp): reshape_before_MatMul_581, Tactic: 0, onnx::MatMul_1144[Float(-13,16,1024)] -> reshape_before_MatMul_581_out_region[Float(-19,1024,1,1)]\n",
      "Layer(CublasConvolution): MatMul_581 + BatchNormalization_583, Tactic: 1, reshape_before_MatMul_581_out_region[Float(-19,1024,1,1)] -> (Unnamed Layer* 1673) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1674) [Shuffle] + Reshape_585, Tactic: 0, (Unnamed Layer* 1673) [Scale]_output[Float(-19,384,1,1)] -> onnx::MatMul_1150[Float(-13,16,384)]\n",
      "Layer(MatrixMultiply): MatMul_586, Tactic: 0, onnx::MatMul_1150[Float(-13,16,384)], (Unnamed Layer* 1679) [Shuffle]_output[Float(1,384,768)] -> onnx::Flatten_1152[Float(-13,16,768)]\n",
      "Layer(NoOp): Flatten_587 + (Unnamed Layer* 1695) [Shuffle], Tactic: 0, onnx::Flatten_1152[Float(-13,16,768)] -> (Unnamed Layer* 1695) [Shuffle]_output[Float(-19,768,1,1)]\n",
      "Layer(Scale): BatchNormalization_588, Tactic: 0, (Unnamed Layer* 1695) [Shuffle]_output[Float(-19,768,1,1)] -> (Unnamed Layer* 1696) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1697) [Shuffle] + Reshape_590, Tactic: 0, (Unnamed Layer* 1696) [Scale]_output[Float(-19,768,1,1)] -> input.280[Float(-13,16,768)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_591), Mul_592), Tactic: 2, input.280[Float(-13,16,768)] -> onnx::MatMul_1158[Float(-13,16,768)]\n",
      "Layer(NoOp): reshape_before_MatMul_593, Tactic: 0, onnx::MatMul_1158[Float(-13,16,768)] -> reshape_before_MatMul_593_out_region[Float(-19,768,1,1)]\n",
      "Layer(CublasConvolution): MatMul_593 + BatchNormalization_595, Tactic: 1, reshape_before_MatMul_593_out_region[Float(-19,768,1,1)] -> (Unnamed Layer* 1721) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1722) [Shuffle] + Reshape_597, Tactic: 0, (Unnamed Layer* 1721) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1164[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_598, Tactic: 1, onnx::MatMul_1150[Float(-13,16,384)], onnx::Add_1164[Float(-13,16,384)] -> onnx::Shape_1165[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_605, Tactic: 0, onnx::Shape_1165[Float(-13,16,384)] -> reshape_before_MatMul_605_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_605 + BatchNormalization_607, Tactic: 0, reshape_before_MatMul_605_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 1751) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1752) [Shuffle] + Reshape_609 + Reshape_613, Tactic: 0, (Unnamed Layer* 1751) [Scale]_output[Float(-19,768,1,1)] -> onnx::Split_1185[Float(-13,16,12,64)]\n",
      "Layer(Shuffle): Transpose_615, Tactic: 0, onnx::Split_1185[Float(-13,16,12,16)] -> onnx::MatMul_1189[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_617, Tactic: 0, onnx::Split_1185[Float(-13,16,12,16)] -> onnx::MatMul_1191[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_616, Tactic: 0, onnx::Split_1185[Float(-13,16,12,32)] -> onnx::MatMul_1190[Float(-13,12,16,32)]\n",
      "Layer(MatrixMultiply): MatMul_618, Tactic: 0, onnx::MatMul_1189[Float(-13,12,16,16)], onnx::MatMul_1191[Float(-13,12,16,16)] -> onnx::Add_1194[Float(-13,12,16,16)]\n",
      "Layer(Scale): onnx::Add_1195 + (Unnamed Layer* 1784) [Shuffle] + Add_622, Tactic: 0, onnx::Add_1194[Float(-13,12,16,16)] -> onnx::Softmax_1196[Float(-13,12,16,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 1795) [Shuffle], Tactic: 0, onnx::Softmax_1196[Float(-13,12,16,16)] -> (Unnamed Layer* 1795) [Shuffle]_output[Float(-25,16)]\n",
      "Layer(CudaSoftMax): Softmax_623, Tactic: 1001, (Unnamed Layer* 1795) [Shuffle]_output[Float(-25,16)] -> (Unnamed Layer* 1796) [Softmax]_output[Float(-25,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 1797) [Shuffle], Tactic: 0, (Unnamed Layer* 1796) [Softmax]_output[Float(-25,16)] -> onnx::MatMul_1197[Float(-13,12,16,16)]\n",
      "Layer(MatrixMultiply): MatMul_624, Tactic: 0, onnx::MatMul_1197[Float(-13,12,16,16)], onnx::MatMul_1190[Float(-13,12,16,32)] -> onnx::Transpose_1198[Float(-13,12,16,32)]\n",
      "Layer(Shuffle): Transpose_625 + Reshape_629, Tactic: 0, onnx::Transpose_1198[Float(-13,12,16,32)] -> input.292[Float(-13,16,384)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_630), Mul_631), Tactic: 2, input.292[Float(-13,16,384)] -> onnx::MatMul_1207[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_632, Tactic: 0, onnx::MatMul_1207[Float(-13,16,384)] -> reshape_before_MatMul_632_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_632 + BatchNormalization_634, Tactic: 0, reshape_before_MatMul_632_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 1826) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1827) [Shuffle] + Reshape_636, Tactic: 0, (Unnamed Layer* 1826) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1213[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_637, Tactic: 1, onnx::Shape_1165[Float(-13,16,384)], onnx::Add_1213[Float(-13,16,384)] -> onnx::MatMul_1214[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_638, Tactic: 0, onnx::MatMul_1214[Float(-13,16,384)] -> reshape_before_MatMul_638_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_638 + BatchNormalization_640, Tactic: 0, reshape_before_MatMul_638_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 1850) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1851) [Shuffle] + Reshape_642, Tactic: 0, (Unnamed Layer* 1850) [Scale]_output[Float(-19,768,1,1)] -> input.304[Float(-13,16,768)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_643), Mul_644), Tactic: 2, input.304[Float(-13,16,768)] -> onnx::MatMul_1222[Float(-13,16,768)]\n",
      "Layer(NoOp): reshape_before_MatMul_645, Tactic: 0, onnx::MatMul_1222[Float(-13,16,768)] -> reshape_before_MatMul_645_out_region[Float(-19,768,1,1)]\n",
      "Layer(CublasConvolution): MatMul_645 + BatchNormalization_647, Tactic: 1, reshape_before_MatMul_645_out_region[Float(-19,768,1,1)] -> (Unnamed Layer* 1875) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1876) [Shuffle] + Reshape_649, Tactic: 0, (Unnamed Layer* 1875) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1228[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_650, Tactic: 1, onnx::MatMul_1214[Float(-13,16,384)], onnx::Add_1228[Float(-13,16,384)] -> onnx::Shape_1229[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_657, Tactic: 0, onnx::Shape_1229[Float(-13,16,384)] -> reshape_before_MatMul_657_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_657 + BatchNormalization_659, Tactic: 0, reshape_before_MatMul_657_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 1905) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1906) [Shuffle] + Reshape_661 + Reshape_665, Tactic: 0, (Unnamed Layer* 1905) [Scale]_output[Float(-19,768,1,1)] -> onnx::Split_1249[Float(-13,16,12,64)]\n",
      "Layer(Shuffle): Transpose_667, Tactic: 0, onnx::Split_1249[Float(-13,16,12,16)] -> onnx::MatMul_1253[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_669, Tactic: 0, onnx::Split_1249[Float(-13,16,12,16)] -> onnx::MatMul_1255[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_668, Tactic: 0, onnx::Split_1249[Float(-13,16,12,32)] -> onnx::MatMul_1254[Float(-13,12,16,32)]\n",
      "Layer(MatrixMultiply): MatMul_670, Tactic: 0, onnx::MatMul_1253[Float(-13,12,16,16)], onnx::MatMul_1255[Float(-13,12,16,16)] -> onnx::Add_1258[Float(-13,12,16,16)]\n",
      "Layer(Scale): onnx::Add_1259 + (Unnamed Layer* 1938) [Shuffle] + Add_674, Tactic: 0, onnx::Add_1258[Float(-13,12,16,16)] -> onnx::Softmax_1260[Float(-13,12,16,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 1949) [Shuffle], Tactic: 0, onnx::Softmax_1260[Float(-13,12,16,16)] -> (Unnamed Layer* 1949) [Shuffle]_output[Float(-25,16)]\n",
      "Layer(CudaSoftMax): Softmax_675, Tactic: 1001, (Unnamed Layer* 1949) [Shuffle]_output[Float(-25,16)] -> (Unnamed Layer* 1950) [Softmax]_output[Float(-25,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 1951) [Shuffle], Tactic: 0, (Unnamed Layer* 1950) [Softmax]_output[Float(-25,16)] -> onnx::MatMul_1261[Float(-13,12,16,16)]\n",
      "Layer(MatrixMultiply): MatMul_676, Tactic: 0, onnx::MatMul_1261[Float(-13,12,16,16)], onnx::MatMul_1254[Float(-13,12,16,32)] -> onnx::Transpose_1262[Float(-13,12,16,32)]\n",
      "Layer(Shuffle): Transpose_677 + Reshape_681, Tactic: 0, onnx::Transpose_1262[Float(-13,12,16,32)] -> input.316[Float(-13,16,384)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_682), Mul_683), Tactic: 2, input.316[Float(-13,16,384)] -> onnx::MatMul_1271[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_684, Tactic: 0, onnx::MatMul_1271[Float(-13,16,384)] -> reshape_before_MatMul_684_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_684 + BatchNormalization_686, Tactic: 0, reshape_before_MatMul_684_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 1980) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 1981) [Shuffle] + Reshape_688, Tactic: 0, (Unnamed Layer* 1980) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1277[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_689, Tactic: 1, onnx::Shape_1229[Float(-13,16,384)], onnx::Add_1277[Float(-13,16,384)] -> onnx::MatMul_1278[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_690, Tactic: 0, onnx::MatMul_1278[Float(-13,16,384)] -> reshape_before_MatMul_690_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_690 + BatchNormalization_692, Tactic: 0, reshape_before_MatMul_690_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 2004) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2005) [Shuffle] + Reshape_694, Tactic: 0, (Unnamed Layer* 2004) [Scale]_output[Float(-19,768,1,1)] -> input.328[Float(-13,16,768)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_695), Mul_696), Tactic: 2, input.328[Float(-13,16,768)] -> onnx::MatMul_1286[Float(-13,16,768)]\n",
      "Layer(NoOp): reshape_before_MatMul_697, Tactic: 0, onnx::MatMul_1286[Float(-13,16,768)] -> reshape_before_MatMul_697_out_region[Float(-19,768,1,1)]\n",
      "Layer(CublasConvolution): MatMul_697 + BatchNormalization_699, Tactic: 1, reshape_before_MatMul_697_out_region[Float(-19,768,1,1)] -> (Unnamed Layer* 2029) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2030) [Shuffle] + Reshape_701, Tactic: 0, (Unnamed Layer* 2029) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1292[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_702, Tactic: 1, onnx::MatMul_1278[Float(-13,16,384)], onnx::Add_1292[Float(-13,16,384)] -> onnx::Shape_1293[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_709, Tactic: 0, onnx::Shape_1293[Float(-13,16,384)] -> reshape_before_MatMul_709_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_709 + BatchNormalization_711, Tactic: 0, reshape_before_MatMul_709_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 2059) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2060) [Shuffle] + Reshape_713 + Reshape_717, Tactic: 0, (Unnamed Layer* 2059) [Scale]_output[Float(-19,768,1,1)] -> onnx::Split_1313[Float(-13,16,12,64)]\n",
      "Layer(Shuffle): Transpose_719, Tactic: 0, onnx::Split_1313[Float(-13,16,12,16)] -> onnx::MatMul_1317[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_721, Tactic: 0, onnx::Split_1313[Float(-13,16,12,16)] -> onnx::MatMul_1319[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_720, Tactic: 0, onnx::Split_1313[Float(-13,16,12,32)] -> onnx::MatMul_1318[Float(-13,12,16,32)]\n",
      "Layer(MatrixMultiply): MatMul_722, Tactic: 0, onnx::MatMul_1317[Float(-13,12,16,16)], onnx::MatMul_1319[Float(-13,12,16,16)] -> onnx::Add_1322[Float(-13,12,16,16)]\n",
      "Layer(Scale): onnx::Add_1323 + (Unnamed Layer* 2092) [Shuffle] + Add_726, Tactic: 0, onnx::Add_1322[Float(-13,12,16,16)] -> onnx::Softmax_1324[Float(-13,12,16,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 2103) [Shuffle], Tactic: 0, onnx::Softmax_1324[Float(-13,12,16,16)] -> (Unnamed Layer* 2103) [Shuffle]_output[Float(-25,16)]\n",
      "Layer(CudaSoftMax): Softmax_727, Tactic: 1001, (Unnamed Layer* 2103) [Shuffle]_output[Float(-25,16)] -> (Unnamed Layer* 2104) [Softmax]_output[Float(-25,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 2105) [Shuffle], Tactic: 0, (Unnamed Layer* 2104) [Softmax]_output[Float(-25,16)] -> onnx::MatMul_1325[Float(-13,12,16,16)]\n",
      "Layer(MatrixMultiply): MatMul_728, Tactic: 0, onnx::MatMul_1325[Float(-13,12,16,16)], onnx::MatMul_1318[Float(-13,12,16,32)] -> onnx::Transpose_1326[Float(-13,12,16,32)]\n",
      "Layer(Shuffle): Transpose_729 + Reshape_733, Tactic: 0, onnx::Transpose_1326[Float(-13,12,16,32)] -> input.340[Float(-13,16,384)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_734), Mul_735), Tactic: 2, input.340[Float(-13,16,384)] -> onnx::MatMul_1335[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_736, Tactic: 0, onnx::MatMul_1335[Float(-13,16,384)] -> reshape_before_MatMul_736_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_736 + BatchNormalization_738, Tactic: 0, reshape_before_MatMul_736_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 2134) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2135) [Shuffle] + Reshape_740, Tactic: 0, (Unnamed Layer* 2134) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1341[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_741, Tactic: 1, onnx::Shape_1293[Float(-13,16,384)], onnx::Add_1341[Float(-13,16,384)] -> onnx::MatMul_1342[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_742, Tactic: 0, onnx::MatMul_1342[Float(-13,16,384)] -> reshape_before_MatMul_742_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_742 + BatchNormalization_744, Tactic: 0, reshape_before_MatMul_742_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 2158) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2159) [Shuffle] + Reshape_746, Tactic: 0, (Unnamed Layer* 2158) [Scale]_output[Float(-19,768,1,1)] -> input.352[Float(-13,16,768)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_747), Mul_748), Tactic: 2, input.352[Float(-13,16,768)] -> onnx::MatMul_1350[Float(-13,16,768)]\n",
      "Layer(NoOp): reshape_before_MatMul_749, Tactic: 0, onnx::MatMul_1350[Float(-13,16,768)] -> reshape_before_MatMul_749_out_region[Float(-19,768,1,1)]\n",
      "Layer(CublasConvolution): MatMul_749 + BatchNormalization_751, Tactic: 1, reshape_before_MatMul_749_out_region[Float(-19,768,1,1)] -> (Unnamed Layer* 2183) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2184) [Shuffle] + Reshape_753, Tactic: 0, (Unnamed Layer* 2183) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1356[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_754, Tactic: 1, onnx::MatMul_1342[Float(-13,16,384)], onnx::Add_1356[Float(-13,16,384)] -> onnx::Shape_1357[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_761, Tactic: 0, onnx::Shape_1357[Float(-13,16,384)] -> reshape_before_MatMul_761_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_761 + BatchNormalization_763, Tactic: 0, reshape_before_MatMul_761_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 2213) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2214) [Shuffle] + Reshape_765 + Reshape_769, Tactic: 0, (Unnamed Layer* 2213) [Scale]_output[Float(-19,768,1,1)] -> onnx::Split_1377[Float(-13,16,12,64)]\n",
      "Layer(Shuffle): Transpose_771, Tactic: 0, onnx::Split_1377[Float(-13,16,12,16)] -> onnx::MatMul_1381[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_773, Tactic: 0, onnx::Split_1377[Float(-13,16,12,16)] -> onnx::MatMul_1383[Float(-13,12,16,16)]\n",
      "Layer(Shuffle): Transpose_772, Tactic: 0, onnx::Split_1377[Float(-13,16,12,32)] -> onnx::MatMul_1382[Float(-13,12,16,32)]\n",
      "Layer(MatrixMultiply): MatMul_774, Tactic: 0, onnx::MatMul_1381[Float(-13,12,16,16)], onnx::MatMul_1383[Float(-13,12,16,16)] -> onnx::Add_1386[Float(-13,12,16,16)]\n",
      "Layer(Scale): onnx::Add_1387 + (Unnamed Layer* 2246) [Shuffle] + Add_778, Tactic: 0, onnx::Add_1386[Float(-13,12,16,16)] -> onnx::Softmax_1388[Float(-13,12,16,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 2257) [Shuffle], Tactic: 0, onnx::Softmax_1388[Float(-13,12,16,16)] -> (Unnamed Layer* 2257) [Shuffle]_output[Float(-25,16)]\n",
      "Layer(CudaSoftMax): Softmax_779, Tactic: 1001, (Unnamed Layer* 2257) [Shuffle]_output[Float(-25,16)] -> (Unnamed Layer* 2258) [Softmax]_output[Float(-25,16)]\n",
      "Layer(NoOp): (Unnamed Layer* 2259) [Shuffle], Tactic: 0, (Unnamed Layer* 2258) [Softmax]_output[Float(-25,16)] -> onnx::MatMul_1389[Float(-13,12,16,16)]\n",
      "Layer(MatrixMultiply): MatMul_780, Tactic: 0, onnx::MatMul_1389[Float(-13,12,16,16)], onnx::MatMul_1382[Float(-13,12,16,32)] -> onnx::Transpose_1390[Float(-13,12,16,32)]\n",
      "Layer(Shuffle): Transpose_781 + Reshape_785, Tactic: 0, onnx::Transpose_1390[Float(-13,12,16,32)] -> input.364[Float(-13,16,384)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_786), Mul_787), Tactic: 2, input.364[Float(-13,16,384)] -> onnx::MatMul_1399[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_788, Tactic: 0, onnx::MatMul_1399[Float(-13,16,384)] -> reshape_before_MatMul_788_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_788 + BatchNormalization_790, Tactic: 0, reshape_before_MatMul_788_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 2288) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2289) [Shuffle] + Reshape_792, Tactic: 0, (Unnamed Layer* 2288) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1405[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_793, Tactic: 1, onnx::Shape_1357[Float(-13,16,384)], onnx::Add_1405[Float(-13,16,384)] -> onnx::MatMul_1406[Float(-13,16,384)]\n",
      "Layer(NoOp): reshape_before_MatMul_794, Tactic: 0, onnx::MatMul_1406[Float(-13,16,384)] -> reshape_before_MatMul_794_out_region[Float(-19,384,1,1)]\n",
      "Layer(CublasConvolution): MatMul_794 + BatchNormalization_796, Tactic: 0, reshape_before_MatMul_794_out_region[Float(-19,384,1,1)] -> (Unnamed Layer* 2312) [Scale]_output[Float(-19,768,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2313) [Shuffle] + Reshape_798, Tactic: 0, (Unnamed Layer* 2312) [Scale]_output[Float(-19,768,1,1)] -> input.376[Float(-13,16,768)]\n",
      "Layer(PointWiseV2): PWN(PWN(HardSigmoid_799), Mul_800), Tactic: 2, input.376[Float(-13,16,768)] -> onnx::MatMul_1414[Float(-13,16,768)]\n",
      "Layer(NoOp): reshape_before_MatMul_801, Tactic: 0, onnx::MatMul_1414[Float(-13,16,768)] -> reshape_before_MatMul_801_out_region[Float(-19,768,1,1)]\n",
      "Layer(CublasConvolution): MatMul_801 + BatchNormalization_803, Tactic: 1, reshape_before_MatMul_801_out_region[Float(-19,768,1,1)] -> (Unnamed Layer* 2337) [Scale]_output[Float(-19,384,1,1)]\n",
      "Layer(NoOp): (Unnamed Layer* 2338) [Shuffle] + Reshape_805, Tactic: 0, (Unnamed Layer* 2337) [Scale]_output[Float(-19,384,1,1)] -> onnx::Add_1420[Float(-13,16,384)]\n",
      "Layer(ElementWise): Add_806, Tactic: 1, onnx::MatMul_1406[Float(-13,16,384)], onnx::Add_1420[Float(-13,16,384)] -> onnx::ReduceMean_1421[Float(-13,16,384)]\n",
      "Layer(Reduce): ReduceMean_807, Tactic: 7, onnx::ReduceMean_1421[Float(-13,16,384)] -> input.384[Float(-13,384)]\n",
      "Layer(NoOp): (Unnamed Layer* 2349) [Shuffle], Tactic: 0, input.384[Float(-13,384)] -> (Unnamed Layer* 2349) [Shuffle]_output[Float(-13,384,1,1)]\n",
      "Layer(Scale): BatchNormalization_808, Tactic: 0, (Unnamed Layer* 2349) [Shuffle]_output[Float(-13,384,1,1)] -> (Unnamed Layer* 2350) [Scale]_output[Float(-13,384,1,1)]\n",
      "Layer(Scale): BatchNormalization_810, Tactic: 0, (Unnamed Layer* 2349) [Shuffle]_output[Float(-13,384,1,1)] -> (Unnamed Layer* 2364) [Scale]_output[Float(-13,384,1,1)]\n",
      "Layer(CublasConvolution): Gemm_811 + head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle] + unsqueeze_node_after_head_dist.l.bias + (Unnamed Layer* 2370) [Shuffle]_(Unnamed Layer* 2370) [Shuffle]_output + (Unnamed Layer* 2371) [ElementWise], Tactic: 0, (Unnamed Layer* 2364) [Scale]_output[Float(-13,384,1,1)] -> (Unnamed Layer* 2371) [ElementWise]_out_tensor[Float(-13,1000,1,1)]\n",
      "Layer(CublasConvolution): Gemm_809 + head.l.bias + (Unnamed Layer* 2356) [Shuffle] + unsqueeze_node_after_head.l.bias + (Unnamed Layer* 2356) [Shuffle]_(Unnamed Layer* 2356) [Shuffle]_output + (Unnamed Layer* 2357) [ElementWise] + Add_812, Tactic: 0, (Unnamed Layer* 2350) [Scale]_output[Float(-13,384,1,1)], (Unnamed Layer* 2371) [ElementWise]_out_tensor[Float(-13,1000,1,1)] -> Add_812_out_tensor[Float(-13,1000,1,1)]\n",
      "Layer(NoOp): copied_squeeze_after_Add_812, Tactic: 0, Add_812_out_tensor[Float(-13,1000,1,1)] -> onnx::Div_1427[Float(-13,1000)]\n",
      "Layer(PointWiseV2): PWN(onnx::Div_1428 + (Unnamed Layer* 2374) [Shuffle], Div_814), Tactic: 28, onnx::Div_1427[Float(-13,1000)] -> output[Float(-13,1000)]\n",
      "[05/24/2022-15:22:20] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +31, GPU +37, now: CPU 31, GPU 37 (MiB)\n",
      "Success !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorrt.tensorrt.IHostMemory at 0x7fe0773d1d70>,\n",
       " <tensorrt.tensorrt.Logger at 0x7fe0773eb8b0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_engine(engine_path):\n",
    "    with open(engine_path,\"rb\") as f:\n",
    "        engine_data = f.read()\n",
    "    engine = trt.Runtime(trt.Logger(trt.Logger.VERBOSE)).deserialize_cuda_engine(engine_data)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/24/2022-15:23:49] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[05/24/2022-15:23:49] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 4202, GPU 1165 (MiB)\n",
      "[05/24/2022-15:23:49] [TRT] [I] Loaded engine size: 38 MiB\n",
      "[05/24/2022-15:23:49] [TRT] [V] Using cublas as a tactic source\n",
      "[05/24/2022-15:23:49] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.8.0 but loaded cuBLAS/cuBLAS LT 11.5.1\n",
      "[05/24/2022-15:23:49] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 4214, GPU 1215 (MiB)\n",
      "[05/24/2022-15:23:49] [TRT] [V] Deserialization required 63888 microseconds.\n",
      "[05/24/2022-15:23:49] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +36, now: CPU 0, GPU 36 (MiB)\n"
     ]
    }
   ],
   "source": [
    "my_engine = load_engine(\"my_model.plan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_buffers(engine, batch_size, data_type):\n",
    "   context = engine.create_execution_context()\n",
    "   context.set_binding_shape(0,[batch_size,3,224,224])\n",
    "   # Determine dimensions and create page-locked memory buffers (which won't be swapped to disk) to hold host inputs/outputs.\n",
    "   h_input_1 = pycuda.driver.pagelocked_empty(trt.volume(context.get_binding_shape(0)), dtype=trt.nptype(data_type))\n",
    "   h_output = pycuda.driver.pagelocked_empty(trt.volume(context.get_binding_shape(1)), dtype=trt.nptype(data_type))\n",
    "    # Allocate device memory for inputs and outputs.\n",
    "   d_input_1 = pycuda.driver.mem_alloc(h_input_1.nbytes)\n",
    "\n",
    "   d_output = pycuda.driver.mem_alloc(h_output.nbytes)\n",
    "    # Create a stream in which to copy inputs/outputs and run inference.\n",
    "   stream = pycuda.driver.Stream()\n",
    "   return context,h_input_1, d_input_1, h_output, d_output, stream \n",
    "\n",
    "def load_images_to_buffer(pics, pagelocked_buffer):\n",
    "   preprocessed = np.asarray(pics).ravel()\n",
    "   np.copyto(pagelocked_buffer, preprocessed) \n",
    "\n",
    "def do_inference(context, pics_1, h_input_1, d_input_1, h_output, d_output, stream, batch_size, width):\n",
    "\n",
    "   load_images_to_buffer(pics_1, h_input_1)\n",
    "       # Transfer input data to the GPU.\n",
    "   pycuda.driver.memcpy_htod_async(d_input_1, h_input_1, stream)\n",
    "\n",
    "       # Run inference.\n",
    "       # context.profiler = trt.Profiler()\n",
    "   context.execute(batch_size, bindings=[int(d_input_1), int(d_output)])\n",
    "       # Transfer predictions back from the GPU.\n",
    "   pycuda.driver.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "       # Synchronize the stream\n",
    "   stream.synchronize()\n",
    "       # Return the host output.\n",
    "   out = h_output.reshape((batch_size, width))\n",
    "       # print(type(out))\n",
    "   return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(engine,batch_size,input_data):\n",
    "    context = engine.create_execution_context()\n",
    "    context.set_binding_shape(0,[batch_size, 3, 224,224])\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "    inputHost = np.ascontiguousarray(input_data.reshape(-1))\n",
    "    outputHost = np.empty(context.get_binding_shape(1),dtype = trt.nptype(engine.get_binding_dtype(1)))\n",
    "\n",
    "    _, inputDevice = cudart.cudaMallocAsync(inputHost.nbytes,stream)\n",
    "    _, outputDevice = cudart.cudaMallocAsync(outputHost.nbytes,stream)\n",
    "\n",
    "    \n",
    "    cudart.cudaMemcpyAsync(inputDevice,inputHost.ctypes.data,inputHost.nbytes,cudart.cudaMemcpyKind.cudaMemcpyHostToDevice,stream)\n",
    "    \n",
    "    context.execute_async_v2([int(inputDevice),int(outputDevice)],stream)\n",
    "\n",
    "    cudart.cudaMemcpyAsync(outputHost.ctypes.data,outputDevice,outputHost.nbytes,cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost,stream)\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputDevice)\n",
    "    cudart.cudaFree(outputDevice)\n",
    "    return outputHost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allocate_buffers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wentaoy/LeViT/levit_test.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhal-fpga-x86.ncsa.illinois.edu/home/wentaoy/LeViT/levit_test.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m context,inputHost, inputDevice, outputHost, outputDevice,stream \u001b[39m=\u001b[39m allocate_buffers(my_engine,\u001b[39m4\u001b[39m,trt\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhal-fpga-x86.ncsa.illinois.edu/home/wentaoy/LeViT/levit_test.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m out \u001b[39m=\u001b[39m do_inference(context, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39m4\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m), inputHost, inputDevice, outputHost, outputDevice, stream, \u001b[39m4\u001b[39m,\u001b[39m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'allocate_buffers' is not defined"
     ]
    }
   ],
   "source": [
    "context,inputHost, inputDevice, outputHost, outputDevice,stream = allocate_buffers(my_engine,4,trt.float32)\n",
    "out = do_inference(context, np.random.randn(4,3,224,224), inputHost, inputDevice, outputHost, outputDevice, stream, 4,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/24/2022-15:24:34] [TRT] [V] Using cublas as a tactic source\n",
      "[05/24/2022-15:24:34] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.8.0 but loaded cuBLAS/cuBLAS LT 11.5.1\n",
      "[05/24/2022-15:24:34] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 4299, GPU 1215 (MiB)\n",
      "[05/24/2022-15:24:34] [TRT] [V] Total per-runner device persistent memory is 105472\n",
      "[05/24/2022-15:24:34] [TRT] [V] Total per-runner host persistent memory is 53200\n",
      "[05/24/2022-15:24:34] [TRT] [V] Allocated activation device memory of size 21776384\n",
      "[05/24/2022-15:24:34] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +21, now: CPU 0, GPU 57 (MiB)\n"
     ]
    }
   ],
   "source": [
    "my_model = levit.LeViT_128(pretrained=True)\n",
    "input_data = np.random.rand(4,3,224,224)\n",
    "input_tensor = torch.Tensor(input_data)\n",
    "out_torch = my_model(input_tensor)\n",
    "out = inference(my_engine,4,input_data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8886,  0.7305,  1.5469,  ...,  1.3973, -0.2703,  1.5398],\n",
       "         [ 0.4422, -1.4356, -0.4701,  ..., -1.0412, -0.9055, -1.7349],\n",
       "         [-0.8149,  0.0101, -0.4138,  ..., -1.2335, -0.9594,  0.8930],\n",
       "         [ 0.7111,  0.0948, -1.3353,  ...,  0.4502,  2.3650,  0.3567]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-1.4870,  1.2106,  1.1281,  ...,  0.1757,  0.0764,  3.5329],\n",
       "         [ 1.1356,  0.3842,  0.9476,  ..., -0.5550, -0.9377, -1.5505],\n",
       "         [-0.4595,  0.9924,  0.1319,  ..., -0.3796,  0.2248,  0.7724],\n",
       "         [ 0.6558, -0.9540, -1.8382,  ...,  0.6027,  3.4104, -0.0396]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4d02458079c4f92f85f58c510c4d244a015bb37e4ec25bcb0e0ea570f847ffd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorrt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
